%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% In preparation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% SAT for digital logic
% Sophie's paper
% Ross

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Submitted
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% FMSD journal
% LPAR
% PEak journal paper
% LICS
% IJCAR - Optimization modulo theories
% CAV - Marabou 2.0
% CAV - SplitGB
% CAV - Nham
% CAV - Pei
% CAV - Clover

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% To Appear
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Rewrite rule verification
% Lemur
% Quantization AAAI

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Patents
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%complete
@patent{MBLS20,
  title     = "Post-silicon validation and debug using symbolic quick error detection",
  number    = "10528448",
  author    = "Mitra, Subhasish and Barrett, Clark and Lin, David and Singh, Eshan",
  year      = "2020",
  month     = "January",
  note      = "Patent No. 10528448",
  url       = "http://www.freepatentsonline.com/10528448.html",
  category  = "Patents",
  abstract  = "Disclosed are improved methods and structures for verifying integrated circuits and in particular systems-on-a-chip constructed therefrom. We call methods and structures according to the present disclosure Symbolic Quick Error Detection or Symbolic QED, Illustrative characteristics of Symbolic QED include: 1) It is applicable to any System-on-Chip (SoC) design as long as it contains at least one programmable processor; 2) It is broadly applicable for logic bugs inside processor cores, accelerators, and uncore components; 3) It does not require failure reproduction; 4) It does not require human intervention during bug localization; 5) It does not require trace buffers, 6) It does not require assertions; and 7) It uses hardware structures called ``change detectors'' which introduce only a small area overhead. Symbolic QED exhibits: 1) A systematic (and automated) approach to inserting ``change detectors'' during a design phase; 2) Quick Error Detection (QED) tests that detect bugs with short error detection latencies and high coverage; and 3) Formal techniques that enable bug localization and generation of minimal bug traces upon bug detection."
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Edited Proceedings
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%complete
@proceedings{BY19,
   url       = "https://hdl.handle.net/2152/79853",
   editor    = "Clark Barrett and Jin Yang",
   title     = "Proceedings of Formal Methods in Computer-Aided Design, FMCAD 2019",
   publisher = "FMCAD Inc.",
   address   = "San Jose, CA, USA",
   month     = oct,
   year      = 2019,
   category  = "Edited Volumes",
}

%complete
@book{CFB+19,
   url       = "https://link.springer.com/journal/10817/63/4",
   editor    = "Iliano Cervesato and Maribel Fernandez and Clark Barrett and Temesghen Kahsai",
   title     = "Special Issue: Linearity and Special Issue: Selected Extended Papers of NFM 2017",
   series    = "Journal of Automated Reasoning",
   volume    = 63,
   number    = 4,
   publisher = "Springer",
   month     = dec,
   year      = 2019,
   issn      = "0168-7433",
   category  = "Edited Volumes",
   abstract  = "This special issue consists of extended versions of papers selected from the 9th NASA Formal Methods Symposium (NFM 2017). The symposium was held at the NASA Ames Research Center, Moffett Field, CA, on May 16 - 18, 2017."
}

%complete
@proceedings{BDK17,
   url       = "http://www.springer.com/us/book/9783319572871",
   editor    = "Clark Barrett and Misty Davies and Temesghen Kahsai",
   title     = "{NASA} Formal Methods: 9th International Symposium, {NFM} 2017",
   series    = "Lecture Notes in Computer Science",
   volume    = 10227,
   publisher = "Springer",
   address   = "Moffet Field, CA, USA",
   month     = may,
   year      = 2017,
   isbn      = "978-3-319-57288-8",
   doi       = "10.1007/978-3-319-57288-8",
   category  = "Edited Volumes",
   abstract  = "This book constitutes the proceedings of the 9th International Symposium on NASA Formal Methods, NFM 2017, held in Moffett Field, CA, USA, in May 2017.
The 23 full and 8 short papers presented in this volume were carefully reviewed and selected from 77 submissions. The papers focus on formal techniques and other approaches for software assurance, their theory, current capabilities and limitations, as well as their potential application to aerospace, robotics, and other NASA-relevant safety-critical systems during all stages of the software life-cycle."
}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Book Chapters
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%complete
@incollection{BSST21,
  url       = "http://theory.stanford.edu/~barrett/pubs/BSST21.pdf",
  Author =	 {Clark Barrett and Roberto Sebastiani and Sanjit
                  Seshia and Cesare Tinelli},
  Booktitle =	 {Handbook of Satisfiability, Second Edition},
  Series = {Frontiers in Artificial Intelligence and Applications},
  Chapter =	 33,
  Editor =	 {Biere, Armin and Heule, Marijn J. H. and van Maaren,
                  Hans and Walsh, Toby},
  Month =	 {February},
  Pages =	 {825--885},
  Publisher =	 {IOS Press},
  Title =	 {Satisfiability Modulo Theories},
  Volume =	 {336},
  Year =	 {2021},
  category  = "Book Chapters",
abstract = "Applications in artificial intelligence and formal verification have greatly
benefited from the recent advances in Boolean Satisfiability (SAT).  Often, however, applications in these fields require deter-
mining the satisfiability of formulas in more expressive logics such as first-order
logic. Despite the great progress made in the last twenty years, general-purpose
first-order theorem provers (such as provers based on the resolution calculus) are
typically not able to solve such formulas directly. The main reason for this is that
many applications require not general first-order satisfiability, but rather satisfi-
ability with respect to some background theory, which fixes the interpretations of
certain predicate and function symbols.

For many theories, specialized methods actually yield decision procedures for
the satisfiability of quantifier-free formulas or some subclass thereof. This is the
case, thanks to classical results in mathematics, for the theory of real numbers
and the theory of integer arithmetic (without multiplication). In the last two
decades, however, specialized decision procedures have also been discovered for
a long and still growing list of other theories with practical applications. These
include certain theories of arrays and of strings, several variants of the theory of
finite sets or multisets, the theories of several classes of lattices, the theories of
finite, regular and infinite trees, of lists, tuples, records, queues, hash tables, and
bit-vectors of a fixed or arbitrary finite size.

The research field concerned with the satisfiability of formulas with respect
to some background theory is called Satisfiability Modulo Theories, or SMT, for
short.  In analogy with SAT, SMT procedures (whether they are decision procedures
or not) are usually referred to as SMT solvers.

This chapter provides a brief overview of SMT and its main approaches,
together with references to the relevant literature for a deeper study. In particular,
it focuses on the two most successful major approaches so far for implementing
SMT solvers, usually referred to as the ``eager'' and the ``lazy'' approach. We
note that in recent years, ideas from both approaches have been combined in
successful solvers, but it is still useful from a pedagogical approach to study them
separately."
}

%complete
@incollection{BT18,
  url       = "http://theory.stanford.edu/~barrett/pubs/BT18.pdf",
  author    = "Clark Barrett and Cesare Tinelli",
  booktitle = "Handbook of Model Checking",
  editor    = "Clarke, Edmund M. and Henzinger, Thomas A. and Veith, Helmut and Bloem, Roderick",
  title     = "Satisfiability Modulo Theories",
  pages     = "305--343",
  publisher = "Springer International Publishing",
  year      = 2018,
  isbn      = "978-3-319-10575-8",
  doi       = "10.1007/978-3-319-10575-8_11",
  category  = "Book Chapters",
  abstract  = "Satisfiability Modulo Theories (SMT) refers to the problem of determining
whether a first-order formula is satisfiable with respect to some logical theory.
Solvers based on SMT are used as back-end engines in model checking applications
such as bounded, interpolation-based, and predicate abstraction-based model checking.
After a brief illustration of these uses, we survey the predominant techniques
for solving SMT problems with an emphasis on the lazy approach, in which a propositional
satisfiability (SAT) solver is combined with one or more theory solvers. We
discuss the architecture of a lazy SMT solver, give examples of theory solvers, show
how to combine such solvers modularly, and mention several extensions of the lazy
approach.We also briefly describe the eager approach in which the SMT problem is
reduced to a SAT problem. Finally, we discuss how the basic framework for determining
satisfiability can be extended with additional functionality such as producing
models, proofs, unsatisfiable cores, and interpolants."
}

%complete
@incollection{BdMF15,
  url       = "http://theory.stanford.edu/~barrett/pubs/BdMF15.pdf",
  author    = "Clark Barrett and Leonardo de Moura and Pascal Fontaine",
  title     = "Proofs in Satisfiability Modulo Theories",
  booktitle = "All about Proofs, Proofs for All",
  series    = "Mathematical Logic and Foundations",
  volume    = 55,
  editor    = "Delahaye, David and Woltzenlogel Paleo, Bruno",
  publisher = "College Publications",
  address   = "London, UK",
  month     = jan,
  year      = 2015,
  pages     = "23--44",
  isbn      = "978-1-84890-166-7",
  category  = "Book Chapters",
}

%complete
@incollection{BSST09,
  url       = "http://theory.stanford.edu/~barrett/pubs/BSST09.pdf",
  Author =	 {Clark Barrett and Roberto Sebastiani and Sanjit
                  Seshia and Cesare Tinelli},
  Booktitle =	 {Handbook of Satisfiability},
  Series = {Frontiers in Artificial Intelligence and Applications},
  Chapter =	 26,
  Editor =	 {Biere, Armin and Heule, Marijn J. H. and van Maaren,
                  Hans and Walsh, Toby},
  Month =	 {February},
  Pages =	 {825--885},
  Publisher =	 {IOS Press},
  Title =	 {Satisfiability Modulo Theories},
  Volume =	 {185},
  Year =	 {2009},
  category  = "Book Chapters",
abstract = "Applications in artificial intelligence and formal verification have greatly
benefited from the recent advances in SAT.  It is often the case, however, that
applications in these fields require determining the satisfiability of formulas
in more expressive logics such as first-order logic.  These applications
typically require not general first-order satisfiability, but rather
satisfiability with respect to some background theory, which fixes the
interpretations of certain predicate and function symbols.

For many background theories, specialized methods actually yield decision
procedures for the satisfiability of quantifier-free formulas or some
subclass thereof.  Specialized decision procedures have been discovered for a
long and still growing list of theories with practical applications.  These
include the theory of equality, several arithmetic theories, certain theories
of arrays and of strings, as well as theories of lists, tuples, records,
queues, hash tables, and bit-vectors of a fixed or arbitrary finite size.

The research field concerned with the satisfiability of formulas with respect
to some background theory is called Satisfiability Modulo Theories, or SMT, for
short.  In analogy with SAT, SMT procedures are usually referred to as SMT
solvers.

This chapter provides a brief overview of SMT together with references to the
relevant literature for a deeper study.  It begins with an overview of
techniques for solving SMT by encodings to SAT, known as the ``eager''
approach.  The rest of the chapter is concerned with an alternative technique
in which a SAT solver is integrated with a separate decision procedure (called
a theory solver) for conjunctions of literals in the theory.  This is known as
the ``lazy'' approach.  After presenting the lazy approach as a whole, we take
a closer look at how to construct theory solvers, how to combinine theory
solvers, and several extensions and enhancements."
}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Journal Articles
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%complete
@article{SNR+23,
  url       = "https://link.springer.com/article/10.1007/s10817-023-09682-2",
  author    = "Ying Sheng and Andres N{\"o}tzli and Andrew Reynolds and Yoni Zohar and David Dill and Wolfgang Grieskamp and Junkil Park and Shaz Qadeer and Clark Barrett and Cesare Tinelli",
  title     = "Reasoning About Vectors: Satisfiability Modulo a Theory of Sequences",
  journal   = "Journal of Automated Reasoning",
  publisher = "Springer",
  volume    = 67,
  number    = 32,
  month     = sep,
  year      = 2023,
  doi       = "10.1007/s10817-023-09682-2",
  category  = "Journal Articles",
  abstract  = "Dynamic arrays, also referred to as vectors, are fundamental
                  data structures used in many programs. Modeling their
                  semantics efficiently is crucial when reasoning about such
                  programs. The theory of arrays is widely supported but is not
                  ideal, because the number of elements is fixed (determined by
                  its index sort) and cannot be adjusted, which is a problem,
                  given that the length of vectors often plays an important
                  role when reasoning about vector programs. In this paper, we
                  propose reasoning about vectors using a theory of
                  sequences. We introduce the theory, propose a basic calculus
                  adapted from one for the theory of strings, and extend it to
                  efficiently handle common vector operations. We prove that
                  our calculus is sound and show how to construct a model when
                  it terminates with a saturated configuration. Finally, we
                  describe an implementation of the calculus in cvc5 and
                  demonstrate its efficacy by evaluating it on verification
                  conditions for smart contracts and benchmarks derived from
                  existing array benchmarks."
}

%complete
@article{SZR+23,
  url       = "https://link.springer.com/article/10.1007/s10817-023-09684-0",
  author    = "Ying Sheng and Yoni Zohar and Christophe Ringeissen and Andrew Reynolds and Clark Barrett and Cesare Tinelli",
  title     = "Combining Stable Infiniteness and (Strong) Politeness",
  journal   = "Journal of Automated Reasoning",
  publisher = "Springer",
  volume    = 67,
  number    = 34,
  month     = sep,
  year      = 2023,
  doi       = "10.1007/s10817-023-09684-0",
  category  = "Journal Articles",
  abstract  = "Polite theory combination is a method for obtaining a solver for
                  a combination of two (or more) theories using the solvers of
                  each individual theory as black boxes. Unlike the earlier
                  Nelson–Oppen method, which is usable only when both theories
                  are stably infinite, only one of the theories needs to be
                  strongly polite in order to use the polite combination
                  method. In its original presentation, politeness was required
                  from one of the theories rather than strong politeness, which
                  was later proven to be insufficient. The first contribution
                  of this paper is a proof that indeed these two notions are
                  different, obtained by presenting a polite theory that is not
                  strongly polite. We also study several variants of this
                  question.  The cost of the generality afforded by the polite
                  combination method, compared to the Nelson–Oppen method, is a
                  larger space of arrangements to consider, involving variables
                  that are not necessarily shared between the purified parts of
                  the input formula. The second contribution of this paper is a
                  hybrid method (building on both polite and Nelson–Oppen
                  combination), which aims to reduce the number of considered
                  variables when a theory is stably infinite with respect to
                  some of its sorts but not all of them. The time required to
                  reason about arrangements is exponential in the worst case,
                  so reducing the number of variables considered has the
                  potential to improve performance significantly. We show
                  preliminary evidence for this by demonstrating significant
                  speed-up on a smart contract verification benchmark."
}

%complete
@article{BBC+23,
   url       = "http://dx.doi.org/10.1145/3587692",
   author    = "Haniel Barbosa and Clark Barrett and Byron Cook and Bruno Dutertre and Gereon Kremer and Hanna Lachnitt and Aina Niemetz and Andres N{\"o}tzli and Alex Ozdemir and Mathias Preiner and Andrew Reynolds and Cesare Tinelli and Yoni Zohar",
   title     = "Generating and Exploiting Automated Reasoning Proof Certificates",
   journal   = "Communications of the Association for Computing Machinery (CACM)",
   publisher = "Association for Computing Machinery",
   volume    = 66,
   number    = 10,
   pages     = "86--95",
   month     = oct,
   year      = 2023,
   doi       = "10.1145/3587692",
   category  = "Journal Articles",
   abstract  = "Moving toward a full suite of proof-producing automated
                  reasoning tools with SMT solvers that can produce full,
                  independently checkable proofs for real-world problems.",
}

%complete
@article{BBB+23,
   url       = "http://dx.doi.org/10.1561/3300000041",
   author    = "Clark Barrett and Brad Boyd and Elie Bursztein and Nicholas Carlini and Brad Chen and Jihye Choi and Amrita Roy Chowdhury and Mihai Christodorescu and Anupam Datta and Soheil Feizi and Kathleen Fisher and Tatsunori Hashimoto and Dan Hendrycks and Somesh Jha and Daniel Kang and Florian Kerschbaum and Eric Mitchell and John Mitchell and Zulfikar Ramzan and Khawaja Shams and Dawn Song and Ankur Taly and Diyi Yang",
   title     = "Identifying and Mitigating the Security Risks of Generative AI",
   journal   = "Foundations and Trends in Privacy and Security",
   publisher = "now publishers inc.",
   volume    = 6,
   number    = 1,
   pages     = "1--52",
   year      = 2023,
   doi       = "10.1561/3300000041",
   issn      = "2474-1558",
   category  = "Journal Articles",
   abstract  = "Every major technical invention resurfaces the dual-use
                  dilemma---the new technology has the potential to be used for
                  good as well as for harm. Generative AI (GenAI) techniques,
                  such as large language models (LLMs) and diffusion models,
                  have shown remarkable capabilities (e.g., in-context
                  learning, code-completion, and text-to-image generation and
                  editing). However, GenAI can be used just as well by
                  attackers to generate new attacks and increase the velocity
                  and efficacy of existing attacks.  This monograph reports the
                  findings of a workshop held at Google (co-organized by
                  Stanford University and the University of Wisconsin-Madison)
                  on the dual-use dilemma posed by GenAI. This work is not
                  meant to be comprehensive, but is rather an attempt to
                  synthesize some of the interesting findings from the
                  workshop. We discuss short-term and long-term goals for the
                  community on this topic. We hope this work provides both a
                  launching point for a discussion on this important topic as
                  well as interesting problems that the research community can
                  work to address."
}


%complete
@article{ABB+23,
   url       = "http://theory.stanford.edu/~barrett/pubs/ABB+23.pdf",
   author    = "Alessandro Abate and Haniel Barbosa and Clark Barrett and Cristina David and Pascal Kesseli and Daniel Kroening and Elizabeth Polgreen and Andrew Reynolds and Cesare Tinelli",
   title     = "Synthesising Programs with Non-trivial Constants",
   journal   = "Journal of Automated Reasoning",
   publisher = "Springer",
   volume    = "67",
   number    = 19,
   doi       = "10.1007/s10817-023-09664-4",
   keywords  = "Program synthesis, Automated reasoning, Satisfiability modulo
                  theories, Counterexample guided inductive synthesis",
   month     = may,
   year      = 2023,
   category  = "Journal Articles",
   abstract  = "Program synthesis is the mechanised construction of
                  software. One of the main difficulties is the efficient
                  exploration of the very large solution space, and tools often
                  require a user-provided syntactic restriction of the search
                  space. While useful in general, such syntactic restrictions
                  provide little help for the generation of programs that
                  contain non-trivial costants, unless the user is able to
                  provide the constants in advance. This is a fundamentally
                  difficult task for state-of-the-art synthesisers. We propose
                  a new approach to the synthesis of programs with non-trivial
                  constants that combines the strengths of a
                  counterexample-guided inductive synthesiser with those of a
                  theory solver, exploring the solution space more efficiently
                  without relying on user guidance. We call this approach
                  CEGIS($\mathcal{T}$), where $\mathcal{T}$ is a first-order
                  theory. We present two exemplars, one based on
                  Fourier-Motzkin (FM) variable elimination and one based on
                  first-order satisfiability. We demonstrate the practical
                  value of CEGIS($\mathcal{T}$) by automatically synthesising
                  programs for a set of intricate benchmarks. Additionally, we
                  present a case study where we integrate CEGIS($\mathcal{T}$)
                  within the mature synthesiser CVC4 and show that
                  CEGIS($\mathcal{T}$) improves CVC4’s results."
}


%complete
@article {WBS+22,
   url       = "http://theory.stanford.edu/~barrett/pubs/WBS+22.pdf",
   author    = "Haoze Wu and Clark Barrett and Mahmood Sharif and Nina Narodytska and Gagandeep Singh",
   title     = "Scalable Verification of {GNN}-Based Job Schedulers",
   journal   = "Proceedings of the ACM on Programming Languages",
   volume    = 6,
   number    = "OOPSLA2",
   pages     = "1036--1065",
   doi       = "10.1145/3563325",
   month     = oct,
   year      = 2022,
   category  = "Journal Articles",
   abstract  = "Recently, Graph Neural Networks (GNNs) have been applied for
                  scheduling jobs over clusters, achieving better performance
                  than hand-crafted heuristics. Despite their impressive
                  performance, concerns remain over whether these GNN-based job
                  schedulers meet users' expectations about other important
                  properties, such as strategy-proofness, sharing incentive,
                  and stability. In this work, we consider formal verification
                  of GNN-based job schedulers. We address several
                  domain-specific challenges such as networks that are deeper
                  and specifications that are richer than those encountered
                  when verifying image and NLP classifiers. We develop vegas,
                  the first general framework for verifying both single-step
                  and multi-step properties of these schedulers based on
                  carefully designed algorithms that combine abstractions,
                  refinements, solvers, and proof transfer. Our experimental
                  results show that vegas achieves significant speed-up when
                  verifying important properties of a state-of-the-art
                  GNN-based scheduler compared to previous methods."
}

%incomplete
@article {KMS+22,
   url       = "http://theory.stanford.edu/~barrett/pubs/KMS+22.pdf",
   author    = "Kalhan Koul and Jackson Melchert and Kavya Sreedhar and Leonard Truong and Gedeon Nyengele and Keyi Zhang and Qiaoyi Liu and Jeff Setter and Po-Han Chen and Yuchen Mei and Maxwell Strange and Ross Daly and Caleb Donovick and Alex Carsello and Taeyoung Kong and Kathleen Feng and Dillon Huff and Ankita Nayak and Rajsekhar Setaluri and James Thomas and Nikhil Bhagdikar and David Durst and Zachary Myers and Nestan Tsiskaridze and Stephen Richardson and Rick Bahr and Kayvon Fatahalian and Pat Hanrahan and Clark Barrett and Mark Horowitz and Christopher Torng and Fredrik Kjolstad and Priyanka Raina",
   title     = "{AHA}: An Agile Approach to the Design of Course-Grained Reconfigurable Accelerators and Compilers",
   journal   = "ACM Transactions on Embedded Computing Systems",
   doi       = "10.1145/3534933",
   month     = apr,
   year      = 2022,
   category  = "Journal Articles",
   abstract  = "With the slowing of Moore's law, computer architects have
                  turned to domain-specific hardware specialization to continue
                  improving the performance and efficiency of computing
                  systems. However, specialization typically entails
                  significant modifications to the software stack to properly
                  leverage the updated hardware. The lack of a structured
                  approach for updating both the compiler and the accelerator
                  in tandem has impeded many attempts to systematize this
                  procedure. We propose a new approach to enable flexible and
                  evolvable domain-specific hardware specialization based on
                  coarse-grained reconfigurable arrays (CGRAs). Our agile
                  methodology employs a combination of new programming
                  languages and formal methods to automatically generate the
                  accelerator hardware and its compiler from a single source of
                  truth. This enables the creation of design-space exploration
                  frameworks that automatically generate accelerator
                  architectures that approach the efficiencies of hand-designed
                  accelerators, with a significantly lower design effort for
                  both hardware and compiler generation. Our current system
                  accelerates dense linear algebra applications, but is modular
                  and can be extended to support other domains. Our methodology
                  has the potential to significantly improve the productivity
                  of hardware-software engineering teams and enable quicker
                  customization and deployment of complex accelerator-rich
                  computing systems."
}
%   url       = "https://arxiv.org/pdf/2101.06825v6.pdf",
%   volume    = 18,
%   number    = 3,


%complete
@article {MIG+22,
   url       = "https://arxiv.org/pdf/2101.06825v6.pdf",
   author    = "Makai Mann and Ahmed Irfan and Alberto Griggio and Oded Padon and Clark Barrett",
   title     = "Counterexample-Guided Prophecy for Model Checking Modulo the Theory of Arrays",
   journal   = "Logical Methods in Computer Science",
   volume    = 18,
   number    = 3,
   doi       = "10.46298/lmcs-18(3:26)2022",
   month     = aug,
   year      = 2022,
   category  = "Journal Articles",
   abstract  = "We develop a framework for model checking infinite-state
                  systems by automatically augmenting them with auxiliary
                  variables, enabling quantifier-free induction proofs for
                  systems that would otherwise require quantified
                  invariants. We combine this mechanism with a
                  counterexample-guided abstraction refinement scheme for the
                  theory of arrays. Our framework can thus, in many cases,
                  reduce inductive reasoning with quantifiers and arrays to
                  quantifier-free and array-free reasoning. We evaluate the
                  approach on a wide set of benchmarks from the literature. The
                  results show that our implementation often outperforms
                  state-of-the-art tools, demonstrating its practical
                  potential."
}

%complete
@article {SZR+22,
   url       = "https://rdcu.be/cMVOR",
   author    = "Ying Sheng and Yoni Zohar and Christophe Ringeissen and Jane Lange and Pascal Fontaine and Clark Barrett",
   title     = "Polite Combination of Algebraic Datatypes",
   journal   = "Journal of Automated Reasoning",
   publisher = "Springer",
   volume    = "66",
   number    = 3,
   pages     = "331--335",
   doi       = "10.1007/s10817-022-09625-3",
   keywords  = "Satisfiability Modulo Theories, Automated reasoning, Theory combination, Algebraic datatypes, Polite combination",
   month     = aug,
   year      = 2022,
   category  = "Journal Articles",
   abstract  = "Algebraic datatypes, and among them lists and trees, have
                  attracted a lot of interest in automated reasoning and
                  Satisfiability Modulo Theories (SMT). Since its latest stable
                  version, the SMT-LIB standard defines a theory of algebraic
                  datatypes, which is currently supported by several mainstream
                  SMT solvers. In this paper, we study this particular theory
                  of datatypes and prove that it is strongly polite, showing
                  how it can be combined with other arbitrary disjoint theories
                  using polite combination. The combination method uses a new,
                  simple, and natural notion of additivity that enables
                  deducing strong politeness from (weak) politeness."
}

%complete
@article {KBD+22,
   url       = "https://rdcu.be/cnBec",
   author    = "Guy Katz and Clark Barrett and David L. Dill and Kyle Julian and Mykel J. Kochenderfer",
   title     = "Reluplex: a Calculus for Reasoning about Deep Neural Networks",
   journal   = "Formal Methods in System Design",
   publisher = "Springer",
   keywords  = "Neural networks; Verification; Satisfiability modulo theories",
   month     = feb,
   year      = 2022,
   volume    = 60,
   pages     = "87--116",
   doi       = "10.1007/s10703-021-00363-7",
   category  = "Journal Articles",
   abstract  = "Deep neural networks have emerged as a widely used and
                  effective means for tackling complex, real-world
                  problems. However, a major obstacle in applying them to
                  safety-critical systems is the great difficulty in providing
                  formal guarantees about their behavior. We present a novel,
                  scalable, and efficient technique for verifying properties of
                  deep neural networks (or providing counter-examples). The
                  technique is based on the simplex method, extended to handle
                  the non-convex Rectified Linear Unit (ReLU) activation
                  function, which is a crucial ingredient in many modern neural
                  networks. The verification procedure tackles neural networks
                  as a whole, without making any simplifying assumptions. We
                  evaluated our technique on a prototype deep neural network
                  implementation of the next-generation airborne collision
                  avoidance system for unmanned aircraft (ACAS Xu). Results
                  show that our technique can successfully prove properties of
                  networks that are an order of magnitude larger than the
                  largest networks that could be verified previously."
}

% complete
@article {NPR+21c,
   url       = "http://theory.stanford.edu/~barrett/pubs/NPR+21c.pdf",
   author    = "Aina Niemetz and Mathias Preiner and Andrew Reynolds and Yoni Zohar and Clark Barrett and Cesare Tinelli",
   title     = "Towards Satisfiability Modulo Parametric Bit-vectors",
   journal   = "Journal of Automated Reasoning",
   publisher = "Springer",
   volume    = 65,
   number    = 7,
   doi       = "10.1007/s10817-021-09598-9",
   pages     = "1001--1025",
   keywords  = "Satisfiability Modulo Theories, Bit-precise Reasoning, Parametric Bit-vectors",
   month     = oct,
   year      = 2021,
   category  = "Journal Articles",
   abstract  = "Many SMT solvers implement efficient SAT-based procedures for
                  solving fixed-size bit-vector formulas. These techniques,
                  however, cannot be used directly to reason about bit-vectors
                  of symbolic bit-width. To address this shortcoming, we
                  propose a translation from bit-vector formulas with
                  parametric bit-width to formulas in a logic supported by SMT
                  solvers that includes non-linear integer arithmetic,
                  uninterpreted functions, and universal quantification. While
                  this logic is undecidable, our approach can still solve many
                  formulas that arise in practice by capitalizing on advances
                  in SMT solving for non-linear arithmetic and universally
                  quantified formulas. We provide several case studies in which
                  we have applied this approach with promising results,
                  including the bit-width independent verification of
                  invertibility conditions, compiler optimizations, and
                  bit-vector rewrite rules."
}

%complete
@article {SWZ+21,
   url       = "https://rdcu.be/czUFw",
   author    = "Christopher A. Strong and Haoze Wu and Aleksandar Zelji{\'{c}} and Kyle D. Julian and Guy Katz and Clark Barrett and Mykel J. Kochenderfer",
   title     = "Global optimization of objective functions represented by {ReLU} networks",
   journal   = "Machine Learning",
   publisher = "Springer",
   keywords  = "Neural network verifcation; Optimization; Adversarial examples; Marabou",
   month     = oct,
   year      = 2021,
   doi       = "10.1007/s10994-021-06050-2",
   category  = "Journal Articles",
   abstract  = "Neural networks can learn complex, non-convex functions, and it
                  is challenging to guarantee their correct behavior in
                  safety-critical contexts. Many approaches exist to find
                  failures in networks (e.g., adversarial examples), but these
                  cannot guarantee the absence of failures. Verification
                  algorithms address this need and provide formal guarantees
                  about a neural network by answering “yes or no”
                  questions. For example, they can answer whether a violation
                  exists within certain bounds. However, individual ``yes or no''
                  questions cannot answer qualitative questions such as “what
                  is the largest error within these bounds”; the answers to
                  these lie in the domain of optimization. Therefore, we
                  propose strategies to extend existing verifiers to perform
                  optimization and find: (i) the most extreme failure in a
                  given input region and (ii) the minimum input perturbation
                  required to cause a failure. A naive approach using a
                  bisection search with an off-the-shelf verifier results in
                  many expensive and overlapping calls to the
                  verifier. Instead, we propose an approach that tightly
                  integrates the optimization process into the verification
                  procedure, achieving better runtime performance than the
                  naive approach. We evaluate our approach implemented as an
                  extension of Marabou, a state-of-the-art neural network
                  verifier, and compare its performance with the bisection
                  approach and MIPVerify, an optimization-based verifier. We
                  observe complementary performance between our extension of
                  Marabou and MIPVerify."
}

%complete
@article{LAL+21,
   url       = "http://theory.stanford.edu/~barrett/pubs/LAL+21.pdf",
   author    = "Changliu Liu and Tomer Arnon and Christopher Lazarus and Christopher Strong and Clark Barrett and Mykel J. Kochenderfer",
   title     = "Algorithms for Verifying Deep Neural Networks",
   journal   = "Foundations and Trends in Optimization",
   publisher = "now publishers",
   month     = feb,
   year      = 2021,
   volume    = 4,
   number    = "3-4",
   pages     = "244--404",
   issn      = "2167-3888",
   doi       = "10.1561/2400000035",
   category  = "Journal Articles",
   abstract  = "Deep neural networks are widely used for nonlinear function
                  approximation, with applications ranging from computer vision
                  to control. Although these networks involve the composition
                  of simple arithmetic operations, it can be very challenging
                  to verify whether a particular network satisfies certain
                  input-output properties. This article surveys methods that
                  have emerged recently for soundly verifying such
                  properties. These methods borrow insights from reachability
                  analysis, optimization, and search. We discuss fundamental
                  differences and connections between existing algorithms. In
                  addition, we provide pedagogical implementations of existing
                  methods and compare them on a set of benchmark problems."
}

%complete
@article{NPR+21b,
   url       = "http://theory.stanford.edu/~barrett/pubs/NPR+21b.pdf",
   author    = "Aina Niemetz and Mathias Preiner and Andrew Reynolds and Clark Barrett and Cesare Tinelli",
   title     = "On Solving Quantified Bit-Vectors using Invertibility Conditions",
   journal   = "Formal Methods in System Design",
   publisher = "Springer US",
   keywords  = "Satisfiability modulo theories; Quantified bit-vectors; Invertibility conditions",
   volume    = 57,
   number    = 1,
   pages     = "87--115",
   month     = jan,
   doi       = "10.1007/s10703-020-00359-9",
   year      = 2021,
   category  = "Journal Articles",
   abstract  = "We present a novel approach for solving quantified bit-vector
                  constraints in Satisfiability Modulo Theories (SMT) based on
                  computing symbolic inverses of bit-vector operators. We
                  derive conditions that precisely characterize when bit-vector
                  constraints are invertible for a representative set of
                  bit-vector operators commonly supported by SMT solvers. We
                  utilize syntax-guided synthesis techniques to aid in
                  establishing these conditions and verify them independently
                  by using several SMT solvers. We show that invertibility
                  conditions can be embedded into quantifier instantiations
                  using Hilbert choice expressions and give experimental
                  evidence that a counterexample-guided approach for quantifier
                  instantiation utilizing these techniques leads to performance
                  improvements with respect to state-of-the-art solvers for
                  quantified bit-vector constraints."
}

%complete
@article {RKT+19,
   url       = "http://theory.stanford.edu/~barrett/pubs/RKT+19.pdf",
   author    = "Andrew Reynolds and Viktor Kuncak and Cesare Tinelli and Clark Barrett and Morgan Deters",
   title     = "Refutation-Based Synthesis in {SMT}",
   journal   = "Formal Methods in System Design",
   publisher = "Springer US",
   keywords  = "Program synthesis; Satisfiability modulo theories; Automated deduction",
   volume    = 55,
   number    = 2,
   pages     = "73--102",
   month     = dec,
   issn      = "1572-8102",
   doi       = "10.1007/s10703-017-0270-2",
   year      = 2019,
   category  = "Journal Articles",
   abstract  = "We introduce the first program synthesis engine implemented inside
an SMT solver. We present an approach that extracts solution functions from
unsatisfiability proofs of the negated form of synthesis conjectures. We also discuss
novel counterexample-guided techniques for quantifier instantiation that we use
to make finding such proofs practically feasible. A particularly important class
of specifications are single-invocation properties, for which we present a dedicated
algorithm. To support syntax restrictions on generated solutions, our approach can
transform a solution found without restrictions into the desired syntactic form. As
an alternative, we show how to use evaluation function axioms to embed syntactic
restrictions into constraints over algebraic datatypes, and then use an algebraic
datatype decision procedure to drive synthesis. Our experimental evaluation on
syntax-guided synthesis benchmarks shows that our implementation in the CVC4
SMT solver is competitive with state-of-the-art tools for synthesis."
}

%complete
@article {BBRT18,
   url       = "https://lmcs.episciences.org/4950",
   author    = "Kshitij Bansal and Clark Barrett and Andrew Reynolds and Cesare Tinelli",
   title     = "Reasoning with Finite Sets and Cardinality Constraints in SMT",
   journal   = "Logical Methods in Computer Science",
   keywords  = "Satisfiability modulo theories, finite sets, decision procedures",
   volume    = 14,
   number    = 4,
   doi       = "10.23638/LMCS-14(4:12)2018",
   month     = nov,
   year      = 2018,
   category  = "Journal Articles",
   abstract  =
"We consider the problem of deciding the satisfiability of quantifier-free
formulas in the theory of finite sets with cardinality constraints. Sets are a
common high-level data structure used in programming; thus, such a theory is
useful for modeling program constructs directly. More importantly, sets are a
basic construct of mathematics and thus natural to use when formalizing the
properties of computational systems. We develop a calculus describing a modular
combination of a procedure for reasoning about membership constraints with a
procedure for reasoning about cardinality constraints. Cardinality reasoning
involves tracking how different sets overlap. For efficiency, we avoid
considering Venn regions directly, as done in previous work. Instead, we
develop a novel technique wherein potentially overlapping regions are
considered incrementally as needed, using a graph to track the interaction
among the different regions. The calculus has been designed to facilitate its
implementation within SMT solvers based on the DPLL($T$) architecture. Our
experimental results demonstrate that the new techniques are competitive with
previous techniques and can scale much better on certain classes of problems."
}

%complete
@article {SLB+18,
   url       = "http://theory.stanford.edu/~barrett/pubs/SLB+18.pdf",
   author    = "Eshan Singh and David Lin and Clark Barrett and Subhasish Mitra",
   title     = "Logic Bug Detection and Localization Using Symbolic Quick Error Detection",
   journal   = "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
   publisher = "IEEE",
   keywords  = "Bounded Model Checking, Debug, Formal Debugging, Post-Silicon, Validation and Debug, Quick Error Detection, QED, Symbolic Quick Error Detection",
   doi       = "10.1109/TCAD.2018.2834401",
   year      = 2018,
   category  = "Journal Articles",
   abstract  =
"We present Symbolic Quick Error Detection (Symbolic QED), a structured
approach for logic bug detection and localization which can be used both during
pre-silicon design verification as well as post-silicon validation and
debug. This new methodology leverages prior work on Quick Error Detection (QED)
which has been demonstrated to drastically reduce the latency, in terms of the
number of clock cycles, of error detection following the activation of a logic
(or electrical) bug. QED works through software transformations, including
redundant execution and control flow checking, of the applied tests. Symbolic
QED combines these error-detecting QED transformations with bounded model
checking-based formal analysis to generate minimal-length bug activation traces
that detect and localize any logic bugs in the design. We demonstrate the
practicality and effectiveness of Symbolic QED using the OpenSPARC T2, a
500-million-transistor open-source multicore System-on-Chip (SoC) design, and
using ``difficult'' logic bug scenarios observed in various state-of-the-art
commercial multicore SoCs. Our results show that Symbolic QED: (i) is fully
automatic, unlike manual techniques in use today that can be extremely
time-consuming and expensive; (ii) requires only a few hours in contrast to
manual approaches that might take days (or even months) or formal techniques
that often take days or fail completely for large designs; and (iii) generates
counter-examples (for activating and detecting logic bugs) that are up to 6
orders of magnitude shorter than those produced by traditional
techniques. Significantly, this new approach does not require any additional
hardware."
}

%complete
@article {RTB17,
   url       = "http://theory.stanford.edu/~barrett/pubs/RTB17.pdf",
   author    = "Andrew Reynolds and Cesare Tinelli and Clark Barrett",
   title     = "Constraint solving for finite model finding in {SMT} solvers",
   journal   = "Theory and Practice of Logic Programming",
   publisher = "Cambridge University Press",
   keywords  = "Satisfiability modulo theories, finite model finding",
   volume    = 17,
   number    = 4,
   pages     = "516--558",
   month     = jul,
   year      = 2017,
   category  = "Journal Articles",
   abstract  = "Satisfiability modulo theories (SMT) solvers have been used successfully as reasoning engines for automated verification and other applications based on automated reasoning. Current techniques for dealing with quantified formulas in SMT are generally incomplete, forcing SMT solvers to report ``unknown'' when they fail to prove the unsatisfiability of a formula with quantifiers. This inability to return counter models limits their usefulness in applications that produce queries involving quantified formulas. In this paper, we reduce these limitations by integrating finite model finding techniques based on constraint solving into the architecture used by modern SMT solvers. This approach is made possible by a novel solver for cardinality constraints, as well as techniques for on-demand instantiation of quantified formulas. Experiments show that our approach is competitive with the state of the art in SMT, and orthogonal to approaches in automated theorem proving."
}

%complete
@article {SLB+16,
   url       = "http://theory.stanford.edu/~barrett/pubs/SLB+16.pdf",
   author    = "Eshan Singh and David Lin and Clark Barrett and Subhasish Mitra",
   title     = "Symbolic Quick Error Detection for Pre-Silicon and Post-Silicon Validation: Frequently Asked Questions",
   journal   = "IEEE Design \& Test",
   publisher = "IEEE",
   keywords  = "Computer bugs, Error detection, Silicon, Measurement, Integrated circuit modeling, Symbolic Quick Error Detection, Debug, Post-Silicon Validation, Pre-silicon verification",
   volume    = 33,
   number    = 6,
   pages     = "55--62",
   month     = dec,
   year      = 2016,
   issn      = "2168-2356",
   doi       = "10.1109/MDAT.2016.2590987",
   category  = "Journal Articles",
   abstract  = "Reducing the error detection latency is critical for improving the design visibility while searching for design errors. This article uses a FAQ format to discuss the key points of the symbolic QED method that can be applied during both pre-silicon and post-silicon validation.",
}

%complete
@article {LRT+16,
   url       = "http://theory.stanford.edu/~barrett/pubs/LRT+16.pdf",
   author    = "Tianyi Liang and Andrew Reynolds and Nestan Tsiskaridze and Cesare Tinelli and Clark Barrett and Morgan Deters",
   title     = "An Efficient {SMT} Solver for String Constraints",
   journal   = "Formal Methods in System Design",
   publisher = "Springer US",
   keywords  = "String solving; Satisfiability Modulo Theories; Automated Deduction",
   volume    = 48,
   number    = 3,
   pages     = "206--234",
   month     = jun,
   year      = 2016,
   issn      = "1572-8102",
   doi       = "10.1007/s10703-016-0247-6",
   category  = "Journal Articles",
   abstract  = "An increasing number of applications in verification and security 
rely on or could benefit from automatic solvers that can check the satisfiability
of constraints over a rich set of data types that includes character strings.
Until recently, satisfiability solvers for strings were standalone tools 
that could reason only about fairly restricted fragments of the theory 
of strings and regular expressions such as, for instance, strings
of bounded lengths.
These solvers were based on reductions to satisfiability problems 
over other data types, such as bit vectors, or to automata decision problems.
We present a set of algebraic techniques for solving constraints over 
a rich theory of unbounded strings natively, without reduction 
to other problems. 
These techniques can be used to integrate string reasoning into general, 
multi-theory SMT solvers based on the DPLL(T) architecture.
We have implemented them in our SMT solver CVC4 to expand 
its already large set of built-in theories to a theory of strings 
with concatenation, length, and membership in regular languages.
This implementation makes CVC4 the first solver able to accept 
a rich set of mixed constraints over strings, integers, reals, arrays 
and algebraic datatypes.
Our initial experimental results show that, in addition, 
over pure string problems, CVC4 is highly competitive  
with specialized string solvers with a comparable input language."
}

%complete
@article {BDdM+13,
   url       = "http://theory.stanford.edu/~barrett/pubs/BDdM+13.pdf",
   author    = "Clark Barrett and Morgan Deters and Leonardo de Moura and Albert Oliveras and Aaron Stump",
   title     = "6 Years of {SMT-COMP}",
   journal   = "Journal of Automated Reasoning",
   publisher = "Springer Netherlands",
   volume    = 50,
   number    = 3,
   doi       = {10.1007/s10817-012-9246-5},
   pages     = "243--277",
   keywords  = {SAT Modulo Theories; Competition; Experimental evaluation},
   month     = mar,
   year      = 2013,
   category  = "Journal Articles",
   abstract  = "The annual Satisﬁability Modulo Theories Competition (SMT-COMP) was
initiated in 2005 in order to stimulate the advance of state-of-the-art techniques and
tools developed by the Satisﬁability Modulo Theories (SMT) community. This paper
summarizes the ﬁrst six editions of the competition. We present the evolution of the
competition’s organization and rules, show how the state of the art has improved
over the course of the competition, and discuss the impact SMT-COMP has had on
the SMT community and beyond. Additionally, we include an exhaustive list of all
competitors, and present experimental results showing signiﬁcant improvement in SMT
solvers during these six years. Finally, we analyze to what extent the initial goals of
the competition have been achieved, and sketch future directions for the competition."
}

%complete
@article {JB13,
   url       = "http://theory.stanford.edu/~barrett/pubs/JB13.pdf",
   author    = "Dejan Jovanovi\'{c} and Clark Barrett",
   affiliation = {New York University, New York, USA},
   title     = "Being Careful about Theory Combination",
   journal   = "Formal Methods in System Design",
   publisher = {Springer US},
   issn      = {0925-9856},
   volume    = 42,
   number    = 1,
   doi       = "10.1007/s10703-012-0159-z",
   keywords  = {Theory combination; Nelson-Oppen; Satisfiability modulo theories},
   pages     = "67--90",
   month     = feb,
   year      = 2013,
   category  = "Journal Articles",
   abstract  = "One of the main shortcomings of traditional methods for combining theories is
the complexity of guessing the arrangement of variables shared by the individual theories.
This paper presents a reformulation of the Nelson-Oppen method that takes into account
explicit equality propagation and can ignore pairs of shared variables that the theories do
not care about. We show the correctness of the new approach and present care functions
for the theory of uninterpreted functions and the theory of arrays. The effectiveness of the
new method is illustrated by experimental results demonstrating a dramatic performance
improvement on benchmarks combining arrays and bit-vectors."
}

%complete
@article{GBT09,
  url       = "http://theory.stanford.edu/~barrett/pubs/GBT09.pdf",
  author    = "Yeting Ge and Clark Barrett and Cesare Tinelli",
  title     = "Solving Quantified Verification Conditions using Satisfiability Modulo Theories",
  journal   = "Annals of Mathematics and Artificial Intelligence",
  publisher = "Springer",
  volume    = 55,
  number    = "1-2",
  pages     = "101--122",
  month     = feb,
  year      = 2009,
  issn      = "1012-2443",
  doi       = "10.1007/s10472-009-9153-6",
  category  = "Journal Articles",
  abstract  = "First-order logic provides a convenient formalism for describing
a wide variety of verification conditions. Two main approaches to
checking such conditions are pure first-order automated theorem proving
(ATP) and automated theorem proving based on satisfiability modulo
theories (SMT). Traditional ATP systems are designed to handle quantifiers
easily, but often have difficulty reasoning with respect to theories.
SMT systems, on the other hand, have built-in support for many useful
theories, but have a much more difficult time with quantifiers. One clue
on how to get the best of both worlds can be found in the legacy system
Simplify which combines built-in theory reasoning with quantifier instantiation
heuristics. Inspired by Simplify and motivated by a desire to
provide a competitive alternative to ATP systems, this paper describes a
methodology for reasoning about quantifiers in SMT systems.We present
the methodology in the context of the Abstract DPLL Modulo Theories
framework. Besides adapting many of Simplify’s techniques, we also introduce
a number of new heuristics. Most important is the notion of
instantiation level which provides an effective mechanism for prioritizing
and managing the large search space inherent in quantifier instantiation
techniques. These techniques have been implemented in the SMT system
CVC3. Experimental results show that our methodology enables CVC3
to solve a significant number of quantified benchmarks that were not
solvable with previous approaches."
}

%complete
@article{BDO+08,
  url       = "http://theory.stanford.edu/~barrett/pubs/BDO+08.pdf",
  author    = "Clark Barrett and Morgan Deters and Albert Oliveras and Aaron Stump",
  title     = "Design and Results of the $3^{rd}$ Annual Satisfiability Modulo Theories Competition ({SMT-COMP} 2007)",
  journal   = "International Journal on Artificial Intelligence Tools (IJAIT)",
  publisher = "World Scientific",
  volume    = 17,
  number    = 4,
  pages     = "569--606",
  month     = aug,
  year      = 2008,
  category  = "Journal Articles",
  abstract  = "The Satisfiability Modulo Theories Competition (SMT-COMP) is an annual competition aimed at stimulating the
advance of the state-of-the-art techniques and tools developed by the Satisfiability Modulo Theories (SMT) community.
As with the first two editions, SMT-COMP 2007 was held as a satellite event of CAV 2007, held July 3-7, 2007.
This paper gives an overview of the rules, competition format, benchmarks, participants and results of SMT-COMP
2007."
}

%complete
@article{BdMS07,
  url       = "http://theory.stanford.edu/~barrett/pubs/BdMS07.pdf",
  author    = "Clark Barrett and Leonardo de Moura and Aaron Stump",
  title     = "Design and Results of the $2^{nd}$ Satisfiability Modulo Theories Competition ({SMT-COMP} 2006)",
  journal   = "Formal Methods in System Design",
  publisher = "Springer Netherlands",
  volume    = 31,
  number    = 3,
  pages     = "221--239",
  month     = dec,
  year      = 2007,
  issn      = "0925-9856",
  doi       = "10.1007/s10703-007-0038-1",
  category  = "Journal Articles",
  abstract  = "The Satisﬁability Modulo Theories Competition (SMT-COMP) arose from the
SMT-LIB initiative to spur adoption of common, community-designed formats,
and to spark further advances in satisﬁability modulo theories (SMT). The ﬁrst
SMT-COMP was held in 2005 as a satellite event of CAV 2005. SMT-COMP
2006 was held August 17 - 19, 2006, as a satellite event of CAV 2006. This paper
describes the rules and competition format for SMT-COMP 2006, the benchmarks
used, the participants, and the results."
}

%complete
@article{BST07-JSAT,
  url       = "http://theory.stanford.edu/~barrett/pubs/BST07-JSAT.pdf",
  author    = "Clark Barrett and Igor Shikanian and Cesare Tinelli",
  title     = "An Abstract Decision Procedure for a Theory of Inductive Data Types",
  journal   = "Journal on Satisfiability, Boolean Modeling and Computation",
  publisher = "IOS Press",
  volume    = 3,
  pages     = "21--46",
  year      = 2007,
  issn      = "1574-0617",
  category  = "Journal Articles",
  abstract  = "Inductive data types are a valuable modeling tool for software verification. In the past,
decision procedures have been proposed for various theories of inductive data types, some
focused on the universal fragment, and some focused on handling arbitrary quantifiers. Because
of the complexity of the full theory, previous work on the full theory has not focused
on strategies for practical implementation. However, even for the universal fragment, previous
work has been limited in several significant ways. In this paper, we present a general
and practical algorithm for the universal fragment. The algorithm is presented declaratively
as a set of abstract rules which we show to be terminating, sound, and complete.
We show how other algorithms can be realized as strategies within our general framework,
and we propose a new strategy and give experimental results indicating that it performs
well in practice. We conclude with a discussion of several useful ways the algorithm can be
extended."
}

%complete
@article{BdMS05-JAR,
  url       = "http://theory.stanford.edu/~barrett/pubs/BdMS05-JAR.pdf",
  author    = "Clark Barrett and Leonardo de Moura and Aaron Stump",
  title     = "Design and Results of the $1^{st}$ Satisfiability Modulo Theories Competition ({SMT-COMP} 2005)",
  journal   = "Journal of Automated Reasoning",
  publisher = "Springer Netherlands",
  volume    = 35,
  number    = 4,
  pages     = "373--390",
  month     = nov,
  year      = 2005,
  issn      = "0168-7433",
  doi       = "10.1007/s10817-006-9026-1",
  category  = "Journal Articles",
  abstract  = "The Satisfiability Modulo Theories Competition (SMT-COMP) is intended to spark
further advances in the decision procedures field, especially for applications in hardware and
software verification. Public competitions are a well-known means of stimulating advancement
in automated reasoning. Evaluation of SMT solvers entered in SMT-COMP took place
while CAV 2005 was meeting. Twelve solvers were entered, 1352 benchmarks were collected
in seven different divisions."
}

%complete
@article{ZPG+05,
  url       = "http://theory.stanford.edu/~barrett/pubs/ZPG+05.pdf",
  author    = "Lenore Zuck and Amir Pnueli and Benjamin Goldberg and Clark Barrett and Yi Fang and Ying Hu",
  title     = "Translation and Run-Time Validation of Loop Transformations",
  journal   = "Formal Methods in System Design",
  publisher = "Springer Netherlands",
  volume    = 27,
  number    = 3,
  pages     = "335--360",
  month     = nov,
  year      = 2005,
  issn      = "0925-9856",
  doi       = "10.1007/s10703-005-3402-z",
  category  = "Journal Articles",
  abstract  = "This paper presents new approaches to the validation of loop optimizations that compilers
use to obtain the highest performance from modern architectures. Rather than verify the compiler, the
approach of translation validation performs a validation check after every run of the compiler, producing
a formal proof that the produced target code is a correct implementation of the source code.
As part of an active and ongoing research project on translation validation, we have previously described
approaches for validating optimizations that preserve the loop structure of the code and have presented
a simulation-based general technique for validating such optimizations. In this paper, for more aggressive
optimizations that alter the loop structure of the code--such as distribution, fusion, tiling, and
interchange--we present a set of permutation rules which establish that the transformed code satisfies all the implied
data dependencies necessary for the validity of the considered transformation. We describe the extensions
to our tool voc-64 which are required to validate these structure-modifying optimizations.
This paper also discusses preliminary work on run-time validation of speculative loop optimizations. This
involves using run-time tests to ensure the corretness of loop optimizations whose correctness cannot
be guaranteed at compile time. Unlike compiler validation, run-time validation must not only determine
when an optimization has generated incorrect code, but also recovering from the optimization without
aborting the program or producing an incorrect result. This technique has been applied to several loop
optimizations, including loop interchange and loop tiling, and appears to be quite promising."
}

%complete
@article{SJO+05,
  url       = "http://theory.stanford.edu/~barrett/pubs/SJO+05.pdf",
  author    = "Carl-Johan H. Seger and Robert B. Jones and John W. O'Leary and Tom Melham and Mark D. Aagaard and Clark Barrett and Don Syme",
  title     = "An Industrially Effective Environment for Formal Hardware Verification",
  journal   = "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems",
  volume    = 24,
  number    = 9,
  pages     = "1381--1405",
  month     = sep,
  year      = 2005,
  issn      = "0278-0070",
  doi       = "10.1109/TCAD.2005.850814",
  category  = "Journal Articles",
  abstract  = "The Forte formal verification environment for
datapath-dominated hardware is described. Forte has proven to be
effective in large-scale industrial trials and combines an efficient
linear-time logic model-checking algorithm, namely the symbolic
trajectory evaluation (STE), with lightweight theorem proving
in higher-order logic. These are tightly integrated in a general-purpose
functional programming language, which both allows the
system to be easily customized and at the same time serves as
a specification language. The design philosophy behind Forte is
presented and the elements of the verification methodology that
make it effective in practice are also described."
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Conference Papers
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%complete
@inproceedings{WWB23,
  url       = "https://proceedings.neurips.cc/paper_files/paper/2023/file/46907c2ff9fafd618095161d76461842-Paper-Conference.pdf",
  author    = "Min Wu and Haoze Wu and Clark Barrett",
  title     = "VeriX: Towards Verified Explainability of Deep Neural Networks",
  booktitle = "Advances in Neural Information Processing Systems 36 (NeurIPS 2023)",
  editor    = "A. Oh and T. Neumann and A. Globerson and K. Saenko and M. Hardt and S. Levine",
  publisher = "Curran Associates, Inc.",
  pages     = "22247--22268",
  volume    = 36,
  mon       = dec,
  year      = 2023,
  category  = "Conference Publications",
  abstract  = "We present VeriX (Verified eXplainability), a system for
                  producing optimal robust explanations and generating
                  counterfactuals along decision boundaries of machine learning
                  models. We build such explanations and counterfactuals
                  iteratively using constraint solving techniques and a
                  heuristic based on feature-level sensitivity ranking. We
                  evaluate our method on image recognition benchmarks and a
                  real-world scenario of autonomous aircraft taxiing."
}

%complete
@inproceedings{ZSZ+23b,
  url       = "https://proceedings.neurips.cc/paper_files/paper/2023/file/b914a8fcea5c176cf1ed75c762ce27fd-Paper-Conference.pdf",
  author    = "Banghua Zhu and Ying Sheng and Lianmin Zheng and Clark Barrett and Michael Jordan and Jiantao Jiao",
  title     = "Towards Optimal Caching and Model Selection for Large Model Inference",
  booktitle = "Advances in Neural Information Processing Systems 36 (NeurIPS 2023)",
  editor    = "A. Oh and T. Neumann and A. Globerson and K. Saenko and M. Hardt and S. Levine",
  publisher = "Curran Associates, Inc.",
  pages     = "59062--59094",
  volume    = 36,
  mon       = dec,
  year      = 2023,
  category  = "Conference Publications",
  abstract  = "Large Language Models (LLMs) and other large foundation models
                  have achieved impressive results, but their size exacerbates
                  existing resource consumption and latency challenges. In
                  particular, the large-scale deployment of these models is
                  hindered by the significant resource requirements during
                  inference. In this paper, we study two approaches for
                  mitigating these challenges: employing a cache to store
                  previous queries and learning a model selector to choose from
                  an ensemble of models for query processing.  Theoretically,
                  we provide an optimal algorithm for jointly optimizing both
                  approaches to reduce the inference cost in both offline and
                  online tabular settings. By combining a caching algorithm,
                  namely Greedy Dual Size with Frequency (GDSF) or Least
                  Expected Cost (LEC), with a model selector, we achieve
                  optimal rates in both offline and online settings.
                  Empirically, simulations show that our caching and model
                  selection algorithm greatly improves over the baselines, with
                  up to 50x improvement over the baseline when the ratio
                  between the maximum cost and minimum cost is 100.
                  Experiments on real datasets show a 4.3x improvement in FLOPs
                  over the baseline when the ratio for FLOPs is 10, and a 1.8x
                  improvement in latency when the ratio for average latency is
                  1.85.",
}

%complete
@inproceedings{ZSZ+23a,
  url       = "https://proceedings.neurips.cc/paper_files/paper/2023/file/6ceefa7b15572587b78ecfcebb2827f8-Paper-Conference.pdf",
  author    = {Zhang, Zhenyu and Sheng, Ying and Zhou, Tianyi and Chen, Tianlong and Zheng, Lianmin and Cai, Ruisi and Song, Zhao and Tian, Yuandong and R\'{e}, Christopher and Barrett, Clark and Wang, Zhangyang "Atlas" and Chen, Beidi},
  title     = "H$_2$O: Heavy-Hitter Oracle for Efficient Generative Inference of Large Language Models",
  booktitle = "Advances in Neural Information Processing Systems 36 (NeurIPS 2023)",
  editor    = "A. Oh and T. Neumann and A. Globerson and K. Saenko and M. Hardt and S. Levine",
  publisher = "Curran Associates, Inc.",
  pages     = "34661--34710",
  volume    = 36,
  mon       = dec,
  year      = 2023,
  category  = "Conference Publications",
  abstract  = "Large Language Models (LLMs), despite their recent impressive
                  accomplishments, are notably cost-prohibitive to deploy,
                  particularly for applications involving long-content
                  generation, such as dialogue systems and story
                  writing. Often, a large amount of transient state
                  information, referred to as the KV cache, is stored in GPU
                  memory in addition to model parameters, scaling linearly with
                  the sequence length and batch size. In this paper, we
                  introduce a novel approach for implementing the KV cache
                  which significantly reduces its memory footprint. Our
                  approach is based on the noteworthy observation that a small
                  portion of tokens contributes most of the value when
                  computing attention scores. We call these tokens Heavy
                  Hitters (H$_2$). Through a comprehensive investigation, we
                  find that ($i$) the emergence of H$_2$ is natural and
                  strongly correlates with the frequent co-occurrence of tokens
                  in the text, and ($ii$) removing them results in significant
                  performance degradation. Based on these insights, we propose
                  Heavy Hitter Oracle (H$_2$O), a KV cache eviction policy that
                  dynamically retains a balance of recent and H$_2$ tokens. We
                  formulate the KV cache eviction as a dynamic submodular
                  problem and prove (under mild assumptions) a theoretical
                  guarantee for our novel eviction algorithm which could help
                  guide future work. We validate the accuracy of our algorithm
                  with OPT, LLaMA, and GPT-NeoX across a wide range of
                  tasks. Our implementation of H$_2$O with 20\% heavy hitters
                  improves the throughput over three leading inference systems
                  DeepSpeed Zero-Inference, Hugging Face Accelerate, and
                  FlexGen by up to 29x , 29x , and 3x on OPT-6.7B and
                  OPT-30B. With the same batch size, H$_2$O can reduce the
                  latency by up to 1.9x.",
}

%complete
@inproceedings{MRB+23,
  url       = "https://repositum.tuwien.at/handle/20.500.12708/188730",
  author    = "Abdalrhman Mohamed and Andrew Reynolds and Clark Barrett and Cesare Tinelli",
  title     = "A Procedure for SyGuS Solution Fitting via Matching and Rewrite Rule Discovery",
  booktitle = "Proceedings of the $23^{rd}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '23)",
  editor    = "Alexander Nadel and Kristin Yvonne Rozier",
  publisher = "TU Wien Academic Press",
  pages     = "189--198",
  month     = oct,
  year      = 2023,
  doi       = "10.34727/2023/isbn.978-3-85448-060-0_27",
  note      = "Ames, IA",
  category  = "Conference Publications",
  abstract  = "Syntax-guided synthesis (SyGuS) is a recent software synthesis
                  paradigm in which an automated synthesis tool is asked to
                  synthesize a term that satisfies both a semantic and a
                  syntactic specification. We consider a special case of the
                  SyGuS problem, where a term is already known to satisfy the
                  semantic specification but may not satisfy the syntactic
                  one. The goal is then to find an equivalent term that
                  additionally satisfies the syntactic specification, provided
                  by a context-free grammar.  We introduce a novel procedure
                  for solving this problem which leverages pattern matching and
                  automated discovery of rewrite rules. We also provide an
                  implementation of the procedure by modifying the SyGuS solver
                  embedded in the cvc5 SMT solver. Our evaluation shows that
                  our new procedure significantly outperforms the state of the
                  art on a large set of SyGuS problems for standard SMT-LIB
                  theories such as bit-vectors, arithmetic, and strings."
}

%complete
@inproceedings{WHL+23,
  url       = "https://repositum.tuwien.at/handle/20.500.12708/188730",
  author    = "Haoze Wu and Christopher Hahn and Florian Matthias Lonsing and Makai Mann and Raghuram Ramanujan and Clark Barrett",
  title     = "Lightweight Online Learning for Sets of Related Problems in Automated Reasoning",
  booktitle = "Proceedings of the $23^{rd}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '23)",
  editor    = "Alexander Nadel and Kristin Yvonne Rozier",
  publisher = "TU Wien Academic Press",
  pages     = "23--33",
  month     = oct,
  year      = 2023,
  doi       = "10.34727/2023/isbn.978-3-85448-060-0_10",
  note      = "Ames, IA",
  category  = "Conference Publications",
  abstract  = "We present Self-Driven Strategy Learning (SDSL), a lightweight
                  online learning methodology for automated reasoning tasks
                  that involve solving a set of related problems. SDSL does not
                  require offline training, but instead automatically
                  constructs a dataset while solving earlier problems. It fits
                  a machine learning model to this data which is then used to
                  adjust the solving strategy for later problems. We formally
                  define the approach as a set of abstract transition rules. We
                  describe a concrete instance of the SDSL calculus which uses
                  conditional sampling for generating data and random forests
                  as the underlying machine learning model. We implement the
                  approach on top of the KISSAT solver and show that the
                  combination of KISSAT+SDSL certifies larger bounds and finds
                  more counter-examples than other state-of-the-art bounded
                  model checking approaches on benchmarks obtained from the
                  latest Hardware Model Checking Competition.",
}

%complete
@inproceedings{WNR+23,
  url       = "https://repositum.tuwien.at/handle/20.500.12708/188827",
  author    = "Amalee Wilson and Andres N{\"o}tzli and Andrew Reynolds and Byron Cook and Cesare Tinelli and Clark Barrett",
  title     = "Partitioning Strategies for Distributed {SMT} Solving",
  booktitle = "Proceedings of the $23^{rd}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '23)",
  editor    = "Alexander Nadel and Kristin Yvonne Rozier",
  publisher = "TU Wien Academic Press",
  pages     = "199--208",
  month     = oct,
  year      = 2023,
  doi       = "10.34727/2023/isbn.978-3-85448-060-0_28",
  note      = "Ames, IA",
  category  = "Conference Publications",
  abstract  = "For many users of Satisfiability Modulo Theories (SMT) solvers,
                  the solver's performance is the main bottleneck in their
                  application. One promising approach for improving performance
                  is to leverage the increasing availability of parallel and
                  cloud computing. However, despite many efforts, the best
                  parallel approach to date consists of running a portfolio of
                  solvers, meaning that performance is still limited by the
                  best possible sequential performance. In this paper, we
                  revisit divide-and-conquer approaches to parallel SMT, in
                  which a challenging problem is partitioned into several
                  subproblems. We introduce several new partitioning strategies
                  and evaluate their performance, both alone as well as within
                  portfolios, on a large set of difficult SMT benchmarks. We
                  show that hybrid portfolios that include our new strategies
                  can significantly outperform traditional portfolios for
                  parallel SMT."
}

%complete
@inproceedings{WWS+23,
  url       = "https://doi.org/10.1109/IROS55552.2023.10342011",
  author    = "Wu, Haoze and Wu, Min and Sadigh, Dorsa and Barrett, Clark",
  title     = "Soy: An Efficient {MILP} Solver for Piecewise-Affine Systems",
  booktitle = "2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS '23)",
  publisher = "IEEE",
  pages     = "6281--6288",
  month     = oct,
  year      = 2023,
  doi       = "10.1109/IROS55552.2023.10342011",
  note      = "Detroit, MI, USA",
  category  = "Conference Publications",
  abstract  = "Piecewise-affine (PWA) systems are widely used for modeling and
                  control of robotics problems including modeling contact
                  dynamics. A common approach is to encode the control problem
                  of the PWA system as a Mixed-Integer Convex Program (MICP),
                  which can be solved by general-purpose off-the-shelf MICP
                  solvers. To mitigate the scalability challenge of solving
                  these MICP problems, existing work focuses on devising
                  efficient and strong formulations of the problems, while less
                  effort has been spent on exploiting their specific structure
                  to develop specialized solvers. The latter is the theme of
                  our work. We focus on efficiently handling one-hot
                  constraints, which are particularly relevant when encoding
                  PWA dynamics. We have implemented our techniques in a tool,
                  Soy, which organically integrates logical reasoning,
                  arithmetic reasoning, and stochastic local search. For a set
                  of PWA control benchmarks, Soy solves more problems, faster,
                  than two state-of-the-art MICP solvers.",
}


%complete
@inproceedings{TZB23-frocos,
  url       = "https://doi.org/10.1007/978-3-031-43369-6_9",
  author    = "Guilherme V. Toledo and Yoni Zohar and Clark Barrett",
  title     = "Combining Finite Combination Properties: Finite Models and Busy Beavers",
  booktitle = "Proceedings of the $14^{th}$ International Symposium on Frontiers of Combining Systems (FroCoS '23)",
  series    = "Lecture Notes in Artificial Intelligence",
  volume    = 14279,
  publisher = "Springer",
  editor    = "Uri Sattler and Martin Suda",
  pages     = "159--175",
  month     = sep,
  year      = 2023,
  doi       = "10.1007/978-3-031-43369-6_9",
  note      = "Prague, Czech Republic",
  category  = "Conference Publications",
  abstract  = "This work is a part of an ongoing effort to understand the
                  relationships between properties used in theory
                  combination. We here focus on including two properties that
                  are related to shiny theories: the finite model property and
                  stable finiteness. For any combination of properties, we
                  consider the question of whether there exists a theory that
                  exhibits it. When there is, we provide an example with the
                  simplest possible signature. One particular class of interest
                  includes theories with the finite model property that are not
                  finitely witnessable. To construct such theories, we utilize
                  the Busy Beaver function."
}

%complete
@inproceedings{EVZ+23,
  url       = "https://link.springer.com/chapter/10.1007/978-3-031-43369-6_3",
  author    = "Burak Ekici and Arjun Viswanathan and Yoni Zohar and Cesare Tinelli and Clark Barrett",
  title     = "Formal Verification of Bit-Vector Invertibility Conditions in Coq",
  booktitle = "Proceedings of the $14^{th}$ International Symposium on Frontiers of Combining Systems (FroCoS '23)",
  series    = "Lecture Notes in Artificial Intelligence",
  volume    = 14279,
  publisher = "Springer",
  editor    = "Uri Sattler and Martin Suda",
  pages     = "41--59",
  month     = sep,
  year      = 2023,
  doi       = "10.1007/978-3-031-43369-6_3",
  note      = "Prague, Czech Republic",
  category  = "Conference Publications",
  abstract  = "We prove the correctness of invertibility conditions for the
                  theory of fixed-width bit-vectors---used to solve quantified
                  bit-vector formulas in the Satisfiability Modulo Theories
                  (SMT) solver cvc5---in the Coq proof assistant. Previous work
                  proved many of these in a completely automatic fashion for
                  arbitrary bit-width; however, some were only proved for
                  bit-widths up to 65, even though they are being used to solve
                  formulas over larger bit-widths. In this paper we describe
                  the process of proving a representative subset of these
                  invertibility conditions in Coq. In particular, we describe
                  the BVList library for bit-vectors in Coq, our extensions to
                  it, and proofs of the invertibility conditions."
}

%complete
@inproceedings{CDZ+23,
  url       = "https://ieeexplore.ieee.org/document/10247903",
  author    = "Chattopadhyay, Saranyu and Devarajegowda, Keerthikumara and Zhao, Bihan and Lonsing, Florian and D'Agostino, Brandon A. and Vavelidou, Ioanna and Bhatt, Vijay D. and Prebeck, Sebastian and Ecker, Wolfgang and Trippel, Caroline and Barrett, Clark and Mitra, Subhasish",
  title     = "{G-QED}: Generalized {QED} Pre-silicon Verification beyond Non-Interfering Hardware Accelerators",
  booktitle = "Proceedings of the $60^{th}$ Design Automation Conference (DAC '23)",
  month     = jul,
  year      = 2023,
  publisher = "IEEE",
  doi       = "10.1109/DAC56929.2023.10247903",
  keywords  = "Productivity; Context; Design automation; Digital systems; Side-channel attacks; Energy efficiency; Timing; QED; Quick Error Detection; Accelerators; Processors; Functional consistency",
  note      = "San Francisco, CA",
  category  = "Conference Publications",
  abstract  = "Hardware accelerators (HAs) underpin high-performance and
                  energy-efficient digital systems. Correctness of these
                  systems thus depends on the correctness of constituent
                  HAs. Self-consistency-based pre-silicon verification
                  techniques, like A-QED (Accelerator Quick Error Detection),
                  provide a quick and provably thorough HA verification
                  framework that does not require extensive design-specific
                  properties or a full functional specification. However, A-QED
                  is limited to verifying HAs which are non-interfering -- i.e.,
                  they produce the same result for a given input independent of
                  its context within a sequence of inputs. We present a new
                  technique called G-QED (Generalized QED) which goes beyond
                  non-interfering HAs while retaining A-QED’s benefits. Our
                  extensive results as well as a detailed industrial case study
                  show that: G-QED is highly thorough in detecting critical
                  bugs in well-verified designs that otherwise escape
                  traditional verification flows while simultaneously improving
                  verification productivity 18-fold (from 370 person days to 21
                  person days). These results are backed by theoretical
                  guarantees of soundness and completeness.",
}

%complete
@inproceedings{MFD+23,
  url       = "https://doi.org/10.1145/3582016.3582070",
  author    = "Melchert, Jackson and Feng, Kathleen and Donovick, Caleb and Daly, Ross and Sharma, Ritvik and Barrett, Clark and Horowitz, Mark A. and Hanrahan, Pat and Raina, Priyanka",
  title     = "{APEX}: A Framework for Automated Processing Element Design Space Exploration using Frequent Subgraph Analysis",
  booktitle = "Proceedings of the $28^{th}$ {ACM} International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), Volume 3",
  pages     = "33--45",
  series    = "ASPLOS 2023",
  isbn      = "9781450399180",
  month     = mar,
  year      = 2023,
  publisher = "Association for Computing Machinery",
  address   = "New York, NY, USA",
  doi       = "10.1145/3582016.3582070",
  keywords = "subgraph, reconfigurable accelerators, processing elements, hardware-software co-design, graph analysis, domain-specific accelerators, design space exploration, CGRA",
  note      = "Vancouver, BC, Canada",
  category  = "Conference Publications",
  abstract  = "The architecture of a coarse-grained reconfigurable array (CGRA)
                  processing element (PE) has a significant effect on the
                  performance and energy-efficiency of an application running
                  on the CGRA. This paper presents APEX, an automated approach
                  for generating specialized PE architectures for an
                  application or an application domain. APEX first analyzes
                  application domain benchmarks using frequent subgraph mining
                  to extract commonly occurring computational subgraphs. APEX
                  then generates specialized PEs by merging subgraphs using a
                  datapath graph merging algorithm. The merged datapath graphs
                  are translated into a PE specification from which we
                  automatically generate the PE hardware description in Verilog
                  along with a compiler that maps applications to the PE. The
                  PE hardware and compiler are inserted into a flexible CGRA
                  generation and compilation toolchain that allows for agile
                  evaluation of CGRAs. We evaluate APEX for two domains,
                  machine learning and image processing. For image processing
                  applications, our automatically generated CGRAs with
                  specialized PEs achieve from 5\% to 30\% less area and from
                  22\% to 46\% less energy compared to a general-purpose
                  CGRA. For machine learning applications, our automatically
                  generated CGRAs consume 16\% to 59\% less energy and 22\% to
                  39\% less area than a general-purpose CGRA. This work paves
                  the way for creation of application domain-driven
                  design-space exploration frameworks that automatically
                  generate efficient programmable accelerators, with a much
                  lower design effort for both hardware and compiler
                  generation.",
}

%complete
@InProceedings{IZB+23,
  url       = "https://drops.dagstuhl.de/opus/volltexte/2023/19020/",
  author    = "Isac, Omri and Zohar, Yoni and Barrett, Clark and Katz, Guy",
  title     = "{DNN} Verification, Reachability, and the Exponential Function Problem",
  booktitle = "$34^{th}$ International Conference on Concurrency Theory (CONCUR '23)",
  pages     = "26:1--26:18",
  series    = "Leibniz International Proceedings in Informatics (LIPIcs)",
  ISBN      = "978-3-95977-299-0",
  ISSN      = "1868-8969",
  month     = sep,
  year      = 2023,
  volume    = 279,
  editor    = "P\'{e}rez, Guillermo A. and Raskin, Jean-Fran\c{c}ois",
  publisher = "Schloss Dagstuhl -- Leibniz-Zentrum f{\"u}r Informatik",
  address   = "Dagstuhl, Germany",
  doi       = "10.4230/LIPIcs.CONCUR.2023.26",
  note      = "Antwerp, Belgium",
  category  = "Conference Publications",
  abstract  = "Deep neural networks (DNNs) are increasingly being deployed to
                  perform safety-critical tasks. The opacity of DNNs, which
                  prevents humans from reasoning about them, presents new
                  safety and security challenges. To address these challenges,
                  the verification community has begun developing techniques
                  for rigorously analyzing DNNs, with numerous verification
                  algorithms proposed in recent years. While a significant
                  amount of work has gone into developing these verification
                  algorithms, little work has been devoted to rigorously
                  studying the computability and complexity of the underlying
                  theoretical problems. Here, we seek to contribute to the
                  bridging of this gap. We focus on two kinds of DNNs: those
                  that employ piecewise-linear activation functions (e.g.,
                  ReLU), and those that employ piecewise-smooth activation
                  functions (e.g., Sigmoids). We prove the two following
                  theorems: (i) the decidability of verifying DNNs with a
                  particular set of piecewise-smooth activation functions,
                  including Sigmoid and tanh, is equivalent to a well-known,
                  open problem formulated by Tarski; and (ii) the DNN
                  verification problem for any quantifier-free linear
                  arithmetic specification can be reduced to the DNN
                  reachability problem, whose approximation is
                  NP-complete. These results answer two fundamental questions
                  about the computability and complexity of DNN verification,
                  and the ways it is affected by the network’s activation
                  functions and error tolerance; and could help guide future
                  efforts in developing DNN verification tools.",
}

%complete
@inproceedings{OWB+23,
  url       = "https://link.springer.com/chapter/10.1007/978-3-031-37709-9_8",
  author    = "Ozdemir, Alex and Wahby, Riad S. and Brown, Fraser and Barrett, Clark",
  title     = "Bounded Verification for Finite-Field-Blasting",
  booktitle = "Proceedings of the $35^{th}$ International Conference on Computer Aided Verification (CAV '23)",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  volume    = 13965,
  pages     = "154--175",
  editor    = "Enea, Constantin and Lal, Akash",
  month     = jul,
  year      = 2023,
  note      = "Paris, France",
  doi       = "10.1007/978-3-031-37709-9_8",
  category  = "Conference Publications",
  abstract  = "Zero Knowledge Proofs (ZKPs) are cryptographic protocols by
                  which a prover convinces a verifier of the truth of a
                  statement without revealing any other information. Typically,
                  statements are expressed in a high-level language and then
                  compiled to a low-level representation on which the ZKP
                  operates. Thus, a bug in a ZKP compiler can compromise the
                  statement that the ZK proof is supposed to establish. This
                  paper takes a step towards ZKP compiler correctness by
                  partially verifying a field-blasting compiler pass, a pass
                  that translates Boolean and bit-vector logic into equivalent
                  operations in a finite field. First, we define correctness
                  for field-blasters and ZKP compilers more generally. Next, we
                  describe the specific field-blaster using a set of encoding
                  rules and define verification conditions for individual
                  rules. Finally, we connect the rules and the correctness
                  definition by showing that if our verification conditions
                  hold, the field-blaster is correct. We have implemented our
                  approach in the CirC ZKP compiler and have proved bounded
                  versions of the corresponding verification conditions. We
                  show that our partially verified field-blaster does not hurt
                  the performance of the compiler or its output; we also report
                  on four bugs uncovered during verification."
}

%complete
@inproceedings{OKT+23,
  url       = "https://link.springer.com/chapter/10.1007/978-3-031-37703-7_8",
  author    = "Ozdemir, Alex and Kremer, Gereon and Tinelli, Cesare and Barrett, Clark",
  title     = "Satisfiability Modulo Finite Fields",
  booktitle = "Proceedings of the $35^{th}$ International Conference on Computer Aided Verification (CAV '23)",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  volume    = 13965,
  pages     = "163--186",
  editor    = "Enea, Constantin and Lal, Akash",
  month     = jul,
  year      = 2023,
  note      = "Paris, France",
  doi       = "10.1007/978-3-031-37703-7_8",
  category  = "Conference Publications",
  abstract  = "We study satisfiability modulo the theory of finite fields and
                  give a decision procedure for this theory. We implement our
                  procedure for prime fields inside the cvc5 SMT solver. Using
                  this theory, we construct SMT queries that encode translation
                  validation for various zero knowledge proof compilers applied
                  to Boolean computations. We evaluate our procedure on these
                  benchmarks. Our experiments show that our implementation is
                  superior to previous approaches (which encode field
                  arithmetic using integers or bit-vectors)."
}

%complete
@inproceedings{TZB23-cade, 
  url       = "https://link.springer.com/chapter/10.1007/978-3-031-38499-8_30", 
  author    = "Toledo, Guilherme V. and Zohar, Yoni and Barrett, Clark",
  title     = "Combining Combination Properties: An Analysis of Stable Infiniteness, Convexity, and Politeness",
  booktitle = "Proceedings of the $29^{th}$ International Conference on Automated Deduction (CADE '23)",
  series    = "Lecture Notes in Artificial Intelligence",
  publisher = "Springer",
  volume    = 14132,
  editor    = "Pientka, Brigitte and Tinelli, Cesare",
  pages     = "522--541",
  month     = jul,
  year      = 2023,
  note      = "Rome, Italy",
  doi       = "10.1007/978-3-031-38499-8_30",
  category  = "Conference Publications",
  abstract  = "We make two contributions to the study of theory combination in
                  satisfiability modulo theories. The first is a table of
                  examples for the combinations of the most common
                  model-theoretic properties in theory combination, namely
                  stable infiniteness, smoothness, convexity, finite
                  witnessability, and strong finite witnessability (and
                  therefore politeness and strong politeness as well). All of
                  our examples are sharp, in the sense that we also offer
                  proofs that no theories are available within simpler
                  signatures. This table significantly progresses the current
                  understanding of the various properties and their
                  interactions. The most remarkable example in this table is of
                  a theory over a single sort that is polite but not strongly
                  polite (the existence of such a theory was only known until
                  now for two-sorted signatures). The second contribution is a
                  new combination theorem showing that in order to apply polite
                  theory combination, it is sufficient for one theory to be
                  stably infinite and strongly finitely witnessable, thus
                  showing that smoothness is not a critical property in this
                  combination method. This result has the potential to greatly
                  simplify the process of showing which theories can be used in
                  polite combination, as showing stable infiniteness is
                  considerably simpler than showing smoothness."
}

%complete
@InProceedings{WWW+23,
  url       = "https://proceedings.mlr.press/v206/wei23c.html",
  author    = "Wei, Dennis and Wu, Haoze and Wu, Min and Chen, Pin-Yu and Barrett, Clark and Farchi, Eitan",
  title     = "Convex Bounds on the Softmax Function with Applications to Robustness Verification",
  booktitle = "Proceedings of The $26^{th}$ International Conference on Artificial Intelligence and Statistics (AISTATS '23)",
  volume    = "206",
  series    = "Proceedings of Machine Learning Research",
  publisher = "PMLR",
  editor    = "Ruiz, Francisco and Dy, Jennifer and van de Meent, Jan-Willem",
  month     = apr,
  pages     = "6853--6878",
  year      = "2023",
  note      = "Valencia, Spain",
  category  = "Conference Publications",
  abstract  = "The softmax function is a ubiquitous component at the output of
                  neural networks and increasingly in intermediate layers as
                  well. This paper provides convex lower bounds and concave
                  upper bounds on the softmax function, which are compatible
                  with convex optimization formulations for characterizing
                  neural networks and other ML models. We derive bounds using
                  both a natural exponential-reciprocal decomposition of the
                  softmax as well as an alternative decomposition in terms of
                  the log-sum-exp function. The new bounds are provably and/or
                  numerically tighter than linear bounds obtained in previous
                  work on robustness verification of transformers. As
                  illustrations of the utility of the bounds, we apply them to
                  verification of transformers as well as of the robustness of
                  predictive uncertainty estimates of deep ensembles."
}

%complete
@inproceedings{CEB+23,
  url       = "https://easychair.org/publications/paper/q7L6",
  author    = "Elazar Cohen and Yizhak Yisrael Elboher and Clark Barrett and Guy Katz",
  title     = "Tighter Abstract Queries in Neural Network Verification",
  booktitle = "Proceedings of $24^{th}$ International Conference on Logic for Programming, Artificial Intelligence and Reasoning (LPAR '23)",
  series    = "EPiC Series in Computing",
  publisher = "EasyChair",
  volume    = 94,
  pages     = "124--143",
  editor    = "Ruzica Piskac and Andrei Voronkov",
  month     = mar,
  year      = 2023,
  note      = "Manizales, Columbia",
  doi       = "10.29007/3mk7",
  category  = "Conference Publications",
  abstract  = "Neural networks have become critical components of reactive
                  systems in various do- mains within computer science. Despite
                  their excellent performance, using neural networks entails
                  numerous risks that stem from our lack of ability to
                  understand and reason about their behavior. Due to these
                  risks, various formal methods have been proposed for verify-
                  ing neural networks; but unfortunately, these typically
                  struggle with scalability barriers. Recent attempts have
                  demonstrated that abstraction-refinement approaches could
                  play a significant role in mitigating these limitations; but
                  these approaches can often produce net- works that are so
                  abstract, that they become unsuitable for verification. To
                  deal with this issue, we present CEGARETTE, a novel
                  verification mechanism where both the system and the property
                  are abstracted and refined simultaneously. We observe that
                  this approach allows us to produce abstract networks which
                  are both small and sufficiently accurate, allowing for quick
                  verification times while avoiding a large number of
                  refinement steps. For evaluation purposes, we implemented
                  CEGARETTE as an extension to the recently proposed CEGAR-NN
                  framework. Our results are highly promising, and demonstrate
                  a significant improvement in performance over multiple
                  benchmarks.",
}

%complete
@inproceedings{BKR+23,
  url       = "https://easychair.org/publications/paper/lNvq",
  author    = "Haniel Barbosa and Chantal Keller and Andrew Reynolds and Arjun Viswanathan and Cesare Tinelli and Clark Barrett",
  title     = "An Interactive SMT Tactic in Coq using Abductive Reasoning",
  booktitle = "Proceedings of $24^{th}$ International Conference on Logic for Programming, Artificial Intelligence and Reasoning (LPAR '23)",
  series    = "EPiC Series in Computing",
  publisher = "EasyChair",
  volume    = 94,
  pages     = "11--22",
  editor    = "Ruzica Piskac and Andrei Voronkov",
  month     = mar,
  year      = 2023,
  note      = "Manizales, Columbia",
  doi       = "10.29007/432m",
  category  = "Conference Publications",
  abstract  = "A well-known challenge in leveraging automatic theorem provers,
                  such as satisfiability modulo theories (SMT) solvers, to
                  discharge proof obligations from interactive theorem provers
                  (ITPs) is determining which axioms to send to the solver
                  together with the con- jecture to be proven. Too many axioms
                  may confuse or clog the solver, while too few may make a
                  theorem unprovable. When a solver fails to prove a
                  conjecture, it is unclear to the user which case
                  transpired. In this paper we enhance SMTCoq --- an integration
                  between the Coq ITP and the cvc5 SMT solver --- with a tactic
                  called abduce aimed at mitigating the uncertainty above. When
                  the solver fails to prove the goal, the user may invoke
                  abduce which will use abductive reasoning to provide facts
                  that will allow the solver to prove the goal, if any."
}

%complete
@inproceedings{WTR+23,
  url       = "http://theory.stanford.edu/~barrett/pubs/WTR+23.pdf",
  author    = "Haoze Wu and Teruhiro Tagomori and Alexander Robey and Fengjun Yang and Nikolai Matni and George Pappas and Hamed Hassani and Corina P{\u{a}}s{\u{a}}reanu and Clark Barrett",
  title     = "Toward Certified Robustness Against Real-World Distribution Shifts",
  booktitle = "Proceedings of the 2023 IEEE Conference on Secure and Trustworthy Machine Learning (SaTML)",
  publisher = "IEEE",
  editor    = "Patrick McDaniel and Nicolas Papernot",
  month     = feb,
  pages     = "537--553",
  doi       = "10.1109/SaTML54575.2023.00042",
  year      = 2023,
  note      = "Raleigh, NC",
  category  = "Conference Publications",
  abstract  = "We consider the problem of certifying the robustness of deep
                  neural networks against real-world distribution shifts. To do
                  so, we bridge the gap between hand-crafted specifications and
                  realistic deployment settings by considering a
                  neural-symbolic verification framework in which generative
                  models are trained to learn perturbations from data and
                  specifications are defined with respect to the output of
                  these learned models. A pervasive challenge arising from this
                  setting is that although S-shaped activations (e.g., sigmoid,
                  tanh) are common in the last layer of deep generative models,
                  existing verifiers cannot tightly approximate S-shaped
                  activations. To address this challenge, we propose a general
                  meta-algorithm for handling S-shaped activations which
                  leverages classical notions of counter-example-guided
                  abstraction refinement. The key idea is to ``lazily'' refine
                  the abstraction of S-shaped functions to exclude spurious
                  counter-examples found in the previous abstraction, thus
                  guaranteeing progress in the verification process while
                  keeping the state-space small. For networks with sigmoid
                  activations, we show that our technique outperforms
                  state-of-the-art verifiers on certifying robustness against
                  both canonical adversarial perturbations and numerous
                  real-world distribution shifts. Furthermore, experiments on
                  the MNIST and CIFAR-10 datasets show that
                  distribution-shift-aware algorithms have significantly higher
                  certified robustness against distribution shifts.",
}

%complete
@inproceedings{OBK22,
  url       = "http://theory.stanford.edu/~barrett/pubs/OBK22.pdf",
  author    = "Matan Ostrovsky and Clark Barrett and Guy Katz",
  title     = "An Abstraction-Refinement Approach to Verifying Convolutional Neural Networks",
  booktitle = "Proceedings of the $20^{th}$ International Symposium on Automated Technology for Verification and Analysis (ATVA '22)",
  series    = "Lecture Notes in Computer Science",
  volume    = 13505,
  publisher = "Springer International Publishing",
  editor    = "Ahmed Bouajjani and Luk{\'a}{\v{s}} Hol{\'i}k and Zhilin Wu",
  pages     = "391--396",
  month     = oct,
  year      = 2022,
  doi       = "10.1007/978-3-031-19992-9_25",
  category  = "Conference Publications",
  abstract  = "Convolutional neural networks (CNNs) have achieved immense
                  popularity in areas like computer vision, image processing,
                  speech proccessing, and many others. Unfortunately, despite
                  their excellent performance, they are prone to producing
                  erroneous results---for example, minor perturbations to their
                  inputs can result in severe classification errors. In this
                  paper, we present the CNN-ABS framework, which implements an
                  abstraction-refinement based scheme for CNN
                  verification. Specifically, CNN-ABS simplifies the
                  verification problem through the removal of convolutional
                  connections in a way that soundly creates an
                  over-approximation of the original problem; it then
                  iteratively restores these connections if the resulting
                  problem becomes too abstract. CNN-ABS is designed to use
                  existing verification engines as a backend, and our
                  evaluation demonstrates that it can significantly boost the
                  performance of a state-of-the-art DNN verification engine,
                  reducing runtime by 15.7\% on average."
}

%complete
@inproceedings{DDM+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/DDM+22.pdf",
  author    = "Ross Daly and Caleb Donovick and Jackson Melchert and Rajsekhar Setaluri and Nestan Tsiskaridze and Priyanka Raina and Clark Barrett and Pat Hanrahan",
  title     = "Synthesizing Instruction Selection Rewrite Rules from {RTL} using {SMT}",
  booktitle = "Proceedings of the $22^{nd}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '22)",
  editor    = "Alberto Griggio and Neha Rungta",
  publisher = "TU Wien Academic Press",
  pages     = "139--150",
  month     = oct,
  year      = 2022,
  doi       = "10.34727/2022/isbn.978-3-85448-053-2_20",
  category  = "Conference Publications",
  abstract  = "Creating a compiler for an instruction set architecture (ISA)
                  requires a set of rewrite rules describing how to translate
                  from the compiler's intermediate representation (IR) to the
                  ISA. We address this challenge by synthesizing rewrite rules
                  from a register-transfer level (RTL) description of the
                  target architecture (with minimal annotations about its state
                  and the ISA format), together with formal IR semantics, by
                  constructing SMT queries where solutions represent valid
                  rewrite rules.  We evaluate our approach on multiple
                  architectures, supporting both integer and floating-point
                  operations. We synthesize both integer and floating-point
                  rewrite rules from an intermediate representation to various
                  reconfigurable array architectures in under 1.2 seconds per
                  rule. We also synthesize integer rewrite rules from
                  WebAssembly to RISC-V with both standard and custom
                  extensions in under 4 seconds per rule, and we synthesize
                  floating-point rewrite rules in under 8 seconds per rule."
}

%complete
@inproceedings{NBN+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/NBN+22.pdf",
  author    = "Andres N{\"o}tzli and Haniel Barbosa and Aina Niemetz and Mathias Preiner and Andrew Reynolds and Clark Barrett and Cesare Tinelli",
  title     = "Reconstructing Fine-Grained Proofs of Rewrites Using a Domain-Specific Language",
  booktitle = "Proceedings of the $22^{nd}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '22)",
  editor    = "Alberto Griggio and Neha Rungta",
  publisher = "TU Wien Academic Press",
  pages     = "65--74",
  month     = oct,
  year      = 2022,
  doi       = "10.34727/2022/isbn.978-3-85448-053-2_12",
  category  = "Conference Publications",
  abstract  = "Satisfiability modulo theories (SMT) solvers are widely used to
                  prove security and safety properties of computer systems. For
                  these applications, it is crucial that the result reported by
                  an SMT solver be correct. Recently, there has been a renewed
                  focus on producing independently checkable proofs in SMT
                  solvers, partly with the aim of addressing this risk.  These
                  proofs record the reasoning done by an SMT solver and are
                  ideally detailed enough to be easy to check. At the same
                  time, modern SMT solvers typically implement hundreds of
                  different term-rewriting rules in order to achieve
                  state-of-the-art performance. Generating detailed proofs for
                  applications of these rules is a challenge, because code
                  implementing rewrite rules can be large and
                  complex. Instrumenting this code to additionally produce
                  proofs makes it even more complex and makes it harder to add
                  new rewrite rules. We propose an alternative approach to the
                  direct instrumentation of the rewriting module of an SMT
                  solver. The approach uses a domain-specific language (DSL) to
                  describe a set of rewrite rules declaratively and then
                  reconstructs detailed proofs for specific rewrite steps on
                  demand based on those declarative descriptions."
}

%complete
@inproceedings{NCW+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/NCW+22.pdf",
  author    = "Abhishek Nair and Saranyu Chattopadhyay and Haoze Wu and Alex Ozdemir and Clark Barrett",
  title     = "Proof-Stitch: Proof Combination for Divide-and-Conquer {SAT} Solvers",
  booktitle = "Proceedings of the $22^{nd}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '22)",
  editor    = "Alberto Griggio and Neha Rungta",
  publisher = "TU Wien Academic Press",
  pages     = "84--88",
  month     = oct,
  year      = 2022,
  doi       = "10.34727/2022/isbn.978-3-85448-053-2_14",
  category  = "Conference Publications",
  abstract  = "With the increasing availability of parallel computing power,
                  there is a growing focus on parallelizing algorithms for
                  important automated reasoning problems such as Boolean
                  satisfiability (SAT). Divide-and-Conquer (D\&C) is a popular
                  parallel SAT solving paradigm that partitions SAT instances
                  into independent sub-problems which are then solved in
                  parallel.  For unsatisfiable instances, state-of-the-art D\&C
                  solvers generate DRAT refutations for each
                  sub-problem. However, they do not generate a single
                  refutation for the original instance. To close this gap, we
                  present Proof-Stitch, a procedure for combining refutations
                  of different sub-problems into a single refutation for the
                  original instance. We prove the correctness of the procedure
                  and propose optimizations to reduce the size and checking
                  time of the combined refutations by invoking existing
                  trimming tools in the proof-combination process. We also
                  provide an extensible implementation of the proposed
                  technique. Experiments on instances from last year's SAT
                  competition show that the optimized refutations are checkable
                  up to seven times faster than unoptimized refutations."
}

%complete
@inproceedings{ZWB+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/ZWB+22.pdf",
  author    = "Tom Zelazny and Haoze Wu and Clark Barrett and Guy Katz",
  title     = "On Optimizing Back-Substitution Methods for Neural Network Verification",
  booktitle = "Proceedings of the $22^{nd}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '22)",
  editor    = "Alberto Griggio and Neha Rungta",
  publisher = "TU Wien Academic Press",
  pages     = "17--26",
  month     = oct,
  year      = 2022,
  doi       = "10.34727/2022/isbn.978-3-85448-053-2_7",
  category  = "Conference Publications",
  abstract  = "With the increasing application of deep learning in
                  mission-critical systems, there is a growing need to obtain
                  formal guarantees about the behaviors of neural
                  networks. Indeed, many approaches for verifying neural
                  networks have been recently proposed, but these generally
                  struggle with limited scalability or insufficient accuracy. A
                  key component in many state-of-the-art verification schemes
                  is computing lower and upper bounds on the values that
                  neurons in the network can obtain for a specific input
                  domain---and the tighter these bounds, the more likely the
                  verification is to succeed. Many common algorithms for
                  computing these bounds are variations of the symbolic-bound
                  propagation method; and among these, approaches that utilize
                  a process called back-substitution are particularly
                  successful. In this paper, we present an approach for making
                  back-substitution produce tighter bounds. To achieve this, we
                  formulate and then minimize the imprecision errors incurred
                  during back-substitution. Our technique is general, in the
                  sense that it can be integrated into numerous existing
                  symbolic-bound propagation techniques, with only minor
                  modifications. We implement our approach as a
                  proof-of-concept tool, and present favorable results compared
                  to state-of-the-art verifiers that perform
                  back-substitution."
}

%complete
@inproceedings{IBZ+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/IBZ+22.pdf",
  author    = "Omri Isac and Clark Barrett and Min Zhang and Guy Katz",
  title     = "Neural Network Verification with Proof Production",
  booktitle = "Proceedings of the $22^{nd}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '22)",
  editor    = "Alberto Griggio and Neha Rungta",
  publisher = "TU Wien Academic Press",
  pages     = "38--48",
  month     = oct,
  year      = 2022,
  doi       = "10.34727/2022/isbn.978-3-85448-053-2_9",
  category  = "Conference Publications",
  abstract  = "Deep neural networks (DNNs) are increasingly being employed in
                  safety-critical systems, and there is an urgent need
                  to guarantee their correctness.  Consequently, the
                  verification community has devised multiple techniques and
                  tools for verifying DNNs.  When DNN verifiers discover an
                  input that triggers an error, that is easy to confirm; but
                  when they report that no error exists, there is no way to
                  ensure that the verification tool itself is not flawed.  As
                  multiple errors have already been observed in DNN verification
                  tools, this calls the applicability of DNN verification into
                  question.  In this work, we present a novel mechanism for
                  enhancing Simplex-based DNN verifiers with proof
                  production capabilities: the generation of an easy-to-check
                  witness of unsatisfiability, which attests to the absence
                  of errors. Our proof production is based on an efficient
                  adaptation of the well-known Farkas' lemma, combined with
                  mechanisms for handling piecewise-linear functions and
                  numerical precision errors. As a proof of concept, we
                  implemented our technique on top of the Marabou DNN verifier.
                  Our evaluation on a safety-critical system for airborne
                  collision avoidance shows that proof production succeeds in
                  almost all cases and requires only minimal overhead."
}

%complete
@inproceedings{SNR+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/SNR+22.pdf",
  author    = "Sheng, Ying and N{\"o}tzli, Andres and Reynolds, Andrew and Zohar, Yoni and Dill, David and Grieskamp, Wolfgang and Park, Junkil and Qadeer, Shaz and Barrett, Clark and Tinelli, Cesare",
  title     = "Reasoning About Vectors Using an SMT Theory of Sequences",
  booktitle = "Proceedings of the $11^{th}$ International Joint Conference on Automated Reasoning (IJCAR '22)",
  series    = "Lecture Notes in Computer Science",
  volume    = 13385,
  publisher = "Springer Nature",
  editor    = "Jasmin Blanchette and Laura Kov{\'a}cs and Dirk Pattinson",
  pages     = "125--143",
  month     = aug,
  year      = 2022,
  doi       = "10.1007/978-3-031-10769-6_7",
  category  = "Conference Publications",
  abstract  = "Dynamic arrays, also referred to as vectors, are fundamental data
                  structures used in many programs. Modeling their semantics
                  efficiently is crucial when reasoning about such
                  programs. The theory of arrays is widely supported but is not
                  ideal, because the number of elements is fixed (determined by
                  its index sort) and cannot be adjusted, which is a problem,
                  given that the length of vectors often plays an important
                  role when reasoning about vector programs. In this paper, we
                  propose reasoning about vectors using a theory of
                  sequences. We introduce the theory, propose a basic calculus
                  adapted from one for the theory of strings, and extend it to
                  efficiently handle common vector operations. We prove that
                  our calculus is sound and show how to construct a model when
                  it terminates with a saturated configuration. Finally, we
                  describe an implementation of the calculus in cvc5 and
                  demonstrate its efficacy by evaluating it on verification
                  conditions for smart contracts and benchmarks derived from
                  existing array benchmarks.",
}

%complete
@inproceedings{KRB+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/KRB+22.pdf",
  author    = "Gereon Kremer and Andrew Reynolds and Clark Barrett and Cesare Tinelli",
  title     = "Cooperating Techniques for Solving Nonlinear Real Arithmetic in the cvc5 SMT Solver (System Description)",
  booktitle = "Proceedings of the $11^{th}$ International Joint Conference on Automated Reasoning (IJCAR '22)",
  series    = "Lecture Notes in Computer Science",
  volume    = 13385,
  publisher = "Springer Nature",
  editor    = "Jasmin Blanchette and Laura Kov{\'a}cs and Dirk Pattinson",
  pages     = "95--105",
  month     = aug,
  year      = 2022,
  doi       = "10.1007/978-3-031-10769-6_7",
  category  = "Conference Publications",
  abstract  = "The cvc5 SMT solver solves quantifier-free nonlinear real arithmetic
                  problems by combining the cylindrical algebraic coverings
                  method with incremental linearization in an
                  abstraction-refinement loop. The result is a complete
                  algebraic decision procedure that leverages efficient
                  heuristics for refining candidate models. Furthermore, it can
                  be used with quantifiers, integer variables, and in
                  combination with other theories. We describe the overall
                  framework, individual solving techniques, and a number of
                  implementation details. We demonstrate its effectiveness with
                  an evaluation on the SMT-LIB benchmarks.",
}

%complete
@inproceedings{BRK+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/BRK+22.pdf",
  author    = "Haniel Barbosa and Andrew Reynolds and Gereon Kremer and Hanna Lachnitt and Aina Niemetz and Andres N{\"o}tzli and Alex Ozdemir and Mathias Preiner and Arjun Viswanathan and Scott Viteri and Yoni Zohar and Cesare Tinelli and Clark Barrett",
  title     = "Flexible Proof Production in an Industrial-Strength SMT Solver",
  booktitle = "Proceedings of the $11^{th}$ International Joint Conference on Automated Reasoning (IJCAR '22)",
  series    = "Lecture Notes in Computer Science",
  volume    = 13385,
  publisher = "Springer Nature",
  editor    = "Jasmin Blanchette and Laura Kov{\'a}cs and Dirk Pattinson",
  pages     = "15--35",
  month     = aug,
  year      = 2022,
  doi       = "10.1007/978-3-031-10769-6_3",
  category  = "Conference Publications",
  abstract  = "Proof production for SMT solvers is paramount to ensure their
                  correctness independently from implementations, which are
                  often prohibitively difficult to verify. Historically,
                  however, SMT proof production has struggled with performance
                  and coverage issues, resulting in the disabling of many
                  crucial solving techniques and in coarse-grained (and thus
                  hard to check) proofs. We present a flexible proof-production
                  architecture designed to handle the complexity of versatile,
                  industrial-strength SMT solvers and show how we leverage it
                  to produce detailed proofs, including for components
                  previously unsupported by any solver. The architecture allows
                  proofs to be produced modularly, lazily, and with numerous
                  safeguards for correctness. This architecture has been
                  implemented in the state-of-the-art SMT solver cvc5. We
                  evaluate its proofs for SMT-LIB benchmarks and show that the
                  new architecture produces better coverage than previous
                  approaches, has acceptable performance overhead, and supports
                  detailed proofs for most solving components.",
}

%complete
@inproceedings{NRB+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/NRB+22.pdf",
  author    = "Andres N{\"o}tzli and Andrew Reynolds and Haniel Barbosa and Clark Barrett and Cesare Tinelli",
  title     = "Even Faster Conflicts and Lazier Reductions for String Solvers",
  booktitle = "Proceedings of the $34^{th}$ International Conference on Computer Aided Verification (CAV '22)",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  volume    = 13372,
  pages     = "205--226",
  editor    = "Sharon Shoham and Yakir Vizel",
  month     = aug,
  year      = 2022,
  doi       = "10.1007/978-3-031-13188-2_11",
  category  = "Conference Publications",
  abstract  = "In the past decade, satisfiability modulo theories (SMT) solvers have
                  been extended to support the theory of strings and regular
                  expressions. This theory has proven to be useful in a wide
                  range of applications in academia and industry. To
                  accommodate the expressive nature of string constraints used
                  in those applications, string solvers use a multi-layered
                  architecture where extended operators are reduced to a set of
                  core operators. These reductions, however, are often costly
                  to reason about. In this work, we propose new techniques for
                  eagerly discovering conflicts based on equality reasoning and
                  lazily avoiding reductions for certain extended functions
                  based on lightweight reasoning. We present a strategy for
                  integrating and scheduling these techniques in a
                  CDCL(T)-based theory solver for strings
                  and regular expressions. We implement the techniques and the
                  strategy in cvc5, a state-of-the-art SMT solver, and show
                  that they lead to a significant performance improvement.",
}

%complete
@inproceedings{NPB22,
  url       = "http://theory.stanford.edu/~barrett/pubs/NPB22.pdf",
  author    = "Aina Niemetz and Mathias Preiner and Clark Barrett",
  title     = "Murxla: A Modular and Highly Extensible API Fuzzer for SMT Solvers",
  booktitle = "Proceedings of the $34^{th}$ International Conference on Computer Aided Verification (CAV '22)",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  volume    = 13372,
  pages     = "92--106",
  editor    = "Sharon Shoham and Yakir Vizel",
  month     = aug,
  year      = 2022,
  doi       = "10.1007/978-3-031-13188-2_5",
  category  = "Conference Publications",
  abstract  = "SMT solvers are highly complex pieces of software with
                  performance, robustness, and correctness as key
                  requirements. Complementing traditional testing techniques
                  for these solvers with randomized stress testing has been
                  shown to be quite effective. Recent work has showcased the
                  value of input fuzzing for finding issues, but this approach
                  typically does not comprehensively test a solver's
                  API. Previous work on model-based API fuzzing was tailored to
                  a single solver and a small subset of SMT-LIB. We present
                  Murxla, a comprehensive, modular, and highly extensible
                  model-based API fuzzer for SMT solvers. Murxla randomly
                  generates valid sequences of solver API calls based on a
                  customizable API model, with full support for the semantics
                  and features of SMT-LIB. It is solver-agnostic but extensible
                  to allow for solver-specific testing and supports option
                  fuzzing, cross-checking with other solvers, translation to
                  SMT-LIBv2, and SMT-LIBv2 input fuzzing. Our evaluation
                  confirms its efficacy in finding issues in multiple
                  state-of-the-art SMT solvers.",
}

%complete
@inproceedings{BBB+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/BBB+22.pdf",
  author    = "Haniel Barbosa and
               Clark W. Barrett and
               Martin Brain and
               Gereon Kremer and
               Hanna Lachnitt and
               Makai Mann and
               Abdalrhman Mohamed and
               Mudathir Mohamed and
               Aina Niemetz and
               Andres N{\"{o}}tzli and
               Alex Ozdemir and
               Mathias Preiner and
               Andrew Reynolds and
               Ying Sheng and
               Cesare Tinelli and
               Yoni Zohar",
  title     = "cvc5: {A} Versatile and Industrial-Strength {SMT} Solver",
  booktitle = "Proceedings of the $28^{th}$ International Conference on Tools
               and Algorithms for the Construction and Analysis of Systems
               (TACAS '22)",
  series    = "Lecture Notes in Computer Science",
  editor    = "Dana Fisman and Grigore Rosu",
  volume    = "13243",
  pages     = "415--442",
  publisher = "Springer",
  year      = "2022",
  month     = "apr",
  doi       = "10.1007/978-3-030-99524-9\_24",
  note      = "\em Best SCP Tool Paper Award.",
  category  = "Conference Publications",
  abstract  = "cvc5 is the latest SMT solver in the cooperating validity checker series
  and builds on the successful code base of CVC4.
  This paper serves as a comprehensive system description of cvc5's
  architectural design and highlights the major features and components
  introduced since CVC4 1.8.
  We evaluate cvc5's performance on all benchmarks in SMT-LIB and provide a
  comparison against CVC4 and Z3."
}

%complete
@inproceedings{WZK+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/WZK+22.pdf",
  author    = "Haoze Wu and Aleksandar Zelji{\'{c}} and Guy Katz and Clark Barrett",
  title     = "Efficient Neural Network Analysis with Sum-of-Infeasibilities",
  booktitle = "Proceedings of the $28^{th}$ International Conference on Tools
                  and Algorithms for the Construction and Analysis of Systems
                  (TACAS '22)",
  series    = "Lecture Notes in Computer Science",
  editor    = "Dana Fisman and Grigore Rosu",
  volume    = "13243",
  pages     = "143--163",
  publisher = "Springer",
  month     = apr,
  year      = 2022,
  doi       = "10.1007/978-3-030-99524-9\_24",
  category  = "Conference Publications",
  abstract  = "Inspired by sum-of-infeasibilities methods in convex
                  optimization, we propose a novel procedure for analyzing
                  verification queries on neural networks with piecewise-linear
                  activation functions.  Given a convex relaxation which
                  over-approximates the non-convex activation functions, we
                  encode the violations of activation functions as a cost
                  function and optimize it with respect to the convex
                  relaxation.  The cost function, referred to as the
                  Sum-of-Infeasibilities (SoI), is designed so that its
                  minimum is zero and achieved only if all the activation
                  functions are satisfied. We propose a stochastic procedure,
                  DeepSoI, to efficiently minimize the SoI. An extension to a
                  canonical case-analysis-based complete search procedure can
                  be achieved by replacing the convex procedure executed at
                  each search state with DeepSoI. Extending the complete search
                  with DeepSoI achieves multiple simultaneous goals: 1) it guides
                  the search towards a counter-example; 2) it enables more
                  informed branching decisions; and 3) it creates additional
                  opportunities for bound derivation.  An extensive evaluation
                  across different benchmarks and solvers demonstrates the
                  benefit of the proposed techniques. In particular, we
                  demonstrate that SoI significantly improves the performance
                  of an existing complete search procedure.  Moreover, the
                  SoI-based implementation outperforms other state-of-the-art
                  complete verifiers.  We also show that our technique can
                  efficiently improve upon the perturbation bound derived by a
                  recent adversarial attack algorithm."
}

%complete
@inproceedings{ZIM+22,
  url       = "http://theory.stanford.edu/~barrett/pubs/ZIM+22.pdf",
  author    = "Yoni Zohar and Ahmed Irfan and Makai Mann and Aina Niemetz and Andres N{\"o}tzli and Mathias Preiner and Andrew Reynolds and Clark Barrett and Cesare Tinelli",
  title     = "Bit-Precise Reasoning via Int-Blasting",
  booktitle = "Proceedings of the $23^{rd}$ International Conference on Verification, Model Checking, and Abstract Interpretion (VMCAI '22)",
  editor    = "Bernd Finkbeiner and Thomas Wies",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  volume    = "13182",
  pages     = "496--518",
  doi       = "10.1007/978-3-030-94583-1_24",
  month     = jan,
  year      = 2022,
  category  = "Conference Publications",
  abstract  = "The state of the art for bit-precise reasoning in the context of
                  Satisfiability Modulo Theories (SMT) is a SAT-based technique
                  called bit-blasting where the input formula is first
                  simplified and then translated to an equisatisfiable
                  propositional formula.  The main limitation of this technique
                  is scalability, especially in the presence of large
                  bit-widths and arithmetic operators.  We introduce an
                  alternative technique, which we call int-blasting,
                  based on a translation to an extension of integer arithmetic
                  rather than propositional logic.  We present several
                  translations, discuss their differences, and evaluate them on
                  benchmarks that arise from the verification of rewrite rule
                  candidates for bit-vector solving, as well as benchmarks from
                  SMT-LIB.  We also provide preliminary results on 35
                  benchmarks that arise from smart contract verification.  The
                  evaluation shows that this technique is particularly useful
                  for benchmarks with large bit-widths and can solve benchmarks
                  that the state of the art cannot."
}

%complete
@inproceedings{TSM+21,
  url       = "http://theory.stanford.edu/~barrett/pubs/TSM+21.pdf",
  author    = "Nestan Tsiskaridze and Maxwell Strange and Makai Mann and Kavya Sreedhar and Qiaoyi Liu and Mark Horowitz and Clark Barrett",
  title     = "Automating System Configuration",
  booktitle = "Proceedings of the $21^{st}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '21)",
  editor    = "Ruzica Piskac and Michael W. Whalen",
  publisher = "TU Wien Academic Press",
  pages     = "102--111",
  month     = oct,
  year      = 2021,
  doi       = "10.34727/2021/isbn.978-3-85448-046-4_19",
  category  = "Conference Publications",
  abstract  = "The increasing complexity of modern confgurable systems makes it
                  critical to improve the level of automation in the process of
                  system confguration. Such automation can also improve the
                  agility of the development cycle, allowing for rapid and
                  automated integration of decoupled workfows.  In this paper,
                  we present a new framework for automated confguration of
                  systems representable as state machines. The framework
                  leverages model checking and satisfability modulo theories
                  (SMT) and can be applied to any application domain
                  representable using SMT formulas. Our approach can also be
                  applied modularly, improving its scalability. Furthermore, we
                  show how optimization can be used to produce confgurations
                  that are best according to some metric and also more likely
                  to be understandable to humans. We showcase this framework
                  and its fexibility by using it to confgure a CGRA memory tile
                  for various image processing applications."
}

%complete
@inproceedings{CLP+21,
  url       = "http://theory.stanford.edu/~barrett/pubs/CLP+21.pdf",
  author    = "Chattopadhyay, Saranyu and Lonsing, Florian and Piccolboni, Luca and Soni, Deepraj and Wei, Peng and Zhang, Xiaofan and Zhou, Yuan and Carloni, Luca and Chen, Deming and Cong, Jason and Karri, Ramesh and Zhang, Zhiru and Trippel, Caroline and Barrett, Clark and Mitra, Subhasish",
  title     = "Scaling Up Hardware Accelerator Verification using {A-QED} with Functional Decomposition",
  booktitle = "Proceedings of the $21^{st}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '21)",
  editor    = "Ruzica Piskac and Michael W. Whalen",
  publisher = "TU Wien Academic Press",
  pages     = "42--52",
  month     = oct,
  year      = 2021,
  doi       = "10.34727/2021/isbn.978-3-85448-046-4_12",
  category  = "Conference Publications",
  abstract  = "Hardware accelerators (HAs) are essential building blocks for
                  fast and energy-efficient computing systems. Accelerator
                  Quick Error Detection (A-QED) is a recent formal technique
                  which uses Bounded Model Checking for pre-silicon
                  verification of HAs. A-QED checks an HA for self-consistency,
                  i.e., whether identical inputs within a sequence of
                  operations always produce the same output. Under modest
                  assumptions, A-QED is both sound and complete. However, as is
                  well-known, large design sizes significantly limit the
                  scalability of formal verification, including A-QED. We
                  overcome this scalability challenge through a new
                  decomposition technique for A-QED, called A-QED with
                  Decomposition (A-QED$^2$). A-QED$^2$ systematically decomposes an
                  HA into smaller, functional sub-modules, called
                  sub-accelerators, which are then verified independently using
                  A-QED. We prove completeness of A-QED$^2$ ; in particular, if
                  the full HA under verification contains a bug, then A-QED$^2$
                  ensures detection of that bug during A-QED verification of
                  the corresponding subaccelerators. Results on over 100
                  (buggy) versions of a wide variety of HAs with millions of
                  logic gates demonstrate the effectiveness and practicality of
                  A-QED$^2$."
}

%complete
@inproceedings{OWB21,
  url       = "http://theory.stanford.edu/~barrett/pubs/OWB21.pdf",
  author    = "Alex Ozdemir and Haoze Wu and Clark Barrett",
  title     = "{SAT} Solving in the Serverless Cloud",
  booktitle = "Proceedings of the $21^{st}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '21)",
  editor    = "Ruzica Piskac and Michael W. Whalen",
  publisher = "TU Wien Academic Press",
  pages     = "241--245",
  month     = oct,
  year      = 2021,
  doi       = "10.34727/2021/isbn.978-3-85448-046-4_33",
  category  = "Conference Publications",
  abstract  = {In recent years, cloud service providers have sold computation
                  in increasingly granular units. Most recently, "serverless"
                  executors run a single executable with restricted network
                  access and for a limited time. The beneft of these
                  restrictions is scale: thousand-way parallelism can be
                  allocated in seconds, and CPU time is billed with sub-second
                  granularity. To exploit these executors, we introduce gg-SAT:
                  an implementation of divide-and-conquer SAT
                  solving. Infrastructurally, gg-SAT departs substantially from
                  previous implementations: rather than handling process or
                  server management itself, gg-SAT builds on the gg framework,
                  allowing computations to be executed on a confgurable
                  backend, including serverless offerings such as AWS
                  Lambda. Our experiments suggest that when run on the same
                  hardware, gg-SAT performs competitively with other D&C
                  solvers, and that the 1000-way parallelism it offers (through
                  AWS Lambda) is useful for some challenging SAT instances.}
}

%complete
@inproceedings{PWG+21,
  url       = "http://theory.stanford.edu/~barrett/pubs/PWG+21.pdf",
  author    = "Colin Paterson and Haoze Wu and John Grese and Radu Calinescu and Corina S. P{\u{a}}s{\u{a}}reanu and Clark Barrett",
  title     = "DeepCert: Verification of Contextually Relevant Robustness for Neural Network Image Classifiers",
  booktitle = "Computer Safety, Reliability, and Security (SAFECOMP '21)",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer International Publishing",
  volume    = "12852",
  editor    = "Habli, Ibrahim and Sujan, Mark and Bitsch, Friedemann",
  pages     = "3--17",
  month     = sep,
  year      = 2021,
  doi       = "10.1007/978-3-030-83903-1_5",
  category  = "Conference Publications",
  abstract  = "We introduce DeepCert, a tool-supported method for verifying the
                  robustness of deep neural network (DNN) image classifiers to
                  contextually relevant perturbations such as blur, haze, and
                  changes in image contrast. While the robustness of DNN
                  classifiers has been the subject of intense research in
                  recent years, the solutions delivered by this research focus
                  on verifying DNN robustness to small perturbations in the
                  images being classified, with perturbation magnitude measured
                  using established L_p norms. This is
                  useful for identifying potential adversarial attacks on DNN
                  image classifiers, but cannot verify DNN robustness to
                  contextually relevant image perturbations, which are
                  typically not small when expressed with
                  L_p norms. DeepCert addresses this
                  underexplored verification problem by supporting: (1) the
                  encoding of real-world image perturbations; (2) the
                  systematic evaluation of contextually relevant DNN
                  robustness, using both testing and formal verification; (3)
                  the generation of contextually relevant counterexamples; and,
                  through these, (4) the selection of DNN image classifiers
                  suitable for the operational context (i) envisaged when a
                  potentially safety-critical system is designed, or (ii)
                  observed by a deployed system. We demonstrate the
                  effectiveness of DeepCert by showing how it can be used to
                  verify the robustness of DNN image classifiers build for two
                  benchmark datasets (`German Traffic Sign' and `CIFAR-10') to
                  multiple contextually relevant perturbations."
}

%complete
@inproceedings{MIL+21,
  url       = "http://theory.stanford.edu/~barrett/pubs/MIL+21.pdf",
  author    = "Makai Mann and Ahmed Irfan and Florian Lonsing and Yahan Yang
                  and Hongce Zhang and Kristopher Brown and Aarti Gupta and
                  Clark Barrett",
  title     = "Pono: A Flexible and Extensible {SMT}-based Model Checker",
  booktitle = "Proceedings of the $33^{rd}$ International Conference on Computer Aided Verification (CAV '21)",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer International Publishing",
  volume    = 12760,
  pages     = "461--474",
  editor    = "Rustan Leino and Alexandra Silva",
  month     = jul,
  year      = 2021,
  doi       = "10.1007/978-3-030-81688-9_22",
  category  = "Conference Publications",
  abstract  = "Symbolic model checking is an important tool for finding bugs
                  (or proving the absence of bugs) in modern system
                  designs. Because of this, improving the ease of use,
                  scalability, and performance of model checking tools and
                  algorithms continues to be an important research
                  direction. In service of this goal, we present Pono, an
                  open-source SMT-based model checker. Pono is designed to be
                  both a research platform for developing and improving model
                  checking algorithms, as well as a performance-competitive
                  tool that can be used for academic and industry verification
                  applications. In addition to performance, Pono prioritizes
                  transparency (developed as an open-source project on GitHub),
                  flexibility (Pono can be adapted to a variety of tasks by
                  exploiting its general SMT-based interface), and
                  extensibility (it is easy to add new algorithms and new
                  back-end solvers). In this paper, we describe the design of
                  the tool with a focus on the flexible and extensible
                  architecture, cover its current capabilities, and demonstrate
                  that Pono is competitive with state-of-the-art tools."
}

%complete
@inproceedings{SZR+21,
  url       = "http://theory.stanford.edu/~barrett/pubs/SZR+21.pdf",
  author    = "Ying Sheng and Yoni Zohar and Christophe Ringeissen and Andrew Reynolds and Clark Barrett and Cesare Tinelli",
  title     = "Politeness and Stable Infiniteness: Stronger Together",
  booktitle = "Proceedings of the $28^{th}$ International Conference on Automated Deduction (CADE '21)",
  series    = "Lecture Notes in Artificial Intelligence",
  publisher = "Springer",
  volume    = 12699,
  editor    = "Andr\'e Platzer and Geoff Sutcliffe",
  pages     = "148--165",
  month     = jul,
  year      = 2021,
  category  = "Conference Publications",
  abstract  = "We make two contributions to the study of polite combination
                  in satisfiability modulo theories. The first is a separation
                  between politeness and strong politeness, by presenting a
                  polite theory that is not strongly polite. This result shows
                  that proving strong politeness (which is often harder than
                  proving politeness) is sometimes needed in order to use
                  polite combination. The second contribution is an
                  optimization to the polite combination method, obtained by
                  borrowing from the Nelson-Oppen method. The Nelson-Oppen
                  method is based on guessing arrangements over shared
                  variables. In contrast, polite combination requires an
                  arrangement over all variables of the shared sorts. We show
                  that when using polite combination, if the other theory is
                  stably infinite with respect to a shared sort, only the
                  shared variables of that sort need be considered in
                  arrangements, as in the Nelson-Oppen method. The time
                  required to reason about arrangements is exponential in the
                  worst case, so reducing the number of variables considered
                  has the potential to improve performance significantly. We
                  show preliminary evidence for this by demonstrating a
                  speed-up on a smart contract verification benchmark."
}

%complete
@inproceedings{MWZ+21,
  url       = "http://theory.stanford.edu/~barrett/pubs/MWZ+21.pdf",
  author    = "Makai Mann and Amalee Wilson and Yoni Zohar and Lindsey Stuntz
                  and Ahmed Irfan and Kristopher Brown and Caleb Donovick and
                  Allison Guman and Cesare Tinelli and Clark Barrett",
  title     = "Smt-Switch: A Solver-Agnostic {C}++ {API} for {SMT} Solving",
  booktitle = "Proceedings of the $24^{th}$ International Conference on Theory and Applications of Satisfiability Testing (SAT '21)",
  series    = "Lecture Notes in Computer Science",
  volume    = 12831,
  publisher = "Springer",
  editor    = "Chu-Min Li and Felip Many\`a",
  pages     = "377--386",
  month     = jul,
  year      = 2021,
  note      = "Barcelona, Spain",
  doi       = "10.1007/978-3-030-80223-3_26",
  category  = "Conference Publications",
  abstract  = "This paper presents Smt-Switch, an open-source, solver-agnostic
                  API for SMT solving. Smt-Switch provides simple, uniform, and
                  high-performance access to SMT solving for applications in
                  areas such as automated reasoning, planning, and formal
                  verification. It defines an abstract interface, which can be
                  implemented by different SMT solvers. The interface allows
                  the user to create, traverse, and manipulate terms, as well
                  as dynamically dispatch queries to various underlying SMT
                  solvers."
}

%complete
@inproceedings{MIG+21,
  url       = "http://theory.stanford.edu/~barrett/pubs/MIG+21.pdf",
  author    = "Makai Mann and Ahmed Irfan and Alberto Griggio and Oded Padon
                  and Clark Barrett",
  title     = "Counterexample-Guided Prophecy for Model Checking Modulo the
                  Theory of Arrays",
  booktitle = "Proceedings of the $27^{th}$ International Conference on Tools
                  and Algorithms for the Construction and Analysis of Systems
                  (TACAS '21)",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  editor    = "Jan Friso Groote and Kim Guldstrand Larsen",
  volume    = 12651,
  pages     = "113--132",
  month     = mar,
  year      = 2021,
  doi       = "10.1007/978-3-030-72016-2",
  category  = "Conference Publications",
  abstract  = "We develop a framework for model checking infinite-state systems
                  by automatically augmenting them with auxiliary variables,
                  enabling quantifier-free induction proofs for systems that
                  would otherwise require quantified invariants. We combine
                  this mechanism with a counterexample-guided abstraction
                  refinement scheme for the theory of arrays. Our framework can
                  thus, in many cases, reduce inductive reasoning with
                  quantifiers and arrays to quantifier-free and array-free
                  reasoning. We evaluate the approach on a wide set of
                  benchmarks from the literature. The results show that our
                  implementation often outperforms state-of-the-art tools,
                  demonstrating its practical potential."
}

%complete
@inproceedings{NPR+21,
  url       = "http://theory.stanford.edu/~barrett/pubs/NPR+21.pdf",
  author    = "Aina Niemetz and Mathias Preiner and Andrew Reynolds and Clark
                  Barrett and Cesare Tinelli",
  title     = "Syntax-Guided Quantifier Instantiation",
  booktitle = "Proceedings of the $27^{th}$ International Conference on Tools
                  and Algorithms for the Construction and Analysis of Systems
                  (TACAS '21)",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  editor    = "Jan Friso Groote and Kim Guldstrand Larsen",
  volume    = 12652,
  pages     = "145--163",
  month     = mar,
  year      = 2021,
  doi       = "10.1007/978-3-030-72013-1",
  category  = "Conference Publications",
  abstract  = "This paper presents a novel approach for quantifier
                  instantiation in Satisfiability Modulo Theories (SMT) that
                  leverages syntax-guided synthesis (SyGuS) to choose
                  instantiation terms. It targets quantified constraints over
                  background theories such as (non)linear integer, reals and
                  floating-point arithmetic, bit-vectors, and their
                  combinations. Unlike previous approaches for quantifier
                  instantiation in these domains which rely on theory-specific
                  strategies, the new approach can be applied to any (combined)
                  theory, when provided with a grammar for instantiation terms
                  for all sorts in the theory. We implement syntax-guided
                  instantiation in the SMT solver CVC4, leveraging its support
                  for enumerative SyGuS. Our experiments demonstrate the
                  versatility of the approach, showing that it is competitive
                  with or exceeds the performance of state-of-the-art solvers
                  on a range of background theories."
}

%complete
@inproceedings{AWB+21,
  url       = "http://theory.stanford.edu/~barrett/pubs/AWB+21.pdf",
  author    = "Guy Amir and Haoze Wu and Clark Barrett and Guy Katz",
  title     = "An {SMT}-Based Approach for Verifying Binarized Neural Networks",
  booktitle = "Proceedings of the $27^{th}$ International Conference on Tools
                  and Algorithms for the Construction and Analysis of Systems
                  (TACAS '21)",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  editor    = "Jan Friso Groote and Kim Guldstrand Larsen",
  volume    = 12652,
  pages     = "203--222",
  month     = mar,
  year      = 2021,
  doi       = "10.1007/978-3-030-72013-1_11",
  category  = "Conference Publications",
  abstract  = "Deep learning has emerged as an effective approach for creating
                  modern software systems, with neural networks often
                  surpassing hand-crafted systems. Unfortunately, neural
                  networks are known to suffer from various safety and security
                  issues. Formal verification is a promising avenue for
                  tackling this difficulty, by formally certifying that
                  networks are correct. We propose an SMT-based technique for
                  verifying binarized neural networks---a popular kind of
                  neural network, where some weights have been binarized in
                  order to render the neural network more memory and energy
                  efficient, and quicker to evaluate. One novelty of our
                  technique is that it allows the verification of neural
                  networks that include both binarized and non-binarized
                  components. Neural network verification is computationally
                  very difficult, and so we propose here various optimizations,
                  integrated into our SMT procedure as deduction steps, as well
                  as an approach for parallelizing verification queries. We
                  implement our technique as an extension to the Marabou
                  framework, and use it to evaluate the approach on popular
                  binarized neural network architectures."
}

%complete
@inproceedings{IJW+20,
  url       = "http://theory.stanford.edu/~barrett/pubs/IJW+20.pdf",
  author    = "Ahmed Irfan and Kyle D. Julian and Haoze Wu and Clark Barrett and Mykel J. Kochenderfer and Baoluo Meng and James Lopez",
  title     = "Towards Verification of Neural Networks for Small Unmanned Aircraft Collision Avoidance",
  booktitle = "Proceedings of the $39^{th}$ Digital Avionics Systems Conference (DASC '20)",
  month     = oct,
  year      = 2020,
  doi       = "10.1109/DASC50938.2020.9256616",
  category  = "Conference Publications",
  abstract  = "The ACAS X family of aircraft collision avoidance systems uses
                  large numeric lookup tables to make decisions.  Recent work
                  used a deep neural network to approximate and compress a
                  collision avoidance table, and simulations showed that the
                  neural network performance was comparable to the original
                  table. Consequently, neural network representations are being
                  explored for use on small aircraft with limited storage
                  capacity.  However, the black-box nature of deep neural
                  networks raises safety concerns because simulation results
                  are not exhaustive.  This work takes steps towards addressing
                  these concerns by applying formal methods to analyze the
                  behavior of collision avoidance neural networks both in
                  isolation and in a closed-loop system. We evaluate our
                  approach on a specific set of collision avoidance networks
                  and show that even though the networks are not always locally
                  robust, their closed-loop behavior ensures that they will not
                  reach an unsafe (collision) state.",
}

%complete
@inproceedings{JBK20,
  url       = "http://theory.stanford.edu/~barrett/pubs/JBK20.pdf",
  author    = "Yuval Jacoby and Clark Barrett and Guy Katz",
  title     = "Verifying Recurrent Neural Networks Using Invariant Inference",
  booktitle = "Proceedings of the $18^{th}$ International Symposium on Automated Technology for Verification and Analysis (ATVA '20)",
  series    = "Lecture Notes in Computer Science",
  volume    = 12302,
  publisher = "Springer International Publishing",
  editor    = "Hung, Dang Van and Sokolsky, Oleg",
  pages     = "57--74",
  month     = oct,
  year      = 2020,
  doi       = "10.1007/978-3-030-59152-6_3",
  category  = "Conference Publications",
  abstract  = "Deep neural networks are revolutionizing the way complex systems
                  are developed. However, these automatically-generated
                  networks are opaque to humans, making it difficult to reason
                  about them and guarantee their correctness. Here, we propose
                  a novel approach for verifying properties of a widespread
                  variant of neural networks, called recurrent neural
                  networks. Recurrent neural networks play a key role in, e.g.,
                  speech recognition, and their verification is crucial for
                  guaranteeing the reliability of many critical systems. Our
                  approach is based on the inference of invariants, which allow
                  us to reduce the complex problem of verifying recurrent
                  networks into simpler, non-recurrent problems. Experiments
                  with a proof-of-concept implementation of our approach
                  demonstrate that it performs orders-of-magnitude better than
                  the state of the art."
}

%complete
@inproceedings{RNB+20-FMCAD,
  url       = "http://theory.stanford.edu/~barrett/pubs/RNB+20-FMCAD.pdf",
  author    = "Andrew Reynolds and Andres N{\"o}tzli and Clark Barrett and Cesare Tinelli",
  title     = "Reductions for Strings and Regular Expressions Revisited",
  booktitle = "Proceedings of the $20^{th}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '20)",
  editor    = "Alexander Ivrii and Ofer Strichman",
  publisher = "TU Wien Academic Press",
  pages     = "225--235",
  month     = sep,
  year      = 2020,
  doi       = "10.34727/2020/isbn.978-3-85448-042-6_30",
  category  = "Conference Publications",
  abstract  = "The theory of strings supported by solvers in formal methods
                  contains a large number of operators. Instead of implementing
                  a semi-decision procedure that reasons about all the
                  operators directly, string solvers often reduce operators to
                  a core fragment and implement a semi-decision procedure over
                  that fragment. These reductions considerably increase the
                  number of constraints and thus have to be done carefully to
                  achieve good performance. We propose novel reductions from
                  regular expressions to string constraints and a framework for
                  minimizing the introduction of new variables in current
                  reductions of string constraints. The reductions of regular
                  expression constraints enable string solvers to handle a
                  significant fragment of such constraints without using
                  dedicated reasoning over regular expressions. Minimizing the
                  number of variables in the reduced constraints makes those
                  constraints significantly cheaper to solve by the core
                  solver. An experimental evaluation of our implementation of
                  both techniques in CVC4, a state-of-the-art SMT solver with
                  extensive support for the theory of strings, shows that they
                  significantly improve the solver's performance."
}

%complete
@inproceedings{WOZ+20,
  url       = "http://theory.stanford.edu/~barrett/pubs/WOZ+20.pdf",
  author    = "Haoze Wu and Alex Ozdemir and Aleksandar Zelji{\'{c}} and Kyle Julian and Ahmed Irfan and Divya Gopinath and Sadjad Fouladi and Guy Katz and Corina Pasareanu and Clark Barrett",
  title     = "Parallelization Techniques for Verifying Neural Networks",
  booktitle = "Proceedings of the $20^{th}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '20)",
  editor    = "Alexander Ivrii and Ofer Strichman",
  publisher = "TU Wien Academic Press",
  pages     = "128--137",
  month     = sep,
  year      = 2020,
  doi       = "10.34727/2020/isbn.978-3-85448-042-6_20",
  category  = "Conference Publications",
  abstract  = "Inspired by recent successes of parallel techniques for solving
                  Boolean satisfiability, we investigate a set of strategies
                  and heuristics to leverage parallelism and improve the
                  scalability of neural network verification. We present a
                  general description of the Split-and-Conquer partitioning
                  algorithm, implemented within the Marabou framework, and
                  discuss its parameters and heuristic choices. In particular,
                  we explore two novel partitioning strategies, that partition
                  the input space or the phases of the neuron activations,
                  respectively. We introduce a branching heuristic and a
                  direction heuristic that are based on the notion of
                  polarity. We also introduce a highly parallelizable
                  pre-processing algorithm for simplifying neural network
                  verification problems.  An extensive experimental evaluation
                  shows the benefit of these techniques on both existing and
                  new benchmarks. A preliminary experiment ultra-scaling our
                  algorithm using a large distributed cloud-based platform also
                  shows promising results."
}

%complete
@inproceedings{LMB20,
  url       = "http://theory.stanford.edu/~barrett/pubs/LMB20.pdf",
  author    = "Florian Lonsing and Subhasish Mitra and Clark Barrett",
  title     = "A Theoretical Framework for Symbolic Quick Error Detection",
  booktitle = "Proceedings of the $20^{th}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '20)",
  editor    = "Alexander Ivrii and Ofer Strichman",
  publisher = "TU Wien Academic Press",
  pages     = "26--35",
  month     = sep,
  year      = 2020,
  doi       = "10.34727/2020/isbn.978-3-85448-042-6_9",
  category  = "Conference Publications",
  abstract  = "Symbolic quick error detection (SQED) is a formal pre-silicon
                  verification technique targeted at processor designs.  It
                  leverages bounded model checking (BMC) to check a design for
                  counterexamples to a self-consistency property: given the
                  instruction set architecture (ISA) of the design, executing
                  an instruction sequence twice on the same inputs must always
                  produce the same outputs. Self-consistency is a universal,
                  implementation-independent property. Consequently, in
                  contrast to traditional verification approaches that use
                  implementationspecific assertions (often generated manually),
                  SQED does not require a full formal design specification or
                  manually-written properties. Case studies have shown that
                  SQED is effective for commercial designs and that SQED
                  substantially improves design productivity. However, until
                  now there has been no formal characterization of its
                  bug-finding capabilities. We aim to close this gap by laying
                  a formal foundation for SQED. We use a transition-system
                  processor model and define the notion of a bug using an
                  abstract specification relation. We prove the soundness of
                  SQED, i.e., that any bug reported by SQED is in fact a real
                  bug in the processor. Importantly, this result holds
                  regardless of what the actual specification relation is. We
                  next describe conditions under which SQED is complete, that
                  is, what kinds of bugs it is guaranteed to find. We show that
                  for a large class of bugs, SQED can always find a trace
                  exhibiting the bug. Ultimately, we prove full completeness of
                  a variant of SQED that uses specialized state reset
                  instructions. Our results enable a rigorous understanding of
                  SQED and its bug-finding capabilities and give insights on
                  how to optimize implementations of SQED in practice."
}

%complete
@inproceedings{THS+20,
  url       = "http://theory.stanford.edu/~barrett/pubs/THS+20.pdf",
  author    = "Truong, Lenny and Herbst, Steven and Setaluri, Rajsekhar and Mann, Makai and Daly, Ross and Zhang, Keyi and Donovick, Caleb and Stanley, Daniel and Horowitz, Mark and Barrett, Clark and Hanrahan, Pat",
  title     = "fault: A Python Embedded Domain-Specific Language for Metaprogramming Portable Hardware Verification Components",
  booktitle = "Proceedings of the $32^{nd}$ International Conference on Computer Aided Verification (CAV '20)",
  series    = "Lecture Notes in Computer Science",
  volume    = 12224,
  publisher = "Springer International Publishing",
  editor    = "Shuvendu K. Lahiri and Chao Wang",
  pages     = "403--414",
  month     = jul,
  year      = 2020,
  isbn      = "978-3-030-53288-8",
  category  = "Conference Publications",
  abstract  = "While hardware generators have drastically improved design
                  productivity, they have introduced new challenges for the
                  task of verification. To effectively cover the functionality
                  of a sophisticated generator, verification engineers require
                  tools that provide the flexibility of
                  metaprogramming. However, flexibility alone is not enough;
                  components must also be portable in order to encourage the
                  proliferation of verification libraries as well as enable new
                  methodologies. This paper introduces fault, a Python embedded
                  hardware verification language that aims to empower design
                  teams to realize the full potential of generators.",
}

%complete
@inproceedings{ZCQ+20,
  url       = "http://theory.stanford.edu/~barrett/pubs/ZCQ+20.pdf",
  author    = "Jingyi Emma Zhong and Kevin Cheang and Shaz Qadeer and Wolfgang Grieskamp and Sam Blackshear and Junkil Park and Yoni Zohar and Clark Barrett and David L. Dill",
  title     = "The Move Prover",
  booktitle = "Proceedings of the $32^{nd}$ International Conference on Computer Aided Verification (CAV '20)",
  series    = "Lecture Notes in Computer Science",
  volume    = 12224,
  publisher = "Springer International Publishing",
  editor    = "Shuvendu K. Lahiri and Chao Wang",
  pages     = "137--150",
  month     = jul,
  year      = 2020,
  isbn      = "978-3-030-53288-8",
  category  = "Conference Publications",
  abstract  = "The Libra blockchain is designed to store billions of dollars in
                  assets, so the security of code that executes transactions is
                  important. The Libra blockchain has a new language for
                  implementing transactions, called ``Move.'' This paper
                  describes the Move Prover, an automatic formal verification
                  system for Move. We overview the unique features of the Move
                  language and then describe the architecture of the Prover,
                  including the language for formal specification and the
                  translation to the Boogie intermediate verification
                  language.",
}

%complete
@inproceedings{BBB+20,
  url       = "http://theory.stanford.edu/~barrett/pubs/BBB+20.pdf",
  author    = "R. {Bahr} and C. {Barrett} and N. {Bhagdikar} and A. {Carsello} and R. {Daly} and C. {Donovick} and D. {Durst} and K. {Fatahalian} and K. {Feng} and P. {Hanrahan} and T. {Hofstee} and M. {Horowitz} and D. {Huff} and F. {Kjolstad} and T. {Kong} and Q. {Liu} and M. {Mann} and J. {Melchert} and A. {Nayak} and A. {Niemetz} and G. {Nyengele} and P. {Raina} and S. {Richardson} and R. {Setaluri} and J. {Setter} and K. {Sreedhar} and M. {Strange} and J. {Thomas} and C. {Torng} and L. {Truong} and N. {Tsiskaridze} and K. {Zhang}",
  title     = "Creating an Agile Hardware Design Flow",
  booktitle = "Proceedings of the $57^{th}$ Design Automation Conference (DAC '20)",
  publisher = "Association for Computing Machinery",
  month     = jul,
  doi       = "10.1109/DAC18072.2020.9218553",
  year      = 2020,
  category  = "Conference Publications",
  abstract  = "Although an agile approach is standard for software design, how
                  to properly adapt this method to hardware is still an open
                  question. This work addresses this question while building a
                  system on chip (SoC) with specialized accelerators. Rather
                  than using a traditional waterfall design flow, which starts
                  by studying the application to be accelerated, we begin by
                  constructing a complete flow from an application expressed in
                  a high-level domain-specific language (DSL), in our case
                  Halide, to a generic coarse-grained reconfigurable array
                  (CGRA). As our under-standing of the application grows, the
                  CGRA design evolves, and we have developed a suite of tools
                  that tune application code, the compiler, and the CGRA to
                  increase the efficiency of the resulting implementation. To
                  meet our continued need to update parts of the system while
                  maintaining the end-to-end flow, we have created DSL-based
                  hardware generators that not only provide the Verilog needed
                  for the implementation of the CGRA, but also create the
                  collateral that the compiler/mapper/place and route system
                  needs to configure its operation. This work provides a
                  systematic approach for desiging and evolving
                  high-performance and energy-efficient hardware-software
                  systems for any application domain."
}

%complete
@inproceedings{SLC+20,
  url       = "http://theory.stanford.edu/~barrett/pubs/SLC+20.pdf",
  author    = "Eshan Singh and Florian Lonsing and Saranyu Chattopadhyay and Max Strange and Peng Wei and Xiaofan Zhang and Yuan Zhao and Jason Cong and Deming Chen and Zhiru Zhang and Priyankja Raina and Clark Barrett and Subhasish Mitra",
  title     = "{A-QED} Verification of Hardware Accelerators",
  booktitle = "Proceedings of the $57^{th}$ Design Automation Conference (DAC '20)",
  publisher = "Association for Computing Machinery",
  month     = jul,
  doi       = "10.1109/DAC18072.2020.9218715",
  year      = 2020,
  category  = "Conference Publications",
  abstract  = "We present A-QED (Accelerator-Quick Error Detection), a new
                  approach for pre-silicon formal verification of stand-alone
                  hardware accelerators. A-QED relies on bounded model checking
                  -- however, it does not require extensive design-specific
                  properties or a full formal design specification. While A-
                  QED is effective for both RTL and high-level synthesis (HLS)
                  design flows, it integrates seamlessly with HLS flows. Our
                  A-QED results on several hardware accelerator designs
                  demonstrate its practicality and effectiveness: 1. A-QED
                  detected all bugs detected by conventional verification
                  flow. 2. A-QED detected bugs that escaped conventional
                  verification flow. 3. A-QED improved verification
                  productivity dramatically, by 30X, in one of our case studies
                  (1 person-day using A-QED vs. 30 person-days using
                  conventional verification flow). 4. A-QED produced short
                  counterexamples for easy debug (37X shorter on average
                  vs. conventional verification flow)."
}

%complete
@inproceedings{SZR+20,
  url       = "http://theory.stanford.edu/~barrett/pubs/SZR+20.pdf",
  author    = "Ying Sheng and Yoni Zohar and Christophe Ringeissen and Jane Lange and Pascal Fontaine and Clark Barrett",
  title     = "Politeness for the Theory of Algebraic Datatypes",
  booktitle = "Proceedings of the $10^{th}$ International Joint Conference on Automated Reasoning (IJCAR '20)",
  series    = "Lecture Notes in Computer Science",
  volume    = 12166,
  publisher = "Springer International Publishing",
  editor    = "Peltier, Nicolas and Sofronie-Stokkermans, Viorica",
  pages     = "238--255",
  month     = jul,
  year      = 2020,
  note      = "{\em Best paper award.}",
  isbn      = "978-3-030-51074-9",
  category  = "Conference Publications",
  abstract  = "Algebraic datatypes, and among them lists and trees, have
                  attracted a lot of interest in automated reasoning and
                  Satisfiability Modulo Theories (SMT). Since its latest stable
                  version, the SMT-LIB standard defines a theory of algebraic
                  datatypes, which is currently supported by several mainstream
                  SMT solvers. In this paper, we study this particular theory
                  of datatypes and prove that it is strongly polite, showing
                  also how it can be combined with other arbitrary disjoint
                  theories using polite combination. Our results cover both
                  inductive and finite datatypes, as well as their union. The
                  combination method uses a new, simple, and natural notion of
                  additivity, that enables deducing strong politeness from
                  (weak) politeness.",
}

%complete
@inproceedings{RNB+20-IJCAR,
  url       = "http://theory.stanford.edu/~barrett/pubs/RNB+20-IJCAR.pdf",
  author    = "Reynolds, Andrew and N{\"o}tzli, Andres and Barrett, Clark and Tinelli, Cesare",
  title     = "A Decision Procedure for String to Code Point Conversion",
  booktitle = "Proceedings of the $9^{th}$ International Joint Conference on Automated Reasoning (IJCAR '20)",
  series    = "Lecture Notes in Computer Science",
  volume    = 12166,
  publisher = "Springer International Publishing",
  editor    = "Peltier, Nicolas and Sofronie-Stokkermans, Viorica",
  pages     = "218--237",
  month     = jul,
  year      = 2020,
  isbn      = "978-3-030-51074-9",
  category  = "Conference Publications",
  abstract  = "In text encoding standards such as Unicode, text strings are
                  sequences of code points, each of which can be represented as
                  a natural number. We present a decision procedure for a
                  concatenation-free theory of strings that includes length and
                  a conversion function from strings to integer code
                  points. Furthermore, we show how many common string
                  operations, such as conversions between lowercase and
                  uppercase, can be naturally encoded using this conversion
                  function. We describe our implementation of this approach in
                  the SMT solver CVC4, which contains a high-performance string
                  subsolver, and show that the use of a native procedure for
                  code points significantly improves its performance with
                  respect to other state-of-the-art string solvers.",
}

%complete
@inproceedings{GFM+20,
   url       = "http://theory.stanford.edu/~barrett/pubs/GFM+20.pdf",
   author    = "Sumathi Gokulanathan and Alexander Feldsher and Adi Malca and Clark Barrett and Guy Katz",
   title     = "Simplifying Neural Networks using Formal Verification",
   booktitle = "{NASA} Formal Methods: 12th International Symposium, (NFM '20)",
   series    = "Lecture Notes in Computer Science",
   editor    = "Lee, Ritchie and Jha, Susmit and Mavridou, Anastasia",
   publisher = "Springer",
   month     = may,
   pages     = "85--93",
   isbn      = "978-3-030-55754-6",
   year      = 2020,
   note      = "Moffet Field, California",
   category  = "Conference Publications",
   abstract  = "Deep neural network (DNN) verification is an emerging field,
                  with diverse verification engines quickly becoming
                  available. Demonstrating the effectiveness of these engines
                  on real-world DNNs is an important step towards their wider
                  adoption. We present a tool that can leverage existing
                  verification engines in performing a novel application:
                  neural network simplification, through the reduction of the
                  size of a DNN without harming its accuracy. We report on the
                  work-flow of the simplification process, and demonstrate its
                  potential significance and applicability on a family of
                  real-world DNNs for aircraft collision avoidance, whose sizes
                  we were able to reduce by as much as 10{\%}."
}

%complete
@inproceedings{MB20,
  url       = "http://theory.stanford.edu/~barrett/pubs/MB20.pdf",
  author    = "Makai Mann and Clark Barrett",
  title     = "Partial Order Reduction for Deep Bug Finding in Synchronous Hardware",
  booktitle = "Proceedings of the $26^{th}$ International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS '20)",
  series    = "Lecture Notes in Computer Science",
  volume    = 12078,
  publisher = "Springer",
  month     = apr,
  year      = 2020,
  editor    = "Biere, Armin and Parker, David",
  pages     = "367--386",
  isbn      = "978-3-030-45190-5",
  category  = "Conference Publications",
  abstract  = "Symbolic model checking has become an important part of the
                  verification flow in industrial hardware design. However, its
                  use is still limited due to scaling issues. One way to
                  address this is to exploit the large amounts of symmetry
                  present in many real world designs. In this paper, we adapt
                  partial order reduction for bounded model checking of
                  synchronous hardware and introduce a novel technique that
                  makes partial order reduction practical in this new
                  domain. These approaches are largely automatic, requiring
                  only minimal manual effort. We evaluate our technique on
                  open-source and commercial packet mover circuits - designs
                  containing FIFOs and arbiters."
}

%complete
@inproceedings{DFS+20,
  url       = "http://theory.stanford.edu/~barrett/pubs/DFS+20.pdf",
  author    = "Keerthikumara Devarajegowda and Mohammad Rahmani Fadiheh and Eshan Singh and Clark Barrett and Subhasish Mitra and Wolfgang Ecker and Dominik Stoffel and Wolfgang Kunz",
  title     = "Gap-Free Processor Verification by {S}$^2${QED} and Property Generation",
  booktitle = "Proceedings of the 2020 Design, Automation and Test in Europe (DATE '20)",
  publisher = "IEEE",
  month     = mar,
  pages     = "526--531",
  doi       = "10.23919/DATE48585.2020.9116515",
  year      = 2020,
  note      = "Grenoble, France",
  category  = "Conference Publications",
  abstract  = "The required manual effort and verification expertise are among
                  the main hurdles for adopting formal verification in
                  processor design flows. Developing a set of properties that
                  fully covers all instruction behaviors is a laborious and
                  challenging task. This paper proposes a highly automated and
                  ``complete'' processor verification approach which requires
                  considerably less manual effort and expertise compared to the
                  state of the art. The proposed approach extends the S$^2$QED
                  approach to cover both single and multiple instruction bugs
                  and ensures that a design is completely verified according to
                  a well-defined criterion. This makes the approach robust
                  against human errors. The properties are simple and can be
                  automatically generated from an ISA model with small manual
                  effort. Furthermore, unlike in conventional property
                  checking, the verification engineer does not need to
                  explicitly specify the processor's behavior in different
                  special scenarios, such as stalling, exception, or
                  speculation, since these are taken care of implicitly by the
                  proposed computational model. The great promise of the
                  approach is shown by an industrial case study with a 5-stage
                  RISC-V processor",
}

%complete
@inproceedings{DMB+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/DMB+19.pdf",
  author    = "Caleb Donovick and Makai Mann and Clark Barrett and Pat Hanrahan",
  title     = "Agile {SMT}-Based Mapping for {CGRA}s with Restricted Routing Networks",
  booktitle = "Proceedings of the International Conference on ReConFigurable Computing and FPGAs (ReConFig '19)",
  publisher = "IEEE",
  editor    = "David Andrews and Ren\'{e} Cumplido and Claudia Feregrino and Marco Platzner",
  month     = dec,
  year      = 2019,
  note      = "Cancun, Mexico",
  doi       = "10.1109/ReConFig48160.2019.8994781",
  category  = "Conference Publications",
  abstract  = "Coarse-grained reconfigurable architectures (CGRAs) are becoming
                  popular accelerators for computationally intensive
                  tasks. CGRAs offer the reconfigurability of an FPGA, but with
                  larger configurable blocks which provide performance closer
                  to ASICs. CGRAs can achieve very high compute density if the
                  routing networks are restricted; however, mapping using
                  traditional annealing-based approaches does not perform well
                  for such architectures. This paper uses Satisfiability Modulo
                  Theories (SMT) solvers to rapidly map designs onto arbitrary
                  CGRA fabrics. This approach is sound, complete, and in many
                  cases an order of magnitude faster than state-of-the-art
                  constraint-based mapping techniques using integer linear
                  programming (ILP). Additionally, we propose a functional
                  duplication strategy that decreases pressure on the routing
                  network from high-fanout operations, leading to significant
                  performance improvements."
}

%complete
@inproceedings{YWB+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/YWB+19.pdf",
  author    = "Jiaxuan You and Haoze Wu and Clark Barrett and Raghuram Ramanujan and Jure Leskovec",
  title     = "{G2SAT}: Learning to Generate {SAT} Formulas",
  booktitle = "Advances in Neural Information Processing Systems 32 (NeurIPS '19)",
  publisher = "Curran Associates, Inc.",
  editor    = "H. Wallach and H. Larochelle and A. Beygelzimer and F. d'Alch\'{e}-Buc and E. Fox and R. Garnett",
  pages     = "10552--10563",
  month     = dec,
  year      = 2019,
  note      = "Vancouver, Canada",
  category  = "Conference Publications",
  abstract  = "The Boolean Satisfiability (SAT) problem is the canonical
                  NP-complete problem and is fundamental to computer science,
                  with a wide array of applications in planning, verification,
                  and theorem proving. Developing and evaluating practical SAT
                  solvers relies on extensive empirical testing on a set of
                  real-world benchmark formulas. However, the availability of
                  such real-world SAT formulas is limited. While these
                  benchmark formulas can be augmented with synthetically
                  generated ones, existing approaches for doing so are heavily
                  hand-crafted and fail to simultaneously capture a wide range
                  of characteristics exhibited by real-world SAT instances. In
                  this work, we present G2SAT, the first deep generative
                  framework that learns to generate SAT formulas from a given
                  set of input formulas. Our key insight is that SAT formulas
                  can be transformed into latent bipartite graph
                  representations which we model using a specialized deep
                  generative neural network. We show that G2SAT can generate
                  SAT formulas that closely resemble given real-world SAT
                  instances, as measured by both graph metrics and SAT solver
                  behavior. Further, we show that our synthetic SAT formulas
                  could be used to improve SAT solver performance on real-world
                  benchmarks, which opens up new opportunities for the
                  continued development of SAT solvers and a deeper
                  understanding of their performance."
}

%complete
@inproceedings{LGM+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/LGM+19.pdf",
  author    = "Florian Lonsing and Karthik Ganesan and Makai Mann and Srinivasa Shashank Nuthakki and Eshan Singh and Mario Srouji and Yahan Yang and Subhasish Mitra and Clark Barrett",
  title     = "Unlocking the Power of Formal Hardware Verification with {CoSA} and Symbolic {QED}: Invited Paper",
  booktitle = "Proceedings of the International Conference on Computer-Aided Design (ICCAD '19)",
  publisher = "IEEE",
  editor    = "David Pan",
  month     = nov,
  year      = 2019,
  note      = "Westminster, Colorado",
  doi       = "10.1109/ICCAD45719.2019.8942096",
  category  = "Conference Publications",
  abstract  = "As designs grow in size and complexity, design verification
                  becomes one of the most difficult and costly tasks facing
                  design teams. Formal verification techniques offer great
                  promise because of their ability to exhaustively explore
                  design behaviors. However, formal techniques also have a
                  reputation for being labor-intensive and limited to small
                  blocks. Is there any hope for successful application of
                  formal techniques at design scale? We answer this question
                  affirmatively by digging deeper to understand what the real
                  technological issues and opportunities are. First, we look at
                  satisfiability solvers, the engines underlying formal
                  techniques such as model checking. Given the recent
                  innovations in satisfiability solving, we argue that there
                  are many reasons to be optimistic that formal techniques will
                  scale to designs of practical interest. We use our CoSA model
                  checker as a demonstration platform to illustrate how
                  advances in solvers can improve scalability. However, even if
                  solvers become blazingly fast, applying them well is still
                  labor-intensive. This is because formal tools are only as
                  useful as the properties they are given to prove, which
                  traditionally have required great effort to develop. Symbolic
                  quick error detection (SQED) addresses this issue by using a
                  single, universal property that checks designs
                  automatically. We demonstrate how SQED can automatically find
                  logic bugs in a variety of designs and report on bugs found
                  and efficiency gains realized in academic and industry
                  designs. We also present a generator for an improved SQED
                  module that further reduces the amount of manual effort that
                  has to be spent by the designer."
}

%complete
@inproceedings{LRM+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/LRM+19.pdf",
  author    = "J. G. {Lopez} and L. {Ren} and B. {Meng} and R. {Fisher} and J. {Markham} and M. {Figard} and R. {Evans} and R. {Evans} and R. {Spoelhof} and M. {Rubenstahl} and S. {Edwards} and I. {Pedan} and C. {Barrett}",
  booktitle = "Proceedings of the $38^{th}$ Digital Avionics Systems Conference (DASC '19)",
  title     = "Integration and Flight Test of Small {UAS} Detect and Avoid on A Miniaturized Avionics Platform",
  month     = sep,
  year      = 2019,
  doi       = "10.1109/DASC43569.2019.9081780",
  category  = "Conference Publications",
  abstract  = "Detect and avoid (DAA) all other aircraft is a critical
                  component to enable small unmanned aircraft system (sUAS)
                  beyond visual line of sight (BVLOS) operations. Derived from
                  the version of Airborne Collision Avoidance System X (ACAS X)
                  for large UAS (ACAS Xu), a new member of the ACAS X family
                  for sUAS (ACAS sXu) is being developed by the Federal
                  Aviation Administration's (FAA's) Traffic-Alert and Collision
                  Avoidance System (TCAS) Program Office. ACAS sXu is intended
                  to provide both collision avoidance (CA) and remain well
                  clear (RWC) capabilities with both vertical and horizontal
                  advisories for the remote pilot in command (RPIC) and/or
                  automated response system onboard the aircraft. ACAS sXu is
                  envisioned to utilize a standard logic to serve sUASs with
                  different equipages and operating in different airspace
                  domains. The standard ACAS sXu logic may be hosted either in
                  the embedded environment on board the sUAS vehicle or in a
                  Cloud environment such as a UAS traffic management (UTM)
                  Service Suppler (USS) platform. It may be integrated with
                  surveillance sources such as Automatic Dependent
                  Surveillance-Broadcast (ADS-B), the anticipated remote
                  identification (remote ID) tracking, networked/shared
                  telemetry, airborne surveillance radar, and ground based
                  surveillance radar, for both cooperative and non-cooperative
                  intruders. To demonstrate proof of concept, gather
                  surveillance data, verify simulation environment, and
                  characterize early logic performance, the FAA and industry
                  partners integrated DAA systems featuring the ACAS sXu logic
                  Version 0, in both embedded environments and a Cloud
                  environment, and successfully conducted a week-long flight
                  test in October 2018 at the New York UAS Test Site in Rome,
                  NY. This paper presents the integration of the sUAS DAA on a
                  miniaturized avionics platform and flight test with a
                  fixed-wing sUAS platform."
}

%complete
@inproceedings{NPR+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/NPR+19.pdf",
  author    = "Aina Niemetz and Mathias Preiner and Andrew Reynolds and Yoni Zohar and Clark Barrett and Cesare Tinelli",
  title     = "Towards Bit-Width-Independent Proofs in SMT Solvers",
  booktitle = "Proceedings of the $27^{th}$ International Conference on Automated Deduction (CADE '19)",
  series    = "Lecture Notes in Artificial Intelligence",
  volume    = 11716,
  publisher = "Springer",
  editor    = "Pascal Fontaine",
  pages     = "366--384",
  month     = aug,
  year      = 2019,
  note      = "Natal, Brazil",
  category  = "Conference Publications",
  abstract  = "Many SMT solvers implement efficient SAT-based procedures
for solving fixed-size bit-vector formulas. These approaches, however,
cannot be used directly to reason about bit-vectors of symbolic
bit-width. To address this shortcoming, we propose a translation from
bit-vector formulas with parametric bit-width to formulas in a logic supported
by SMT solvers that includes non-linear integer arithmetic, uninterpreted
functions, and universal quantification. While this logic is undecidable,
this approach can still solve many formulas by capitalizing on
advances in SMT solving for non-linear arithmetic and universally quantified
formulas. We provide several case studies in which we have applied
this approach with promising results, including the bit-width independent
verification of invertibility conditions, compiler optimizations, and
bit-vector rewrites."
}

%complete
@inproceedings{BREO+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/BREO+19.pdf",
  author    = "Haniel Barbosa and Andrew Reynolds and Daniel El Ouraoui and Cesare Tinelli and Clark Barrett",
  title     = "Extending {SMT} Solvers to Higher-Order Logic",
  booktitle = "Proceedings of the $27^{th}$ International Conference on Automated Deduction (CADE '19)",
  series    = "Lecture Notes in Artificial Intelligence",
  volume    = 11716,
  publisher = "Springer",
  editor    = "Pascal Fontaine",
  pages     = "35--54",
  month     = aug,
  year      = 2019,
  note      = "Natal, Brazil",
  category  = "Conference Publications",
  abstract  = "SMT solvers have throughout the years been able to cope
with increasingly expressive formulas, from ground logics to full first-order
logic (FOL). In contrast, the extension of SMT solvers to higher-order
logic (HOL) is mostly unexplored. We propose a pragmatic extension
for SMT solvers to support HOL reasoning natively without compromising
performance on FOL reasoning, thus leveraging the extensive
research and implementation efforts dedicated to efficient SMT solving.
We show how to generalize data structures and the ground decision procedure
to support partial applications and extensionality, as well as how
to reconcile quantifier instantiation techniques with higher-order variables.
We also discuss a separate approach for redesigning an HOL SMT
solver from the ground up via new data structures and algorithms. We
apply our pragmatic extension to the CVC4 SMT solver and discuss a
redesign of the veriT SMT solver. Our evaluation shows they are competitive
with state-of-the-art HOL provers and often outperform the traditional
encoding into FOL."
}

%complete
@inproceedings{NRB+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/NRB+19.pdf",
  author    = "Andres N{\"o}tzli and Andrew Reynolds and Haniel Barbosa and Aina Niemetz and Mathias Preiner and Clark Barrett and Cesare Tinelli",
  title     = "Syntax-Guided Rewrite Rule Enumeration for SMT Solvers",
  booktitle = "Proceedings of the $22^{nd}$ International Conference on Theory and Applications of Satisfiability Testing (SAT '19)",
  series    = "Lecture Notes in Computer Science",
  volume    = 11628,
  publisher = "Springer",
  editor    = "Mikol\'{a}\u{s} Janota and In\^{e}s Lynce",
  pages     = "279--297",
  month     = jul,
  year      = 2019,
  note      = "Lisbon, Portugal",
  doi       = "10.1007/978-3-030-24258-9_20",
  isbn      = "978-3-030-24257-2",
  category  = "Conference Publications",
  abstract  = "The performance of modern Satisfiability Modulo Theories (SMT)
                  solvers relies crucially on efficient decision procedures as
                  well as static simplification techniques, which include large
                  sets of rewrite rules. Manually discovering and implementing
                  rewrite rules is challenging. In this work, we propose a
                  framework that uses enumerative syntax-guided synthesis
                  (SyGuS) to propose rewrite rules that are not implemented in
                  a given SMT solver. We implement this framework in CVC4, a
                  state-of-the-art SMT and SyGuS solver, and evaluate several
                  use cases. We show that some SMT solvers miss rewriting
                  opportunities, or worse, have bugs in their rewriters. We
                  also show that a variation of our approach can be used to
                  test the correctness of a rewriter. Finally, we show that
                  rewrites discovered with this technique lead to significant
                  improvements in CVC4 on both SMT and SyGuS problems over
                  bit-vectors and strings."
}

%complete
@inproceedings{ONP+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/ONP+19.pdf",
  author    = "Alex Ozdemir and Aina Niemetz and Mathias Preiner and Yoni Zohar and Clark Barrett",
  title     = "{DRAT}-based Bit-Vector Proofs in {CVC4}",
  booktitle = "Proceedings of the $22^{nd}$ International Conference on Theory and Applications of Satisfiability Testing (SAT '19)",
  series    = "Lecture Notes in Computer Science",
  volume    = 11628,
  publisher = "Springer",
  editor    = "Mikol\'{a}\u{s} Janota and In\^{e}s Lynce",
  pages     = "298--305",
  month     = jul,
  year      = 2019,
  note      = "Lisbon, Portugal",
  doi       = "10.1007/978-3-030-24258-9_21",
  isbn      = "978-3-030-24257-2",
  category  = "Conference Publications",
  abstract  = "Many state-of-the-art Satisfiability Modulo Theories (SMT)
                  solvers for the theory of fixed-size bit-vectors employ an
                  approach called bit-blasting, where a given formula is
                  translated into a Boolean satisfiability (SAT) problem and
                  delegated to a SAT solver. Consequently, producing bit-vector
                  proofs in an SMT solver requires incorporating SAT proofs
                  into its proof infrastructure. In this paper, we describe
                  three approaches for integrating DRAT proofs generated by an
                  off-the-shelf SAT solver into the proof infrastructure of the
                  SMT solver CVC4 and explore their strengths and
                  weaknesses. We implemented all three approaches using
                  CryptoMiniSat as the SAT back-end for its bit-blasting engine
                  and evaluated performance in terms of proof-production and
                  proof-checking."
}

%complete
@inproceedings{RNB+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/RNB+19.pdf",
  author    = "Andrew Reynolds and Andres N{\"o}tzli and Clark Barrett and Cesare Tinelli",
  title     = "High-Level Abstractions for Simplifying Extended String Constraints in {SMT}",
  booktitle = "Proceedings of the $31^{st}$ International Conference on Computer Aided Verification (CAV '19)",
  series    = "Lecture Notes in Computer Science",
  volume    = 11561,
  publisher = "Springer International Publishing",
  editor    = "Isil Dillig and Serdar Tasiran",
  pages     = "23--42",
  month     = jul,
  year      = 2019,
  note      = "New York, New York",
  doi       = "10.1007/978-3-030-25543-5_2",
  isbn      = "978-3-030-25542-8",
  category  = "Conference Publications",
  abstract  = "Satisfiability Modulo Theories (SMT) solvers with support for the
                  theory of strings have recently emerged as powerful tools for
                  reasoning about string-manipulating programs. However, due to
                  the complex semantics of extended string functions, it is
                  challenging to develop scalable solvers for the string
                  constraints produced by program analysis tools. We identify
                  several classes of simplification techniques that are
                  critical for the efficient processing of string constraints
                  in SMT solvers. These techniques can reduce the size and
                  complexity of input constraints by reasoning about arithmetic
                  entailment, multisets, and string containment relationships
                  over input terms. We provide experimental evidence that
                  implementing them results in significant improvements over
                  the performance of state-of-the-art SMT solvers for extended
                  string constraints."
}

%complete
@inproceedings{RBN+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/RBN+19.pdf",
  author    = "Andrew Reynolds and Haniel Barbosa and Andres N{\"o}tzli and Cesare Tinelli and Clark Barrett",
  title     = "{CVC4SY}: Smart and Fast Term Enumeration for Syntax-Guided Synthesis",
  booktitle = "Proceedings of the $31^{st}$ International Conference on Computer Aided Verification (CAV '19)",
  series    = "Lecture Notes in Computer Science",
  volume    = 11561,
  publisher = "Springer International Publishing",
  editor    = "Isil Dillig and Serdar Tasiran",
  pages     = "74--83",
  month     = jul,
  year      = 2019,
  note      = "New York, New York",
  doi       = "10.1007/978-3-030-25543-5_5",
  isbn      = "978-3-030-25542-8",
  category  = "Conference Publications",
  abstract  = "We present CVC4SY, a syntax-guided synthesis (SyGuS) solver
                  based on three bounded term enumeration strategies. The first
                  encodes term enumeration as an extension of the
                  quantifier-free theory of algebraic datatypes. The second is
                  based on a highly optimized brute-force algorithm. The third
                  combines elements of the others. Our implementation of the
                  strategies within the satisfiability modulo theories (SMT)
                  solver CVC4 and a heuristic to choose between them leads to
                  significant improvements over state-of-the-art SyGuS
                  solvers."
}

%complete
@inproceedings{BNP+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/BNP+19.pdf",
  author    = "Martin Brain and Aina Niemetz and Mathias Preiner and Andrew Reynolds and Clark Barrett and Cesare Tinelli",
  title     = "Invertibility Conditions for Floating-Point Formulas",
  booktitle = "Proceedings of the $31^{st}$ International Conference on Computer Aided Verification (CAV '19)",
  series    = "Lecture Notes in Computer Science",
  volume    = 11561,
  publisher = "Springer International Publishing",
  editor    = "Isil Dillig and Serdar Tasiran",
  pages     = "116--136",
  month     = jul,
  year      = 2019,
  note      = "New York, New York",
  doi       = "10.1007/978-3-030-25543-5_8",
  isbn      = "978-3-030-25542-8",
  category  = "Conference Publications",
  abstract  = "Automated reasoning procedures are essential for a number of
                  applications that involve bit-exact floating-point
                  computations. This paper presents conditions that
                  characterize when a variable in a floating-point constraint
                  has a solution, which we call invertibility conditions. We
                  describe a novel workflow that combines human interaction and
                  a syntax-guided synthesis (SyGuS) solver that was used for
                  discovering these conditions. We verify our conditions for
                  several floating-point formats. One implication of this
                  result is that a fragment of floating-point arithmetic admits
                  compact quantifier elimination. We implement our
                  invertibility conditions in a prototype extension of our
                  solver CVC4, showing their usefulness for solving quantified
                  constraints over floating-points."
}

%complete
@inproceedings{KHI+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/KHI+19.pdf",
  author    = "Katz, Guy and Huang, Derek A. and Ibeling, Duligur and Julian, Kyle and Lazarus, Christopher and Lim, Rachel and Shah, Parth and Thakoor, Shantanu and Wu, Haoze and Zelji{\'{c}}, Aleksandar and Dill, David L. and Kochenderfer, Mykel J. and Barrett, Clark",
  title     = "The Marabou Framework for Verification and Analysis of Deep Neural Networks",
  booktitle = "Proceedings of the $31^{st}$ International Conference on Computer Aided Verification (CAV '19)",
  series    = "Lecture Notes in Computer Science",
  volume    = 11561,
  publisher = "Springer International Publishing",
  editor    = "Isil Dillig and Serdar Tasiran",
  pages     = "443--452",
  month     = jul,
  year      = 2019,
  note      = "New York, New York",
  doi       = "10.1007/978-3-030-25540-4_26",
  isbn      = "978-3-030-25539-8",
  category  = "Conference Publications",
  abstract  = "Deep neural networks are revolutionizing the way complex systems
                  are designed. Consequently, there is a pressing need for
                  tools and techniques for network analysis and
                  certification. To help in addressing that need, we present
                  Marabou, a framework for verifying deep neural
                  networks. Marabou is an SMT-based tool that can answer
                  queries about a network's properties by transforming these
                  queries into constraint satisfaction problems. It can
                  accommodate networks with different activation functions and
                  topologies, and it performs high-level reasoning on the
                  network that can curtail the search space and improve
                  performance. It also supports parallel execution to further
                  enhance scalability. Marabou accepts multiple input formats,
                  including protocol buffer files generated by the popular
                  TensorFlow framework for neural networks. We describe the
                  system architecture and main components, evaluate the
                  technique and discuss ongoing work."
}

%complete
@inproceedings{FSB+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/FSB+19.pdf",
  author    = "M. R. Fadiheh and D. Stoffel and C. Barrett and S. Mitra and W. Kunz",
  title     = "Processor Hardware Security Vulnerabilities and their Detection by Unique Program Execution Checking",
  booktitle = "Proceedings of the 2019 Design, Automation and Test in Europe (DATE '19)",
  publisher = "IEEE",
  pages     = "994--999",
  month     = mar,
  year      = 2019,
  note      = "Florence, Italy",
  doi       = "10.23919/DATE.2019.8715004",
  isbn      = "978-3-9819263-2-3",
  category  = "Conference Publications",
  abstract  = "Recent discovery of security attacks in advanced
processors, known as Spectre and Meltdown, has resulted in high
public alertness about security of hardware. The root cause of
these attacks is information leakage across covert channels that
reveal secret data without any explicit information flow between
the secret and the attacker. Many sources believe that such covert
channels are intrinsic to highly advanced processor architectures
based on speculation and out-of-order execution, suggesting that
such security risks can be avoided by staying away from highend
processors. This paper, however, shows that the problem is
of wider scope: we present new classes of covert channel attacks
which are possible in average-complexity processors with in-order
pipelining, as they are mainstream in applications ranging from
Internet-of-Things to Autonomous Systems.
We present a new approach as a foundation for remedy against
covert channels: while all previous attacks were found by clever
thinking of human attackers, this paper presents a formal method
called Unique Program Execution Checking which detects and
locates vulnerabilities to covert channels systematically, including
those to covert channels unknown so far."
}

%complete
@inproceedings{SDS+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/SDS+19.pdf",
  author    = "E. Singh and K. Devarajegowda and S. Simon and R. Schnieder and K. Ganesan and M. Fadiheh and D. Stoffel and W. Kunz and C. Barrett and W. Ecker and S. Mitra",
  title     = "Symbolic {QED} Pre-silicon Verification for Automotive Microcontroller Cores: Industrial Case Study", 
  booktitle = "Proceedings of the 2019 Design, Automation and Test in Europe (DATE '19)",
  publisher = "IEEE",
  pages     = "1000--1005",
  month     = mar,
  year      = 2019,
  note      = "Florence, Italy",
  doi       = "10.23919/DATE.2019.8715271",
  isbn      = "978-3-9819263-2-3",
  category  = "Conference Publications",
  abstract  = "We present an industrial case study that demonstrates the
                  practicality and effectiveness of Symbolic Quick Error
                  Detection (Symbolic QED) in detecting logic design flaws
                  (logic bugs) during pre-silicon verification. Our study
                  focuses on several microcontroller core designs (~1,800
                  flip-flops, ~70,000 logic gates) that have been extensively
                  verified using an industrial verification flow and used for
                  various commercial automotive products. The results of our
                  study are as follows: 1. Symbolic QED detected all logic bugs
                  in the designs that were detected by the industrial
                  verification flow (which includes various flavors of
                  simulation-based verification and formal
                  verification). 2. Symbolic QED detected additional logic bugs
                  that were not recorded as detected by the industrial
                  verification flow. (These additional bugs were also perhaps
                  detected by the industrial verification flow.) 3.Symbolic QED
                  enables significant design productivity improvements: (a) 8X
                  improved (i.e., reduced) verification effort for a new design
                  (8 person-weeks for Symbolic QED vs. 17 person-months using
                  the industrial verification flow). (b) 60X improved
                  verification effort for subsequent designs (2 person-days for
                  Symbolic QED vs. 4-7 person-months using the industrial
                  verification flow). (c) Quick bug detection (runtime of 20
                  seconds or less), together with short counterexamples (10 or
                  fewer instructions) for quick debug, using Symbolic QED."
}

%complete
@inproceedings{MMB+18,
  url       = "http://theory.stanford.edu/~barrett/pubs/MMB+18.pdf",
  author    = "Cristian Mattarei and Makai Mann and Clark Barrett and Ross G. Daly and Dillon Huff and Pat Hanrahan",
  title     = "{CoSA}: Integrated Verification for Agile Hardware Design",
  booktitle = "Proceedings of the $18^{th}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '18)",
  editor    = "Nikolaj Bj{\o}rner and Arie Gurfinkel",
  publisher = "FMCAD Inc.",
  pages     = "7--11",
  month     = oct,
  year      = 2018,
  note      = "Austin, Texas",
  doi       = "10.23919/FMCAD.2018.8603014",
  isbn      = "978-0-9835678-8-2",
  category  = "Conference Publications",
  abstract  = "Symbolic model-checking is a well-established technique used in
                  hardware design to assess, and formally verify, functional
                  correctness. However, most modern model-checkers encode the
                  problem into propositional satisfiability (SAT) and do not
                  leverage any additional information beyond the input design,
                  which is typically provided in a hardware description
                  language such as Verilog.  In this paper, we present CoSA
                  (CoreIR Symbolic Analyzer), a model-checking tool for CoreIR
                  designs. CoreIR is a new intermediate representation for
                  hardware. CoSA encodes model-checking queries into
                  first-order formulas that can be solved by Satisfiability
                  Modulo Theories (SMT) solvers. In particular, it natively
                  supports encodings using the theories of bitvectors and
                  arrays. CoSA is closely integrated with CoreIR and can thus
                  leverage CoreIR-generated metadata in addition to
                  user-provided lemmas to assist with formal verification. CoSA
                  supports multiple input formats and provides a broad set of
                  analyses including equivalence checking and safety and
                  liveness verification. CoSA is open-source and written in
                  Python, making it easily extendable."
}

%complete
@inproceedings{GKP+18,
  url       = "http://theory.stanford.edu/~barrett/pubs/GKP+18.pdf",
  author    = "Divya Gopinath and Guy Katz and Corina S. P\u{a}s\u{a}reanu and Clark Barrett",
  title     = "DeepSafe: A Data-driven Approach for Assessing Robustness of Neural Networks",
  booktitle = "Proceedings of the $16^{th}$ International Symposium on Automated Technology for Verification and Analysis (ATVA '18)",
  series    = "Lecture Notes in Computer Science",
  volume    = 11138,
  publisher = "Springer",
  editor    = "Shuvendu Lahiri and Chao Wang",
  pages     = "3--19",
  month     = oct,
  year      = 2018,
  note      = "Los Angeles, California",
  doi       = "10.1007/978-3-030-01090-4_1",
  isbn      = "978-3-030-01090-4",
  category  = "Conference Publications",
  abstract  = "Deep neural networks have achieved impressive results in many
                  complex applications, including classification tasks for
                  image and speech recognition, pattern analysis or
                  perception in self-driving vehicles. However, it has been
                  observed that even highly trained networks are very
                  vulnerable to adversarial perturbations. Adding minimal
                  changes to inputs that are correctly classified can lead to
                  wrong predictions, raising serious security and safety
                  concerns. Existing techniques for checking robustness
                  against such perturbations only consider searching locally
                  around a few individual inputs, providing limited guarantees.
                  We propose DeepSafe, a novel approach for automatically
                  assessing the overall robustness of a neural
                  network. DeepSafe applies clustering over known labeled data
                  and leverages off-the-shelf constraint solvers to
                  automatically identify and check safe regions in which the
                  network is robust, i.e. all the inputs in the region are
                  guaranteed to be classified correctly. We also introduce the
                  concept of targeted robustness, which ensures that the neural
                  network is guaranteed not to misclassify inputs within a
                  region to a specific target (adversarial) label. We evaluate
                  DeepSafe on a neural network implementation of a controller
                  for the next-generation Airborne Collision Avoidance System
                  for unmanned aircraft (ACAS Xu) and for the well known MNIST
                  network. For these networks, DeepSafe identified many regions
                  which were safe, and also found adversarial perturbations of
                  interest."
}

%complete
@inproceedings{RVB+18,
  url       = "http://theory.stanford.edu/~barrett/pubs/RVB+18.pdf",
  author    = "Andrew Reynolds and Arjun Viswanathan and Haniel Barbosa and Cesare Tinelli and Clark Barrett",
  title     = "Datatypes with Shared Selectors",
  booktitle = "Proceedings of the $9^{th}$ International Joint Conference on Automated Reasoning (IJCAR '18)",
  series    = "Lecture Notes in Computer Science",
  volume    = 10900,
  publisher = "Springer International Publishing",
  editor    = "Didier Galmiche and Stephan Schulz and Roberto Sebastiani",
  pages     = "591--608",
  month     = jun,
  year      = 2018,
  note      = "Oxford, United Kingdom",
  doi       = "10.1007/978-3-319-94205-6_39",
  isbn      = "978-3-319-94205-6",
  category  = "Conference Publications",
  abstract  = " We introduce a new theory of algebraic datatypes where selector
                  symbols can be shared between multiple constructors, thereby
                  reducing the number of terms considered by current SMT-based
                  solving approaches. We show that the satisfiability problem
                  for the traditional theory of algebraic datatypes can be
                  reduced to problems where selectors are mapped to shared
                  symbols based on a transformation provided in this paper. The
                  use of shared selectors addresses a key bottleneck for an
                  SMT-based enumerative approach to the Syntax-Guided Synthesis
                  (SyGuS) problem. Our experimental evaluation of an
                  implementation of the new theory in the SMT solver cvc4 on
                  syntax-guided synthesis and other domains provides evidence
                  that the use of shared selectors improves state-of-the-art
                  SMT-based approaches for constraints over algebraic
                  datatypes."
}

%complete
@inproceedings{NPR+18,
  url       = "http://theory.stanford.edu/~barrett/pubs/NPR+18.pdf",
  author    = "Aina Niemetz and Mathias Preiner and Andrew Reynolds and Clark Barrett and Cesare Tinelli",
  title     = "Solving Quantified Bit-Vectors using Invertibility Conditions",
  booktitle = "Proceedings of the $30^{th}$ International Conference on Computer Aided Verification (CAV '18)",
  series    = "Lecture Notes in Computer Science",
  volume    = 10982,
  publisher = "Springer",
  editor    = "Hana Chockler and Georg Weissenbacher",
  pages     = "236--255",
  month     = jul,
  year      = 2018,
  note      = "Oxford, United Kingdom",
  doi       = "10.1007/978-3-319-96142-2_16",
  isbn      = "978-3-319-96142-2",
  category  = "Conference Publications",
  abstract  = " We present a novel approach for solving quantified bit-vector
                  formulas in Satisfiability Modulo Theories (SMT) based on
                  computing symbolic inverses of bit-vector operators. We
                  derive conditions that precisely characterize when bit-vector
                  constraints are invertible for a representative set of
                  bit-vector operators commonly supported by SMT solvers. We
                  utilize syntax-guided synthesis techniques to aid in
                  establishing these conditions and verify them independently
                  by using several SMT solvers. We show that invertibility
                  conditions can be embedded into quantifier instantiations
                  using Hilbert choice expressions, and give experimental
                  evidence that a counterexample-guided approach for quantifier
                  instantiation utilizing these techniques leads to performance
                  improvements with respect to state-of-the-art solvers for
                  quantified bit-vector constraints."
}

%complete
@inproceedings{FUN+18,
  url       = "http://theory.stanford.edu/~barrett/pubs/FUN+18.pdf",
  author    = "M. R. Fadiheh and J. Urdahl and S. S. Nuthakki and S. Mitra and C. Barrett and D. Stoffel and W. Kunz",
  title     = "Symbolic quick error detection using symbolic initial state for pre-silicon verification",
  booktitle = "Proceedings of the 2018 Design, Automation and Test in Europe (DATE '18)",
  publisher = "IEEE",
  pages     = "55--60",
  month     = mar,
  year      = 2018, 
  note      = "Dresden, Germany",
  doi       = "10.23919/DATE.2018.8341979",
  isbn      = "978-3-9819263-0-9",
  category  = "Conference Publications",
  abstract  = "Driven by the demand for highly customizable processor cores
                  for IoT and related applications, there is a renewed interest
                  in effective but low-cost techniques for verifying
                  systems-on-chip (SoCs). This paper revisits the problem of
                  processor verification and presents a radically different
                  approach when compared to the state of the art. The proposed
                  approach is highly automated and leverages recent progress in
                  the field of post-silicon validation by the method of Quick
                  Error Detection (QED) and Symbolic Quick Error Detection
                  (SQED). In this paper, we modify SQED by incorporating a
                  symbolic initial state in its BMC-based analysis and
                  generalize the approach into the S$^2$QED method. As a first
                  advantage, S$^2$QED can separate logic bugs from electrical bugs
                  in QED-based postsilicon validation. Secondly, it also makes
                  a strong contribution to pre-silicon verification by proving
                  that the execution of each instruction is independent of its
                  context in the program. The manual efforts for the proposed
                  approach are orders of magnitude smaller than for
                  conventional property checking. Our experimental results
                  demonstrate the potential of S$^2$QED using the Aquarius
                  open-source processor example."
}

%complete
@inproceedings{NKF+18,
  url       = "http://theory.stanford.edu/~barrett/pubs/NKF+18.pdf",
  author    = "Andres N{\"o}tzli and Jehandad Khan and Andy Fingerhut and Clark Barrett and Peter Athanas",
  title     = "p4pktgen: Automated Test Case Generation for {P4} Programs",
  booktitle = "Proceedings of the ACM Symposium on SDN Research (SOSR '18)",
  publisher = "ACM",
  pages     = "5:1--5:7",
  month     = mar,
  year      = 2018,
  note      = "Los Angeles, California",
  isbn      = "978-1-4503-5664-0",
  doi       = "10.1145/3185467.3185497",
  category  = "Conference Publications",
  abstract  = "With the rise of programmable network switches, network
                  infrastructure is becoming more flexible and more capable
                  than ever before. Programming languages such as P4 lower the
                  barrier for changing the inner workings of network switches
                  and offer a uniform experience across different devices. How-
                  ever, this programmability also brings the risk of
                  introducing hard-to-catch bugs at a level that was previously
                  covered by well-tested devices with a fixed set of
                  capabilities. Subtle discrepancies between different
                  implementations pose a risk of introducing bugs at a layer
                  that is opaque to the user.  To reap the benefit of
                  programmable hardware and keep--or improve upon--the
                  reliability of traditional approaches, new tools are
                  needed. In this work, we present p4pktgen, a tool for
                  automatically generating test cases for P4 programs using
                  symbolic execution. These test cases can be used to validate
                  that P4 programs act as intended on a device."
}

%complete
@inproceedings{MBG+18,
  url       = "http://theory.stanford.edu/~barrett/pubs/MBG+18.pdf",
  author    = "Cristian Mattarei and Clark Barrett and Shu-yu Guo and Bradley Nelson and Ben Smith",
  title     = "{EMME}: a formal tool for {ECMAS}cript Memory Model Evaluation",
  booktitle = "Proceedings of the $24^{th}$ International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS '18)",
  series    = "Lecture Notes in Computer Science",
  volume    = 10806,
  publisher = "Springer",
  editor    = "Dirk Beyer and Marieke Huisman",
  pages     = "55--71",
  month     = apr,
  year      = 2018,
  note      = "Thessaloniki, Greece. {\em Distinguished Artifact Award.}",
  doi       = "10.1007/978-3-319-89963-3_4",
  isbn      = "978-3-319-89963-3",
  category  = "Conference Publications",
  abstract  = "Nearly all web-based interfaces are written in JavaScript. Given
                  its prevalence, the support for high performance JavaScript
                  code is crucial. The ECMA Technical Committee 39 (TC39) has
                  recently extended the ECMAScript language (i.e., JavaScript)
                  to support shared memory accesses between different
                  threads. The extension is given in terms of a natural
                  language memory model specification.  In this paper we
                  describe a formal approach for validating both the memory
                  model and its implementations in various JavaScript
                  engines. We first introduce a formal version of the memory
                  model and report results on checking the model for
                  consistency and other properties. We then introduce our tool,
                  EMME, built on top of the Alloy analyzer, which leverages the
                  model to generate all possible valid executions of a given
                  JavaScript program. Finally, we report results using EMME
                  together with small test programs to analyze industrial
                  JavaScript engines. We show that EMME can find bugs as well
                  as missed opportunities for optimization."
}

%complete
@inproceedings{RTJ+17,
  url       = "http://theory.stanford.edu/~barrett/pubs/RTJ+17.pdf",
  author    = "Andrew Reynolds and Cesare Tinelli and Dejan Jovanovi\'c and Clark Barrett",
  title     = "Designing Theory Solvers with Extensions",
  booktitle = "Proceedings of the $11^{th}$ International Symposium on Frontiers of Combining Systems (FroCoS '17)",
  series    = "Lecture Notes in Artificial Intelligence",
  volume    = 10483,
  publisher = "Springer",
  editor    = "Clare Dixon and Marcelo Finger",
  pages     = "22--40",
  month     = sep,
  year      = 2017,
  note      = "Brasilia, Brazil",
  category  = "Conference Publications",
  abstract  = "Satisfiability Modulo Theories (SMT) solvers have been developed to
natively support a wide range of theories, including linear arithmetic, bit-vectors,
strings, algebraic datatypes and finite sets. They handle constraints in these theories
using specialized theory solvers. In this paper, we overview the design of
these solvers, specifically focusing on theories whose function symbols are partitioned
into a base signature and an extended signature. We introduce generic techniques
that can be used in solvers for extended theories, including a new context-dependent
simplification technique and model-based refinement techniques. We
provide case studies showing our techniques can be leveraged for reasoning in an
extended theory of strings, for bit-vector approaches that rely on lazy bit-blasting
and for new approaches to non-linear arithmetic."
}

%complete
@inproceedings{MRT+17,
  url       = "http://theory.stanford.edu/~barrett/pubs/MRT+17.pdf",
  author    = "Baoluo Meng and Andrew Reynolds and Cesare Tinelli and Clark Barrett",
  title     = "Relational Constraint Solving in SMT",
  booktitle = "Proceedings of the $26^{th}$ International Conference on Automated Deduction (CADE '17)",
  series    = "Lecture Notes in Artificial Intelligence",
  volume    = 10395,
  publisher = "Springer",
  editor    = "Leonardo de Moura",
  pages     = "148--165",
  month     = aug,
  year      = 2017,
  note      = "Gothenburg, Sweden",
  category  = "Conference Publications",
  abstract  = "Relational logic is useful for reasoning about computational problems
with relational structures, including high-level system design, architectural con-
figurations of network systems, ontologies, and verification of programs with
linked data structures. We present a modular extension of an earlier calculus
for the theory of finite sets to a theory of finite relations with such operations
as transpose, product, join, and transitive closure. We implement this extension
as a theory solver of the SMT solver CVC4. Combining this new solver with
the finite model finding features of CVC4 enables several compelling use cases.
For instance, native support for relations enables a natural mapping from Alloy,
a declarative modeling language based on first-order relational logic, to SMT
constraints. It also enables a natural encoding of several description logics with
concrete domains, allowing the use of an SMT solver to analyze, for instance,
Web Ontology Language (OWL) models. We provide an initial evaluation of our
solver on a number of Alloy and OWL models which shows promising results."
}

%complete
@inproceedings{KBD+17,
  url       = "http://theory.stanford.edu/~barrett/pubs/KBD+17.pdf",
  author    = "Guy Katz and Clark Barrett and David L. Dill and Kyle Julian and Mykel J. Kochenderfer",
  title     = "Reluplex: An Efficient {SMT} Solver for Verifying Deep Neural Networks",
  booktitle = "Proceedings of the $29^{th}$ International Conference on Computer Aided Verification (CAV '17)",
  volume    = 10426,
  number    = 1,
  editor    = "Rupak Majumdar and Viktor Kuncak",
  pages     = "97--117",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  month     = jul,
  year      = 2017,
  note      = "Heidelberg, Germany",
  category  = "Conference Publications",
  abstract  = "
Deep neural networks have emerged as a widely used and
effective means for tackling complex, real-world problems. However, a
major obstacle in applying them to safety-critical systems is the great
difficulty in providing formal guarantees about their behavior. We present
a novel, scalable, and efficient technique for verifying properties of deep
neural networks (or providing counter-examples). The technique is based
on the simplex method, extended to handle the non-convex Rectified Linear
Unit (ReLU ) activation function, which is a crucial ingredient in
many modern neural networks. The verification procedure tackles neural
networks as a whole, without making any simplifying assumptions.
We evaluated our technique on a prototype deep neural network implementation
of the next-generation airborne collision avoidance system for
unmanned aircraft (ACAS Xu). Results show that our technique can
successfully prove properties of networks that are an order of magnitude
larger than the largest networks verified using existing methods.
"
}

%complete
@inproceedings{SBM17,
  url       = "http://theory.stanford.edu/~barrett/pubs/SBM17.pdf",
  author    = "Eshan Singh and Clark Barrett and Subhasish Mitra",
  title     = "{E-QED}: Electrical Bug Localization During Post-Silicon Validation Enabled by Quick Error Detection and Formal Methods",
  booktitle = "Proceedings of the $29^{th}$ International Conference on Computer Aided Verification (CAV '17)",
  volume    = 10426,
  number    = 1,
  editor    = "Rupak Majumdar and Viktor Kuncak",
  pages     = "104--125",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  month     = jul,
  year      = 2017,
  note      = "Heidelberg, Germany",
  category  = "Conference Publications",
  abstract  = "
During post-silicon validation, manufactured integrated circuits are extensively
tested in actual system environments to detect design bugs. Bug localization
involves identification of a bug trace (a sequence of inputs that activates
and detects the bug) and a hardware design block where the bug is located.
Existing bug localization practices during post-silicon validation are mostly manual
and ad hoc, and, hence, extremely expensive and time consuming. This is
particularly true for subtle electrical bugs caused by unexpected interactions
between a design and its electrical state. We present E-QED, a new approach that
automatically localizes electrical bugs during post-silicon validation. Our results
on the OpenSPARC T2, an open-source 500-million-transistor multicore chip design,
demonstrate the effectiveness and practicality of E-QED: starting with a
failed post-silicon test, in a few hours (9 hours on average) we can automatically
narrow the location of the bug to (the fan-in logic cone of) a handful of candidate
flip-flops (18 flip-flops on average for a design with ~ 1 Million flip-flops) and
also obtain the corresponding bug trace. The area impact of E-QED is ~2.5\%. In
contrast, determining this same information might take weeks (or even months)
of mostly manual work using traditional approaches.
"
}

@inproceedings{EMT+17,
  url       = "http://theory.stanford.edu/~barrett/pubs/EMT+17.pdf",
  author    = "Burak Ekici and Alain Mebsout and Cesare Tinelli and Chantal Keller and Guy Katz and Andrew Reynolds and Clark Barrett",
  title     = "{SMTC}oq: A Plug-In for Integrating {SMT} Solvers into {C}oq",
  booktitle = "Proceedings of the $29^{th}$ International Conference on Computer Aided Verification (CAV '17)",
  volume    = 10426,
  number    = 1,
  editor    = "Rupak Majumdar and Viktor Kuncak",
  pages     = "126--136",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  month     = jul,
  year      = 2017,
  note      = "Heidelberg, Germany",
  category  = "Conference Publications",
  abstract  = "
This paper describes SMTCoq, a plug-in for the integration of external
solvers into the Coq proof assistant. Based on a checker for generic first-order
proof certificates fully implemented and proved correct in Coq, SMTCoq offers
facilities to check answers from external SAT and SMT solvers and to increase
Coq’s automation using such solvers, all in a safe way. The current version supports
proof certificates produced by the SAT solver ZChaff, for propositional logic, and
the SMT solvers veriT and CVC4, for the quantifier-free fragment of the combined
theory of fixed-size bit vectors, functional arrays with extensionality, linear integer
arithmetic, and uninterpreted function symbols.
"
}

@inproceedings{RWB+17,
  url       = "http://theory.stanford.edu/~barrett/pubs/RWB+17.pdf",
  author    = "Andrew Reynolds and Maverick Woo and Clark Barrett and David Brumley and Tianyi Liang and Cesare Tinelli",
  title     = "Scaling up {DPLL(T)} String Solvers Using Context-Dependent Simplification",
  booktitle = "Proceedings of the $29^{th}$ International Conference on Computer Aided Verification (CAV '17)",
  volume    = 10426,
  number    = 1,
  editor    = "Rupak Majumdar and Viktor Kuncak",
  pages     = "453--474",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  month     = jul,
  year      = 2017,
  note      = "Heidelberg, Germany",
  category  = "Conference Publications",
  abstract  = "
Efficient reasoning about strings is essential to a growing number of
security and verification applications. We describe satisfiability checking techniques
in an extended theory of strings that includes operators commonly occurring
in these applications, such as contains, index of and replace. We introduce
a novel context-dependent simplification technique that improves the scalability
of string solvers on challenging constraints coming from real-world problems.
Our evaluation shows that an implementation of these techniques in the SMT
solver CVC4 significantly outperforms state-of-the-art string solvers on benchmarks
generated using PyEx, a symbolic execution engine for Python programs.
Using a test suite sampled from four popular Python packages, we show that
PyEx uses only 41\% of the runtime when coupled with CVC4 than when coupled
with CVC4's closest competitor while achieving comparable program coverage.
"
}

%complete
@inproceedings{WBW17,
  url       = "http://theory.stanford.edu/~barrett/pubs/WBW17.pdf",
  author    = "Wei Wang and Clark Barrett and Thomas Wies",
  title     = "Partitioned Memory Models for Program Analysis",
  booktitle = "Proceedings of the $18^{th}$ International Conference on Verification, Model Checking, and Abstract Interpretion (VMCAI '17)",
  editor    = "Bouajjani, Ahmed and Monniaux, David",
  publisher = "Springer International Publishing",
  pages     = "539--558",
  isbn      = "978-3-319-52234-0",
  doi       = "10.1007/978-3-319-52234-0_29",
  month     = jan,
  year      = 2017,
  note      = "Paris, France",
  category  = "Conference Publications",
  abstract  = "Scalability is a key challenge in static analysis.  For imperative languages
like C, the approach taken for modeling memory can play a significant role in
scalability.  In this paper, we explore a family of memory models called
partitioned memory models which divide memory up based on the results of
a points-to analysis.  We review Steensgaard's original and field-sensitive
points-to analyses as well as Data Structure Analysis (DSA), and introduce a new 
cell-based points-to analysis which more precisely handles
heap data structures and type-unsafe operations
like pointer arithmetic and pointer casting.
We give experimental results on benchmarks from the software verification
competition using the program verification framework in Cascade.
We show that a partitioned memory model using our cell-based points-to
analysis outperforms models using other analyses.
"
}

%complete
@inproceedings{KBT+16,
  url       = "http://theory.stanford.edu/~barrett/pubs/KBT+16.pdf",
  author    = "Guy Katz and Clark Barrett and Cesare Tinelli and Andrew Reynolds and Liana Hadarean",
  title     = "Lazy Proofs for {DPLL(T)}-Based {SMT} Solvers",
  booktitle = "Proceedings of the $16^{th}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '16)",
  editor    = "Ruzica Piskac and Muralidhar Talupur",
  publisher = "FMCAD Inc.",
  pages     = "93--100",
  month     = oct,
  year      = 2016,
  note      = "Mountain View, California.  {\em Best paper award.}",
  category  = "Conference Publications",
  abstract  = "With the integration of SMT solvers into analysis
  frameworks aimed at ensuring a system's end-to-end
  correctness, having a high level of confidence in
  these solvers' results has become crucial. For unsatisfiable queries,
  a reasonable approach is to have the solver
  return an independently checkable proof of unsatisfiability.
  We propose a lazy, extensible and robust method for enhancing
  DPLL(T)-style SMT solvers with proof-generation capabilities. Our method
  maintains separate Boolean-level and theory-level proofs, and
  weaves them together into one coherent artifact. Each
  theory-specific solver is called upon lazily, a posteriori, to prove precisely
  those solution steps it is responsible for and that are needed for the final proof.
  We present an implementation of our technique in the CVC4 SMT solver.
  CVC4 can produce unsatisfiability proofs for quantifier-free queries involving
  uninterpreted functions, arrays, bitvectors and combinations thereof. 
  We discuss an evaluation of our tool using industrial benchmarks and benchmarks 
  from the SMT-LIB library, which shows promising results."
}

%complete
@inproceedings{BRBT16,
  url       = "http://theory.stanford.edu/~barrett/pubs/BRBT16.pdf",
  author    = "Kshitij Bansal and Andrew Reynolds and Clark Barrett and Cesare Tinelli",
  title     = "A New Decision Procedure for Finite Sets and Cardinality Constraints in {SMT}",
  booktitle = "Proceedings of the $8^{th}$ International Joint Conference on Automated Reasoning (IJCAR '16)",
  series    = "Lecture Notes in Computer Science",
  volume    = 9706,
  publisher = "Springer International Publishing",
  editor    = "Olivetti, Nicola and Tiwari, Ashish",
  pages     = "82--98",
  doi       = "10.1007/978-3-319-40229-1_7",
  isbn      = "978-3-319-40229-1",
  month     = jun,
  year      = 2016,
  note      = "Coimbra, Portugal",
  category  = "Conference Publications",
  abstract  = "
We consider the problem of deciding the theory of finite sets with cardinality
constraints in a satisfiability modulo theories solver.  Sets are a common
high-level data structure used in programming; thus, such a theory is useful
for modeling program constructs directly. More importantly, sets are a basic
construct of mathematics and thus natural to use when mathematically defining
the properties of a computer system.  We develop a calculus consisting of a
modular combination of a procedure for reasoning about membership constraints
and a procedure for reasoning about cardinality constraints. The reasoning for
cardinality involves tracking how different sets overlap. For efficiency, we
avoid considering Venn regions directly, which has been the approach in earlier
work.  Instead, we develop a novel technique wherein potentially overlapping
regions are considered incrementally. We use a graph to track the interaction
of the different regions.  Early experimental results demonstrate that the new
technique is competitive with previous techniques and scales much better on
certain classes of problems.
"
}


%complete
@inproceedings{HBR+15,
  url       = "http://theory.stanford.edu/~barrett/pubs/HBR+.pdf",
  author    = "Liana Hadarean and Clark Barrett and Andrew Reynolds and Cesare Tinelli and Morgan Deters",
  title     = "Fine-grained {SMT} Proofs for the Theory of Fixed-width Bit-vectors",
  booktitle = "Proceedings of the $20^{th}$ International Conference on Logic for Programming, Artificial Intelligence, and Reasoning (LPAR '15)",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  volume    = 9450,
  editor    = {Martin Davis and Ansgar Fehnker and Annabelle McIver and Andrei Voronkov},
  pages     = "340--355",
  month     = nov,
  year      = 2015,
  note      = "Suva, Fiji",
  category  = "Conference Publications",
  abstract  = "Many high-level verification tools rely on SMT solvers to efficiently
discharge complex verification conditions. Some applications require more than
just a yes/no answer from the solver. For satisfiable quantifier-free problems, a
satisfying assignment is a natural artifact. In the unsatisfiable case, an externally
checkable proof can serve as a certificate of correctness and can be mined to
gain additional insight into the problem. We present a method of encoding and
checking SMT-generated proofs for the quantifier-free theory of fixed-width bitvectors.
Proof generation and checking for this theory poses several challenges,
especially for proofs based on reductions to propositional logic. Such reductions
can result in large resolution subproofs in addition to requiring a proof that the
reduction itself is correct. We describe a fine-grained proof system formalized
in the LFSC framework that addresses some of these challenges with the use of
computational side-conditions. We report results using a proof-producing version
of the CVC4 SMT solver on unsatisfiable quantifier-free bit-vector benchmarks
from the SMT-LIB benchmark library."
}

%complete
@inproceedings{LSB+15,
  url       = "http://theory.stanford.edu/~barrett/pubs/LSB+.pdf",
  author    = "David Lin and Eshan Singh and Clark Barrett and Subhasish Mitra",
  title     = "A Structured Approach to Post-Silicon Validation and Debug using Symbolic Quick Error Detection",
  booktitle = "Proceedings of the $42^{nd}$ International Test Conference (ITC '15)",
  publisher = "IEEE",
  pages     = "1--10",
  month     = oct,
  year      = 2015,
  note      = "Anaheim, California.  {\em Best paper award.}",
  category  = "Conference Publications",
  abstract  = "During post-silicon validation and debug,
manufactured integrated circuits (ICs) are tested in actual system
environments to detect and fix design flaws (bugs). Existing postsilicon
validation and debug techniques are mostly ad hoc and often
involve manual steps. Such ad hoc approaches cannot scale with
increasing IC complexity. We present Symbolic Quick Error
Detection (Symbolic QED), a structured approach to post-silicon
validation and debug. Symbolic QED combines the following steps
in a coordinated fashion: 1. Quick Error Detection (QED) tests that
quickly detect bugs with short error detection latencies and high
coverage. 2. Formal analysis techniques to localize bugs and
generate minimal-length bug traces upon detection of the
corresponding bugs.
We demonstrate the practicality and effectiveness of Symbolic QED
using the OpenSPARC T2, a 500-million-transistor open-source
multicore System-on-Chip (SoC) design, and using ``difficult'' logic bug
scenarios that occurred in various state-of-the-art commercial
multicore SoCs. Our results show that Symbolic QED: (i) is fully
automatic (unlike manual techniques in use today that can be
extremely time-consuming and expensive); (ii) requires only a few
hours in contrast to manual approaches that might take days (or even
months) or formal techniques that often take days or fail completely for
large designs; (iii) generates counter-examples (for activating and
detecting logic bugs) that are up to 6 orders of magnitude shorter than
those produced by traditional techniques; and, (iv) does not require
any additional hardware."
}

%complete
@inproceedings{KBH15,
  url       = "http://theory.stanford.edu/~barrett/pubs/KBH15.pdf",
  author    = "Guy Katz and Clark Barrett and David Harel",
  title     = "Theory-Aided Model Checking of Concurrent Transition Systems",
  booktitle = "Proceedings of the $15^{th}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '15)",
  publisher = "FMCAD Inc.",
  pages     = "81--88",
  month     = sep,
  year      = 2015,
  note      = "Austin, Texas",
  category  = "Conference Publications",
  abstract  = "We present a method for the automatic compositional
verification of certain classes of concurrent programs. Our
approach is based on the casting of the model checking problem
into a theory of transition systems within CVC4, a DPLL(T)
based SMT solver. Our transition system theory then cooperates
with other theories supported by the solver (e.g., arithmetic,
arrays), which can help accelerate the verification process. More
specifically, our theory solver looks for known patterns within
the input programs and uses them to generate lemmas in the
languages of other theories. When applicable, these lemmas can
often steer the search away from safe parts of the search space,
reducing the number of states to be explored and expediting the
model checking procedure. We demonstrate the potential of our
technique on a number of broad classes of programs."
}

%complete
@inproceedings{LTR+15,
  url       = "http://theory.stanford.edu/~barrett/pubs/LTR+15.pdf",
  author    = "Tianyi Liang and Nestan Tsiskaridze and Andrew Reynolds and Cesare Tinelli and Clark Barrett",
  title     = "A Decision Procedure for Regular Membership and Length Constraints over Unbounded Strings",
  booktitle = "Proceedings of the $10^{th}$ International Symposium on Frontiers of Combining Systems (FroCoS '15)",
  volume    = 9322,
  editor    = "Lutz, Carsten and Ranise, Silvio",
  pages     = "135--150",
  doi       = "10.1007/978-3-319-24246-0_9",
  series    = "Lecture Notes in Artificial Intelligence",
  publisher = "Springer",
  month     = sep,
  year      = 2015,
  note      = "Wroclaw, Poland",
  category  = "Conference Publications",
  abstract  = "We prove that the quantifier-free fragment of the theory of
character strings with regular language membership constraints and linear
integer constraints over string lengths is decidable. We do that by
describing a sound, complete and terminating tableaux calculus for that
fragment which uses as oracles a decision procedure for linear integer
arithmetic and a number of computable functions over regular expressions.
A distinguishing feature of this calculus is that it provides a completely
algebraic method for solving membership constraints which can
be easily integrated into multi-theory SMT solvers. Another is that it
can be used to generate symbolic solutions for such constraints, that is,
solved forms that provide simple and compact representations of entire
sets of complete solutions. The calculus is part of a larger one providing
the theoretical foundations of a high performance theory solver for string
constraints implemented in the SMT solver CVC4."
}

%complete
@inproceedings{RDK+15,
  url       = "http://theory.stanford.edu/~barrett/pubs/RDK+15.pdf",
  author    = "Andrew Reynolds and Morgan Deters and Viktor Kuncak and Clark Barrett and Cesare Tinelli",
  title     = "Counterexample Guided Quantifier Instantiation for Synthesis in {SMT}",
  booktitle = "Proceedings of the $27^{th}$ International Conference on Computer Aided Verification (CAV '15)",
  volume    = 9206,
  number    = 2,
  editor    = "Daniel Kroening and Corina S. P\u{a}s\u{a}reanu",
  pages     = "198--216",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  month     = jul,
  year      = 2015,
  note      = "San Francisco, California",
  category  = "Conference Publications",
  abstract  = "We introduce the first program synthesis engine implemented inside
an SMT solver. We present an approach that extracts solution functions from unsatisfiability
proofs of the negated form of synthesis conjectures. We also discuss
novel counterexample-guided techniques for quantifier instantiation that we use
to make finding such proofs practically feasible. A particularly important class of
specifications are single-invocation properties, for which we present a dedicated
algorithm. To support syntax restrictions on generated solutions, our approach
can transform a solution found without restrictions into the desired syntactic
form. As an alternative, we show how to use evaluation function axioms to embed
syntactic restrictions into constraints over algebraic datatypes, and then use an
algebraic datatype decision procedure to drive synthesis. Our experimental evaluation
on syntax-guided synthesis benchmarks shows that our implementation in
the CVC4 SMT solver is competitive with state-of-the-art tools for synthesis."
}

%complete
@inproceedings{BRK+15,
  url       = "http://theory.stanford.edu/~barrett/pubs/BRK+15.pdf",
  author    = "Kshitij Bansal and Andrew Reynolds and Tim King and Clark Barrett and Thomas Wies",
  title     = "Deciding Local Theory Extensions via {E}-matching",
  booktitle = "Proceedings of the $27^{th}$ International Conference on Computer Aided Verification (CAV '15)",
  volume    = 9206,
  number    = 2,
  editor    = "Daniel Kroening and Corina S. P\u{a}s\u{a}reanu",
  pages     = "87--105",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  month     = jul,
  year      = 2015,
  note      = "San Francisco, California",
  category  = "Conference Publications",
  abstract  = "Satisfiability Modulo Theories (SMT) solvers incorporate
decision procedures for theories of data types that commonly occur in
software. This makes them important tools for automating verification
problems. A limitation frequently encountered is that verification problems
are often not fully expressible in the theories supported natively by
the solvers. Many solvers allow the specification of application-specific
theories as quantified axioms, but their handling is incomplete outside
of narrow special cases.
In this work, we show how SMT solvers can be used to obtain complete
decision procedures for local theory extensions, an important class
of theories that are decidable using finite instantiation of axioms. We
present an algorithm that uses E-matching to generate instances incrementally
during the search, significantly reducing the number of generated
instances compared to eager instantiation strategies. We have used
two SMT solvers to implement this algorithm and conducted an extensive
experimental evaluation on benchmarks derived from verification conditions
for heap-manipulating programs. We believe that our results are of
interest to both the users of SMT solvers as well as their developers."
}

%complete
@inproceedings{WB15,
  url       = "http://theory.stanford.edu/~barrett/pubs/WB15.pdf",
  author    = "Wei Wang and Clark Barrett",
  title     = "Cascade (Competition Contribution)",
  booktitle = "Proceedings of the $21^{st}$ International Conference on Tools and Algorithms for the Construction and Analysis of Systems (TACAS '15)",
  volume    = 9035,
  editor    = "Christel Baier and Cesare Tinelli",
  pages     = "420--422",
  series    = "Lecture Notes in Computer Science",
  publisher = "Springer",
  month     = apr,
  year      = 2015,
  note      = "London, United Kingdom",
  category  = "Conference Publications",
  abstract  = "Cascade is a static program analysis tool developed at New
York University. It uses bounded model checking to generate verification
conditions and checks them using an SMT solver which either produces
a proof of correctness or gives a concrete trace showing how an assertion
can fail. It supports the majority of standard C features except for floating
point. A distinguishing feature of Cascade is that its analysis uses a
memory model which divides up memory into several partitions based
on alias information."
}

%complete
@inproceedings{KBT14,
  url       = "http://theory.stanford.edu/~barrett/pubs/KBT14.pdf",
  author    = "Tim King and Clark Barrett and Cesare Tinelli",
  title     = "Leveraging Linear and Mixed Integer Programming for {SMT}",
  booktitle = "Proceedings of the $14^{th}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '14)",
  publisher = "FMCAD Inc.",
  pages     = "139--146",
  month     = oct,
  year      = 2014,
  note      = "Lausanne, Switzerland",
  category  = "Conference Publications",
  abstract  = "SMT solvers combine SAT reasoning with specialized theory
                  solvers to either find a feasible solution to a set of
                  constraints or prove that no such solution exists.  Linear
                  programming (LP) solvers come from the tradition of
                  optimization, and are designed to find feasible solutions
                  that are optimal with respect to some optimization function.
                  Typical LP solvers are designed to solve large systems
                  quickly using floating point arithmetic.  Because floating
                  point arithmetic is inexact, rounding errors can lead to
                  incorrect results, making inexact solvers inappropriate for
                  direct use in theorem proving.  Previous efforts to leverage
                  such solvers in the context of SMT have concluded that in
                  addition to being potentially unsound, such solvers are too
                  heavyweight to compete in the context of SMT.  In this paper,
                  we describe a technique for integrating LP solvers that
                  dramatically improves the performance of SMT solvers without
                  compromising correctness.  These techniques have been
                  implemented using the SMT solver CVC4 and the LP solver GLPK.
                  Experiments show that this implementation outperforms other
                  state-of-the-art SMT solvers on the QF\_LRA SMT-LIB
                  benchmarks and is competitive on the QF\_LIA benchmarks."
}

%complete
@inproceedings{HBJ+14,
  url       = "http://theory.stanford.edu/~barrett/pubs/HBJ+14.pdf",
  author    = "Liana Hadarean and Clark Barrett and Dejan Jovanovi\'c and
               Cesare Tinelli and Kshitij Bansal",
  title     = "A Tale of Two Solvers: Eager and Lazy Approaches to Bit-vectors",
  booktitle = "Proceedings of the $26^{th}$ International Conference on Computer Aided Verification (CAV '14)",
  series    = "Lecture Notes in Computer Science",
  volume    = 8559,
  publisher = "Springer",
  editor    = "Armin Biere and Roderick Bloem",
  pages     = "680--695",
  month     = jul,
  year      = 2014,
  note      = "Vienna, Austria",
  category  = "Conference Publications",
  abstract  = "The standard method for deciding bit-vector constraints is via eager
reduction to propositional logic. This is usually done after first applying powerful
rewrite techniques. While often efficient in practice, this method does not scale on
problems for which top-level rewrites cannot reduce the problem size sufficiently.
A lazy solver can target such problems by doing many satisfiability checks, each
of which only reasons about a small subset of the problem. In addition, the lazy
approach enables a wide range of optimization techniques that are not available
to the eager approach. In this paper we describe the architecture and features
of our lazy solver (LBV). We provide a comparative analysis of the eager and
lazy approaches, and show how they are complementary in terms of the types
of problems they can efficiently solve. For this reason, we propose a portfolio
approach that runs a lazy and eager solver in parallel. Our empirical evaluation
shows that the lazy solver can solve problems none of the eager solvers can and
that the portfolio solver outperforms other solvers both in terms of total number
of problems solved and the time taken to solve them."
}


%complete
@inproceedings{LRT+14,
  url       = "http://theory.stanford.edu/~barrett/pubs/LRT+14.pdf",
  author    = "Tianyi Liang and Andrew Reynolds and Cesare Tinelli and Clark Barrett and Morgan Deters",
  title     = "A {DPLL(T)} Theory Solver for a Theory of Strings and Regular Expressions",
  booktitle = "Proceedings of the $26^{th}$ International Conference on Computer Aided Verification (CAV '14)",
  series    = "Lecture Notes in Computer Science",
  volume    = 8559,
  publisher = "Springer",
  editor    = "Armin Biere and Roderick Bloem",
  pages     = "646--662",
  month     = jul,
  year      = 2014,
  note      = "Vienna, Austria",
  category  = "Conference Publications",
  abstract  = "An increasing number of applications in verification and security rely
on or could benefit from automatic solvers that can check the satisfiability of constraints
over a rich set of data types that includes character strings. Unfortunately,
most string solvers today are standalone tools that can reason only about (some
fragment) of the theory of strings and regular expressions, sometimes with strong
restrictions on the expressiveness of their input language. These solvers are based
on reductions to satisfiability problems over other data types, such as bit vectors,
or to automata decision problems. We present a set of algebraic techniques for
solving constraints over the theory of unbounded strings natively, without reduction
to other problems. These techniques can be used to integrate string reasoning
into general, multi-theory SMT solvers based on the DPLL(T) architecture. We
have implemented them in our SMT solver CVC4 to expand its already large set
of built-in theories to a theory of strings with concatenation, length, and membership
in regular languages. Our initial experimental results show that, in addition,
over pure string problems, CVC4 is highly competitive with specialized string
solvers with a comparable input language."
}


%complete
@inproceedings{WBW14,
  url       = "http://theory.stanford.edu/~barrett/pubs/WBW14.pdf",
  author    = "Wei Wang and Clark Barrett and Thomas Wies",
  title     = "Cascade 2.0",
  booktitle = "Proceedings of the $15^{th}$ International Conference on Verification, Model Checking, and Abstract Interpretation (VMCAI '14)",
  series    = "Lecture Notes in Computer Science",
  volume    = 8318,
  publisher = "Springer Berlin Heidelberg",
  editor    = "Kenneth L. McMillan and Xavier Rival",
  pages     = "142--160",
  month     = jan,
  year      = 2014,
  note      = "San Diego, California",
  category  = "Conference Publications",
  abstract  = "Cascade is a program static analysis tool developed at New
York University. Cascade takes as input a program and a control file.
The control file specifies one or more assertions to be checked together
with restrictions on program behaviors. The tool generates verification
conditions for the specified assertions and checks them using an SMT
solver which either produces a proof or gives a concrete trace showing
how an assertion can fail. Version 2.0 supports the majority of standard
C features except for floating point. It can be used to verify both memory
safety as well as user-defined assertions. In this paper, we describe the
Cascade system including some of its distinguishing features such as its
support for different memory models (trading off precision for scalability)
and its ability to reason about linked data structures."
}

%complete
@inproceedings{KBD13,
  url       = "http://theory.stanford.edu/~barrett/pubs/KBD13.pdf",
  author    = "Timothy King and Clark Barrett and Bruno Dutertre",
  title     = "Simplex with Sum of Infeasibilities for {SMT}",
  booktitle = "Proceedings of the $13^{th}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '13)",
  publisher = "FMCAD Inc.",
  pages     = "189--196",
  month     = oct,
  year      = 2013,
  note      = "Portland, Oregon",
  category  = "Conference Publications",
  abstract  = "The de facto standard for state-of-the-art real and
integer linear reasoning within Satisfiability Modulo Theories
(SMT) solvers is the Simplex for DPLL(T) algorithm given by
Dutertre and de Moura. This algorithm works by performing a
sequence of local optimization operations. While the algorithm
is generally efficient in practice, its local pivoting heuristics
lead to slow convergence on some problems. More traditional
Simplex algorithms minimize a global criterion to determine the
feasibility of the input constraints. We present a novel Simplexbased
decision procedure for use in SMT that minimizes the sum
of infeasibilities of the constraints. Experimental results show that
this new algorithm is comparable with or outperforms Simplex
for DPLL(T) on a broad set of benchmarks."
}

%complete
@inproceedings{JBdM13,
  url       = "http://theory.stanford.edu/~barrett/pubs/JBdM13.pdf",
  author    = "Dejan Jovanovi\'{c} and Clark Barrett and Leonardo de Moura",
  title     = "The Design and Implementation of the Model Constructing Satisfiability Calculus",
  booktitle = "Proceedings of the $13^{th}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '13)",
  publisher = "FMCAD Inc.",
  pages     = "173--180",
  month     = oct,
  year      = 2013,
  note      = "Portland, Oregon",
  category  = "Conference Publications",
  abstract  = "We present the design and implementation of the
Model Constructing Satisfiability (MCSat) calculus. The MCSat
calculus generalizes ideas found in CDCL-style propositional SAT
solvers to SMT solvers, and provides a common framework
where recent model-based procedures and techniques can be
justified and combined. We describe how to incorporate support
for linear real arithmetic and uninterpreted function symbols
in the calculus. We report encouraging experimental results,
where MCSat performs competitive with the state-of-the art
SMT solvers without using pre-processing techniques and ad-hoc
optimizations. The implementation is flexible, additional plugins
can be easily added, and the code is freely available."
}

%complete
@inproceedings{BDD13,
  url       = "http://theory.stanford.edu/~barrett/pubs/BDD13.pdf",
  author    = "Clark Barrett and Stephan\'{e} Demri and Morgan Deters",
  title     = "Witness Runs for Counter Machines",
  booktitle = "Proceedings of the $9^{th}$ International Symposium on Frontiers of Combining Systems (FroCoS '13)",
  series    = "Lecture Notes in Artificial Intelligence",
  volume    = 8152,
  publisher = "Springer Berlin Heidelberg",
  editor    = "Fontaine, Pascal and Ringeissen, Christophe and Schmidt, Renate A.",
  pages     = "120-150",
  doi       = "10.1007/978-3-642-40885-4_9",
  isbn      = "978-3-642-40884-7",
  month     = sep,
  year      = 2013,
  note      = "Nancy, France",
  category  = "Conference Publications",
  abstract  = "In this paper, we present recent results about the verification of counter machines by using decision procedures for Presburger arithmetic.  We recall several known classes of counter machines for which the reachability sets are Presburger-definable as well as temporal logics with arithmetical constraints.  We discuss issues related to flat counter machines, path schema enumeration, and the use of SMT solers."
}

%complete
@inproceedings{RTG+13,
  url       = "http://theory.stanford.edu/~barrett/pubs/RTG+13.pdf",
  author    = "Andrew Reynolds and Cesare Tinelli and Amit Goel and Sava Krstic and Morgan Deters and Clark Barrett",
  title     = "Quantifier Instantiation Techniques for Finite Model Finding in {SMT}",
  booktitle = "Proceedings of the $24^{th}$ International Conference on Automated Deduction (CADE '13)",
  series    = "Lecture Notes in Computer Science",
  volume    = 7898,
  publisher = "Springer Berlin Heidelberg",
  editor    = "Bonacina, Maria Paola",
  pages     = "377-391",
  doi       = "10.1007/978-3-642-38574-2_26",
  isbn      = "978-3-642-38573-5",
  year      = 2013,
  note      = "Lake Placid, New York",
  category  = "Conference Publications",
  abstract  = "SMT-based applications increasingly rely on SMT solvers being able
to deal with quantified formulas. Current work shows that for formulas with quantifiers
over uninterpreted sorts counter-models can be obtained by integrating a
finite model finding capability into the architecture of a modern SMT solver. We
examine various strategies for on-demand quantifier instantiation in this setting.
Here, completeness can be achieved by considering all ground instances over the
finite domain of each quantifier. However, exhaustive instantiation quickly becomes
unfeasible with larger domain sizes. We propose instantiation strategies to
identify and consider only a selection of ground instances that suffices to determine
the satisfiability of the input formula. We also examine heuristic quantifier
instantiation techniques such as E-matching for the purpose of accelerating the
search. We give experimental evidence that our approach is practical for use in
industrial applications and is competitive with other approaches."
}

%complete
@inproceedings{JB11-FroCoS,
  url       = "http://theory.stanford.edu/~barrett/pubs/JB11-FroCoS.pdf",
  author    = "Dejan Jovanovi\'{c} and Clark Barrett",
  title     = "Sharing is Caring: Combination of Theories",
  booktitle = "Proceedings of the $8^{th}$ International Symposium on Frontiers of Combining Systems (FroCoS '11)",
  series    = "Lecture Notes in Computer Science",
  volume    = 6989,
  publisher = "Springer",
  editor    = "Cesare Tinelli and Viorica Sofronie-Stokkermans",
  pages     = "195--210",
  month     = oct,
  year      = 2011,
  note      = {Saarbr\"{u}cken, Germany},
  category  = "Conference Publications",
  abstract  = "One of the main shortcomings of the traditional methods for combining theories is the complexity of guessing the arrangement of the variables shared by the individual theories. This paper presents a reformulation of the Nelson-Oppen method that takes into account explicit equality propagation and can ignore pairs of shared variables that the theories do not care about. We show the correctness of the new approach and present care functions for the theory of uninterpreted functions and the theory of arrays. The effectiveness of the new method is illustrated by experimental results demonstrating a dramatic performance improvement on benchmarks combining arrays and bit-vectors."
}

%complete
@inproceedings{BCD+11,
  url       = "http://theory.stanford.edu/~barrett/pubs/BCD+11.pdf",
  author    = "Clark Barrett and Christopher L. Conway and Morgan Deters and
               Liana Hadarean and Dejan Jovanovi\'c and Tim King and
               Andrew Reynolds and Cesare Tinelli",
  title     = "{CVC4}",
  booktitle = "Proceedings of the $23^{rd}$ International Conference on Computer Aided Verification (CAV '11)",
  series    = "Lecture Notes in Computer Science",
  volume    = 6806,
  publisher = "Springer",
  editor    = "Ganesh Gopalakrishnan and Shaz Qadeer",
  pages     = "171--177",
  month     = jul,
  year      = 2011,
  note      = "Snowbird, Utah",
  category  = "Conference Publications",
  abstract  = "CVC4 is the latest version of the Cooperating Validity Checker. A joint project of NYU and U Iowa, CVC4 aims to support the useful feature set of CVC3 and SMT-LIBv2 while optimizing the design of the core system architecture and decision procedures to take advantage of recent engineering and algorithmic advances. CVC4 represents a completely new code base; it is a from-scratch rewrite of CVC3, and many subsystems have been completely redesigned. Additional decision procedures for CVC4 are currently under development, but for what it currently achieves, it is a lighter-weight and higher-performing tool than CVC3. We describe the system architecture, subsystems of note, and discuss some applications and continuing work."
}

%complete
@inproceedings{JB10-LPAR,
  url       = "http://theory.stanford.edu/~barrett/pubs/JB10-LPAR.pdf",
  author    = "Dejan Jovanovi\'{c} and Clark Barrett",
  title     = "Polite Theories Revisited",
  booktitle = "Proceedings of the $17^{th}$ International Conference on Logic for Programming, Artificial Intelligence, and Reasoning (LPAR '10)",
  series    = "Lecture Notes in Computer Science",
  volume    = 6397,
  publisher = "Springer",
  editor    = {Christian G. Ferm\"{u}ller and Andrei Voronkov},
  pages     = "402--416",
  month     = oct,
  year      = 2010,
  isbn      = "3-642-16241-X, 978-3-642-16241-1",
  issn      = "0302-9743",
  note      = "Yogyakarta, Indonesia",
  category  = "Conference Publications",
  abstract  = "The classic method of Nelson and Oppen for combining decision procedures requires the theories to be stably-infinite. Unfortunately, some important theories do not fall into this category (e.g. the theory of bit-vectors). To remedy this problem, previous work introduced the notion of polite theories. Polite theories can be combined with any other theory using an extension of the Nelson-Oppen approach. In this paper we revisit the notion of polite theories, fixing a subtle flaw in the original definition. We give a new combination theorem which specifies the degree to which politeness is preserved when combining polite theories. We also give conditions under which politeness is preserved when instantiating theories by identifying two sorts. These results lead to a more general variant of the theorem for combining multiple polite theories."
}

%complete
@inproceedings{CB10,
  url       = "http://theory.stanford.edu/~barrett/pubs/CB10.pdf",
  author    = "Christopher L. Conway and Clark Barrett",
  title     = "Verifying Low-Level Implementations of High-Level Datatypes",
  booktitle = "Proceedings of the $22^{nd}$ International Conference on Computer Aided Verification (CAV '10)",
  series    = "Lecture Notes in Computer Science",
  volume    = 6174,
  publisher = "Springer",
  editor    = "Tayssir Touili and Byron Cook and Paul Jackson",
  pages     = "306--320",
  month     = jul,
  year      = 2010,
  note      = "Edinburgh, Scotland",
  category  = "Conference Publications",
  abstract  = "For efficiency and portability, network packet processing code is typically written in low-level languages and makes use of bit-level operations to compactly represent data. Although packet data is highly structured, low-level implementation details make it difficult to verify that the behavior of the code is consistent with high-level data invariants. We introduce a new approach to the verification problem, using a high-level definition of packet types as part of a specification rather than an implementation. The types are not used to check the code directly; rather, the types introduce functions and predicates that can be used to assert the consistency of code with programmer-defined data assertions. We describe an encoding of these types and functions using the theories of inductive datatypes, bit vectors, and arrays in the Cvc SMT solver. We present a case study in which the method is applied to open-source networking code and verified within the Cascade verification platform."
}

%complete
@inproceedings{CDN+08,
  url       = "http://theory.stanford.edu/~barrett/pubs/CDN+08.pdf",
  author    = "Christopher L. Conway and Dennis Dams and Kedar S. Namjoshi and Clark Barrett",
  title     = "Pointer Analysis, Conditional Soundness, and Proving the Absence of Errors",
  booktitle = "Proceedings of the $15^{th}$ International Static Analysis Symposium (SAS '08)",
  series    = "Lecture Notes in Computer Science",
  volume    = 5079,
  publisher = "Springer",
  editor    = "Mar\'{i}a Alpuente and Germ\'{a}n Vidal",
  pages     = "62--77",
  month     = jul,
  year      = 2008,
  note      = "Valencia, Spain",
  category  = "Conference Publications",
  abstract  = "It is well known that the use of points-to information can
substantially improve the accuracy of a static program analysis. Commonly
used algorithms for computing points-to information are known
to be sound only for memory-safe programs. Thus, it appears problematic
to utilize points-to information to verify the memory safety property
without giving up soundness. We show that a sound combination is possible,
even if the points-to information is computed separately and only
conditionally sound. This result is based on a refined statement of the
soundness conditions of points-to analyses and a general mechanism for
composing conditionally sound analyses."
}

%complete
@inproceedings{GBT07,
  url       = "http://theory.stanford.edu/~barrett/pubs/GBT07.pdf",
  author    = "Yeting Ge and Clark Barrett and Cesare Tinelli",
  title     = "Solving Quantified Verification Conditions using Satisfiability Modulo Theories",
  booktitle = "Proceedings of the $21^{st}$ International Conference on Automated Deduction (CADE '07)",
  series    = "Lecture Notes in Artificial Intelligence",
  volume    = 4603,
  publisher = "Springer-Verlag",
  editor    = "Frank Pfenning",
  pages     = "167--182",
  month     = jul,
  year      = 2007,
  note      = "Bremen, Germany",
  category  = "Conference Publications",
  abstract  = "First order logic provides a convenient formalism for describing
a wide variety of verification conditions. Two main approaches to
checking such conditions are pure first order automated theorem proving
(ATP) and automated theorem proving based on satisfiability modulo
theories (SMT). Traditional ATP systems are designed to handle quantifiers
easily, but often have difficulty reasoning with respect to theories.
SMT systems, on the other hand, have built-in support for many useful
theories, but have a much more difficult time with quantifiers. One clue
on how to get the best of both worlds can be found in the legacy system
Simplify which combines built-in theory reasoning with quantifier instantiation
heuristics. Inspired by Simplify and motivated by a desire to
provide a competitive alternative to ATP systems, this paper describes a
methodology for reasoning about quantifiers in SMT systems. We present
the methodology in the context of the Abstract DPLL Modulo Theories
framework. Besides adapting many of Simplify’s techniques, we also introduce
a number of new heuristics. Most important is the notion of
instantiation level which provides an effective mechanism for prioritizing
and managing the large search space inherent in quantifier instantiation
techniques. These techniques have been implemented in the SMT system
CVC3. Experimental results show that our methodology enables CVC3
to solve a significant number of benchmarks that were not solvable with
any previous approach."
}

%complete
@inproceedings{BT07,
  url       = "http://theory.stanford.edu/~barrett/pubs/BT07.pdf",
  author    = "Clark Barrett and Cesare Tinelli",
  title     = "{CVC3}",
  booktitle = "Proceedings of the $19^{th}$ International Conference on Computer Aided Verification (CAV '07)",
  series    = "Lecture Notes in Computer Science",
  volume    = 4590,
  publisher = "Springer-Verlag",
  editor    = "Werner Damm and Holger Hermanns",
  pages     = "298--302",
  month     = jul,
  year      = 2007,
  note      = "Berlin, Germany",
  category  = "Conference Publications",
  abstract  = "CVC3, a joint project of NYU and U Iowa, is the new and latest version
of the Cooperating Validity Checker. CVC3 extends and builds on the functionality
of its predecessors and includes many new features such as support for
additional theories, an abstract architecture for Boolean reasoning, and SMT-LIB
compliance. We describe the system and discuss some applications and continuing
work."
}

%complete
@inproceedings{BNO+06,
  url       = "http://theory.stanford.edu/~barrett/pubs/BNO+06.pdf",
  author    = "Clark Barrett and Robert Nieuwenhuis and Albert Oliveras and Cesare Tinelli",
  title     = "Splitting on Demand in {SAT} Modulo Theories",
  booktitle = "Proceedings of the $13^{th}$ International Conference on Logic for Programming, Artificial Intelligence, and Reasoning (LPAR '06)",
  series    = "Lecture Notes in Computer Science",
  volume    = 4246,
  publisher = "Springer-Verlag",
  editor    = "Miki Hermann and Andrei Voronkov",
  pages     = "512--526",
  month     = nov,
  year      = 2006,
  note      = "Phnom Penh, Cambodia",
  category  = "Conference Publications",
  abstract  = "Lazy algorithms for Satisfiability Modulo Theories (SMT)
combine a generic DPLL-based SAT engine with a theory solver for
the given theory T that can decide the T-consistency of conjunctions
of ground literals. For many theories of interest, theory solvers need to
reason by performing internal case splits. Here we argue that it is more
convenient to delegate these case splits to the DPLL engine instead. The
delegation can be done on demand for solvers that can encode their internal
case splits into one or more clauses, possibly including new constants
and literals. This results in drastically simpler theory solvers. We present
this idea in an improved version of DPLL(T), a general SMT architecture
for the lazy approach, and formalize and prove it correct in an extension
of Abstract DPLL Modulo Theories, a framework for modeling and
reasoning about lazy algorithms for SMT. A remarkable additional feature
of the architecture, also discussed in the paper, is that it naturally
includes an efficient Nelson-Oppen-like combination of multiple theories
and their solvers."
}

%complete
@inproceedings{SB06,
  url       = "http://theory.stanford.edu/~barrett/pubs/SB06.pdf",
  author    = "Nikhil Sethi and Clark Barrett",
  title     = "{CASCADE}: C Assertion Checker and Deductive Engine",
  booktitle = "Proceedings of the $18^{th}$ International Conference on Computer Aided Verification (CAV '06)",
  series    = "Lecture Notes in Computer Science",
  volume    = 4144,
  publisher = "Springer-Verlag",
  editor    = "Thomas Ball and Robert B. Jones",
  pages     = "166--169",
  month     = aug,
  year      = 2006,
  note      = "Seattle, Washington",
  category  = "Conference Publications",
  abstract  = "We present a tool, called Cascade, to check assertions in C
programs as part of a multi-stage verification strategy. Cascade takes
as input a C program and a control file (the output of an earlier stage)
that specifies one or more assertions to be checked together with (optionally)
some restrictions on program behaviors. For each assertion, Cascade
produces either a concrete trace violating the assertion or a deduction
(proof) that the assertion cannot be violated."
}

%complete
@inproceedings{BdMS05-CAV,
  url       = "http://theory.stanford.edu/~barrett/pubs/BdMS05-CAV.pdf",
  author    = "Clark Barrett and Leonardo de Moura and Aaron Stump",
  title     = "{SMT-COMP}: Satisfiability Modulo Theories Competition",
  booktitle = "Proceedings of the $17^{th}$ International Conference on Computer Aided Verification (CAV '05)",
  series    = "Lecture Notes in Computer Science",
  volume    = 3576,
  publisher = "Springer-Verlag",
  editor    = "Kousha Etessami and Sriram K. Rajamani",
  pages     = "20--23",
  month     = jul,
  year      = 2005,
  note      = "Edinburgh, Scotland",
  category  = "Conference Publications",
}

%complete
@inproceedings{BFG+05,
  url       = "http://theory.stanford.edu/~barrett/pubs/BFG+05.pdf",
  author    = "Clark Barrett and Yi Fang and Ben Goldberg and Ying Hu and Amir Pnueli and Lenore Zuck",
  title     = "{TVOC}: A Translation Validator for Optimizing Compilers",
  booktitle = "Proceedings of the $17^{th}$ International Conference on Computer Aided Verification (CAV '05)",
  series    = "Lecture Notes in Computer Science",
  volume    = 3576,
  publisher = "Springer-Verlag",
  editor    = "Kousha Etessami and Sriram K. Rajamani",
  pages     = "291--295",
  month     = jul,
  year      = 2005,
  note      = "Edinburgh, Scotland",
  category  = "Conference Publications",
  abstract  = "We describe a tool called TVOC, that uses the translation
validation approach to check the validity of compiler optimizations: for
a given source program, TVOC proves the equivalence of the source code
and the target code produced by running the compiler. There are two
phases to the verification process: the first phase verifies loop transformations
using the proof rule permute; the second phase verifies structure-preserving
optimizations using the proof rule Validate. Verification conditions
are validated using the automatic theorem prover CVC Lite."
}

%complete
@inproceedings{HBG04,
  url       = "http://theory.stanford.edu/~barrett/pubs/HBG04.pdf",
  author    = "Ying Hu and Clark Barrett and Benjamin Goldberg",
  title     = "Theory and Algorithms for the Generation and Validation of Speculative Loop Optimizations",
  booktitle = "Proceedings of the $2^{nd}$ IEEE International Conference on Software Engineering and Formal Methods (SEFM '04)",
  publisher = "IEEE Computer Society",
  pages     = "281--289",
  month     = sep,
  year      = 2004,
  note      = "Beijing, China",
  category  = "Conference Publications",
  abstract  = "Translation validation is a technique that verifies the results
of every run of a translator, such as a compiler, instead
of the translator itself. Previous papers by the authors
and others have described translation validation for compilers
that perform loop optimizations (such as interchange,
tiling, fusion, etc), using a proof rule that treats loop optimizations
as permutations."
}

%complete
@inproceedings{BB04,
  url       = "http://theory.stanford.edu/~barrett/pubs/BB04.pdf",
  author    = "Clark Barrett and Sergey Berezin",
  title     = "{CVC L}ite: A New Implementation of the Cooperating Validity Checker",
  booktitle = "Proceedings of the $16^{th}$ International Conference on Computer Aided Verification (CAV '04)",
  series    = "Lecture Notes in Computer Science",
  volume    = 3114,
  publisher = "Springer-Verlag",
  editor    = "Rajeev Alur and Doron A. Peled",
  pages     = "515--518",
  month     = jul,
  year      = 2004,
  note      = "Boston, Massachusetts",
  category  = "Conference Publications",
}

%complete
@inproceedings{SBD02,
  url       = "http://theory.stanford.edu/~barrett/pubs/SBD02.pdf",
  author    = "Aaron Stump and Clark W. Barrett and David L. Dill",
  title     = "{CVC}: A Cooperating Validity Checker",
  booktitle = "Proceedings of the $14^{th}$ International Conference on Computer Aided Verification (CAV '02)",
  series    = "Lecture Notes in Computer Science",
  volume    = 2404,
  publisher = "Springer-Verlag",
  editor    = "Ed Brinksma and Kim Guldstrand Larsen",
  pages     = "500--504",
  month     = jul,
  year      = 2002,
  note      = "Copenhagen, Denmark",
  category  = "Conference Publications",
}

%complete
@inproceedings{BDS02-CAV02,
  url       = "http://theory.stanford.edu/~barrett/pubs/BDS02-CAV02.pdf",
  author    = "Clark W. Barrett and David L. Dill and Aaron Stump",
  title     = "Checking Satisfiability of First-Order Formulas by Incremental Translation to {SAT}",
  booktitle = "Proceedings of the $14^{th}$ International Conference on Computer Aided Verification (CAV '02)",
  series    = "Lecture Notes in Computer Science",
  volume    = 2404,
  publisher = "Springer-Verlag",
  editor    = "Ed Brinksma and Kim Guldstrand Larsen",
  pages     = "236--249",
  month     = jul,
  year      = 2002,
  note      = "Copenhagen, Denmark",
  category  = "Conference Publications",
}

%complete
@inproceedings{SBDL01,
  url       = "http://theory.stanford.edu/~barrett/pubs/SBDL01.pdf",
  author    = "Aaron Stump and Clark W. Barrett and David L. Dill and Jeremy Levitt",
  title     = "A Decision Procedure for an Extensional Theory of Arrays",
  booktitle = "Proceedings of the $16^{th}$ IEEE Symposium on Logic in Computer Science (LICS '01)",
  publisher = "IEEE Computer Society",
  pages     = "29--37",
  month     = jun,
  year      = 2001,
  note      = "Boston, Massachusetts",
  category  = "Conference Publications",
}

%complete
@inproceedings{BDS00,
  url       = "http://theory.stanford.edu/~barrett/pubs/BDS00.pdf",
  author    = "Clark W. Barrett and David L. Dill and Aaron Stump",
  title     = "A Framework for Cooperating Decision Procedures",
  booktitle = "Proceedings of the $17^{th}$ International Conference on Computer-Aided Deduction (CADE '00)",
  series    = "Lecture Notes in Artificial Intelligence",
  volume    = 1831,
  publisher = "Springer-Verlag",
  editor    = "David McAllester",
  pages     = "79--97",
  month     = jun,
  year      = 2000,
  note      = "Pittsburgh, Pennsylvania",
  category  = "Conference Publications",
}

%complete
@inproceedings{BDL98,
  url       = "http://theory.stanford.edu/~barrett/pubs/BDL98.pdf",
  author    = "Clark W. Barrett and David L. Dill and Jeremy R. Levitt",
  title     = "A Decision Procedure for Bit-vector Arithmetic",
  booktitle = "Proceedings of the $35^{th}$ Design Automation Conference (DAC '98)",
  publisher = "Association for Computing Machinery",
  pages     = "522--527",
  month     = jun,
  year      = 1998,
  note      = "San Francisco, California.  {\em Best paper award.}",
  category  = "Conference Publications",
}

%complete
@inproceedings{SDB96,
  url       = "http://theory.stanford.edu/~barrett/pubs/SDB96.pdf",
  author    = "Jeffrey X. Su and David L. Dill and Clark W. Barrett",
  title     = "Automatic Generation of Invariants in Processor Verification",
  booktitle = "Proceedings of the $1^{st}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '96)",
  series    = "Lecture Notes in Computer Science",
  volume    = 1166,
  publisher = "Springer-Verlag",
  editor    = "Mandayam Srivas and Albert Camilleri",
  pages     = "377--388",
  month     = nov,
  year      = 1996,
  note      = "Palo Alto, California",
  category  = "Conference Publications"
}

%complete
@inproceedings{BDL96,
  url       = "http://theory.stanford.edu/~barrett/pubs/BDL96.pdf",
  author    = "Clark W. Barrett and David L. Dill and Jeremy R. Levitt",
  title     = "Validity Checking for Combinations of Theories with Equality",
  booktitle = "Proceedings of the $1^{st}$ International Conference on Formal Methods In Computer-Aided Design (FMCAD '96)",
  series    = "Lecture Notes in Computer Science",
  volume    = 1166,
  publisher = "Springer-Verlag",
  editor    = "Mandayam Srivas and Albert Camilleri",
  pages     = "187--201",
  month     = nov,
  year      = 1996,
  note      = "Palo Alto, California",
  category  = "Conference Publications",
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Workshop Papers
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@inproceedings{MWT+20,
  url       = "http://theory.stanford.edu/~barrett/pubs/MWT+20.pdf",
  author    = "Makai Mann and Amalee Wilson and Cesare Tinelli and Clark Barrett",
  title     = "Smt-Switch: A Solver-Agnostic C++ {API} for {SMT} Solving (Extended Abstract)",
  booktitle = "Proceedings of the $18^{th}$ International Workshop on Satisfiability Modulo Theories (SMT '20)",
  month     = jul,
  year      = 2020,
  category  = "Refereed Workshop Publications",
  abstract  = "This extended abstract describes work in progress on Smt-Switch,
                  an open-source, solver-agnostic API for SMT
                  solving. Smt-Switch provides an abstract interface, which can
                  be implemented by different SMT solvers. Smt-Switch provides
                  simple, uniform, and high-performance access to SMT solving
                  for applications in areas such as automated reasoning,
                  planning, and formal verification. The interface allows the
                  user to create, traverse, and manipulate terms, as well as to
                  dynamically dispatch queries to different underlying SMT
                  solvers."
}

%complete
@inproceedings{EVZ+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/EVZ+19.pdf",
  author    = "Burak Ekici and Arjun Viswanathan and Yoni Zohar and Clark Barrett and Cesare Tinelli",
  title     = "Verifying Bit-vector Invertibility Conditions in Coq (Extended Abstract)",
  booktitle = "Proceedings of the Sixth Workshop on Proof eXchange for Theorem Proving (PxTP '19)",
  series    = "Electronic Proceedings in Theoretical Computer Science",
  volume    = 301,
  editor    = "Giselle Reis and Haniel Barbosa",
  pages     = "18--26",
  month     = aug,
  year      = 2019,
  note      = "Natal, Brazil",
  category  = "Refereed Workshop Publications",
  abstract  = "This work is a part of an ongoing effort to prove the
                  correctness of invertibility conditions for the theory of
                  fixed-width bit-vectors, which are used to solve quantified
                  bit-vector formulas in the Satisfiability Modulo Theories
                  (SMT) solver CVC4. While many of these were proved in a
                  completely automatic fashion for any bit-width, some were
                  only proved for bit-widths up to 65, even though they are
                  being used to solve formulas over arbitrary bit-widths. In
                  this paper we describe our initial efforts in proving a
                  subset of these invertibility conditions in the Coq proof
                  assistant. We describe the Coq library that we use, as well
                  as the extensions that we introduced to it."
}

%complete
@inproceedings{KBK+19,
  url       = "http://theory.stanford.edu/~barrett/pubs/KBK+19.pdf",
  author    = "Yafim Kazak and Clark Barrett and Guy Katz and Michael Schapira",
  title     = "Verifying Deep-RL-Driven Systems",
  booktitle = "Proceedings of the 2019 Workshop on Network Meets AI \& ML (NetAI '19)",
  publisher = "Association for Computing Machinery",
  pages     = "83--89",
  month     = aug,
  year      = 2019,
  note      = "Beijing, China",
  doi       = "10.1145/3341216.3342218",
  isbn      = "9781450368728",
  category  = "Refereed Workshop Publications",
  abstract  = "Deep reinforcement learning (RL) has recently been successfully
                  applied to networking contexts including routing, flow
                  scheduling, congestion control, packet classification, cloud
                  resource management, and video streaming. Deep-RL-driven
                  systems automate decision making, and have been shown to
                  outperform state-of-the-art handcrafted systems in important
                  domains. However, the (typical) non-explainability of
                  decisions induced by the deep learning machinery employed by
                  these systems renders reasoning about crucial system
                  properties, including correctness and security, extremely
                  difficult. We show that despite the obscurity of decision
                  making in these contexts, verifying that deep-RL-driven
                  systems adhere to desired, designer-specified behavior, is
                  achievable. To this end, we initiate the study of formal
                  verification of deep RL and present Verily, a system for
                  verifying deep-RL-based systems that leverages recent
                  advances in verification of deep neural networks. We employ
                  Verily to verify recently-introduced deep-RL-driven systems
                  for adaptive video streaming, cloud resource management, and
                  Internet congestion control. Our results expose scenarios in
                  which deep-RL-driven decision making yields undesirable
                  behavior. We discuss guidelines for building deep-RL-driven
                  systems that are both safer and easier to verify."
}

%complete (not published)
@inproceedings{RBN+18,
  url       = "http://theory.stanford.edu/~barrett/pubs/RBN+18.pdf",
  author    = "Andrew Reynolds and Haniel Barbosa and Aina Niemetz and Andres N{\"o}tzli and Mathias Preiner and Clark Barrett and Cesare Tinelli",
  title     = "Rewrites for {SMT} Solvers using Syntax-Guided Enumeration",
  booktitle = "Proceedings of the $16^{th}$ International Workshop on Satisfiability Modulo Theories (SMT '18)",
  month     = jul,
  year      = 2018,
  note      = "Oxford, United Kingdom",
  category  = "Refereed Workshop Publications",
  abstract  = "In this paper, we explore a development paradigm for SMT solver
                  developers where rewrite rules are suggested to the developer
                  using syntax-guided enumeration. We capitalize on the recent
                  advances in enumerative syntax-guided synthesis (SyGuS)
                  techniques for efficiently enumerating terms in a grammar of
                  interest, and novel sampling techniques for testing
                  equivalence between terms. We present our preliminary
                  experience with this feature in the SMT solver cvc4, showing
                  its impact on its rewriting capabilities using several
                  internal metrics, and its subsequent impact on solving
                  bit-vector and string constraints."
}

%complete
@inproceedings{KBD+17-FVAV,
  url       = "http://eptcs.web.cse.unsw.edu.au/paper.cgi?FVAV2017.3",
  author    = "Guy Katz and Clark Barrett and David L. Dill and Kyle Julian and Mykel J. Kochenderfer",
  title     = "Towards Proving the Adversarial Robustness of Deep Neural Networks",
  booktitle = "Proceedings of the First Workshop on Formal Verification of Autonomous Vehicles (FVAV '17)",
  series    = "Electronic Proceedings in Theoretical Computer Science",
  volume    = 257,
  editor    = "Lukas Bulwahn and Maryam Kamali and Sven Linker",
  pages     = "19--26",
  month     = sep,
  year      = 2017,
  note      = "Turin, Italy",
  category  = "Refereed Workshop Publications",
  abstract  = "
Autonomous vehicles are highly complex systems, required to function reliably in a wide variety of situations. Manually crafting software controllers for these vehicles is difficult, but there has been some success in using deep neural networks generated using machine-learning. However, deep neural networks are opaque to human engineers, rendering their correctness very difficult to prove manually; and existing automated techniques, which were not designed to operate on neural networks, fail to scale to large systems. This paper focuses on proving the adversarial robustness of deep neural networks, i.e. proving that small perturbations to a correctly-classified input to the network cannot cause it to be misclassified. We describe some of our recent and ongoing work on verifying the adversarial robustness of networks, and discuss some of the open questions we have encountered and how they might be addressed.
"
}

%complete (not published)
@inproceedings{KB11,
  url       = "http://theory.stanford.edu/~barrett/pubs/KB11.pdf",
  author    = "Tim King and Clark Barrett",
  title     = "Exploring and Categorizing Error Spaces using {BMC} and {SMT}",
  booktitle = "Proceedings of the $9^{th}$ International Workshop on Satisfiability Modulo Theories (SMT '11)",
  month     = jul,
  year      = 2011,
  note      = "Snowbird, Utah",
  category  = "Refereed Workshop Publications"
}

%complete (not published)
@inproceedings{BST10,
  url       = "http://theory.stanford.edu/~barrett/pubs/BST10.pdf",
  author    = "Clark Barrett and Aaron Stump and Cesare Tinelli",
  title     = "The {SMT-LIB} Standard -- Version 2.0",
  booktitle = "Proceedings of the $8^{th}$ International Workshop on Satisfiability Modulo Theories (SMT '10)",
  month     = jul,
  year      = 2010,
  note      = "Edinburgh, Scotland",
  category  = "Refereed Workshop Publications",
}

%complete (not published)
@inproceedings{JB10-SMT,
  url       = "http://theory.stanford.edu/~barrett/pubs/JB10-SMT.pdf",
  author    = "Dejan Jovanovi\'{c} and Clark Barrett",
  title     = "Sharing is Caring",
  booktitle = "Proceedings of the $8^{th}$ International Workshop on Satisfiability Modulo Theories (SMT '10)",
  month     = jul,
  year      = 2010,
  note      = "Edinburgh, Scotland",
  category  = "Refereed Workshop Publications",
}

%complete (not published)
@inproceedings{RHT+10,
  url       = "http://theory.stanford.edu/~barrett/pubs/RHT+10.pdf",
  author    = "Andrew Reynolds and Liana Hadarean and Cesare Tinelli and Yeting Ge and Aaron Stump and Clark Barrett",
  title     = "Comparing Proof Systems for Linear Real Arithmetic with {LFSC}",
  booktitle = "Proceedings of the $8^{th}$ International Workshop on Satisfiability Modulo Theories (SMT '10)",
  month     = jul,
  year      = 2010,
  note      = "Edinburgh, Scotland",
  category  = "Refereed Workshop Publications",
}

%complete
@inproceedings{BST07-PDPAR,
  url       = "http://theory.stanford.edu/~barrett/pubs/BST07-PDPAR.pdf",
  author    = "Clark Barrett and Igor Shikanian and Cesare Tinelli",
  title     = "An Abstract Decision Procedure for Satisfiability in the Theory of Recursive Data Types",
  booktitle = "Combined Proceedings of the $4^{th}$ Workshop on Pragmatics of Decision Procedures in Automated Reasoning (PDPAR '06) and the $1^{st}$ International Workshop on Probabilistic Automata and Logics (PaUL '06)",
  series    = "Electronic Notes in Theoretical Computer Science",
  volume    = "174(8)",
  publisher = "Elsevier",
  editor    = "Byron Cook and Roberto Sebastiani",
  pages     = "23--37",
  month     = jun,
  year      = 2007,
  note      = "Seattle, Washington",
  category  = "Refereed Workshop Publications",
}

%complete
@inproceedings{MBG06,
  url       = "http://theory.stanford.edu/~barrett/pubs/MBG06.pdf",
  author    = "Sean McLaughlin and Clark Barrett and Yeting Ge",
  title     = "Cooperating Theorem Provers: A Case Study Combining {HOL-L}ight and {CVC L}ite",
  booktitle = "Proceedings of the $3^{rd}$ Workshop on Pragmatics of Decision Procedures in Automated Reasoning (PDPAR '05)",
  series    = "Electronic Notes in Theoretical Computer Science",
  volume    = "144(2)",
  publisher = "Elsevier",
  editor    = "Alessandro Armando and Alessandro Cimatti",
  pages     = "43--51",
  month     = jan,
  year      = 2006,
  note      = "Edinburgh, Scotland",
  category  = "Refereed Workshop Publications",
}

%complete
@InProceedings{HBG+05,
  url       = "http://theory.stanford.edu/~barrett/pubs/HBG+05.pdf",
  author    = "Ying Hu and Clark Barrett and Benjamin Goldberg and Amir Pnueli",
  title     = "Validating More Loop Optimizations",
  booktitle = "Proceedings of the $4^{th}$ International Workshop on Compiler Optimization meets Compiler Verificaiton (COCV '05)",
  series    = "Electronic Notes in Theoretical Computer Science",
  volume    = "141(2)",
  publisher = "Elsevier",
  editor    = "J. Knoop and G.C. Necula and W. Zimmermann",
  pages     = "69--84",
  month     = dec,
  year      = 2005,
  note      = "Edinburgh, Scotland",
  category  = "Refereed Workshop Publications"
}

%complete
@InProceedings{GZB05,
  url       = "http://theory.stanford.edu/~barrett/pubs/GZB05.pdf",
  author    = "Benjamin Goldberg and Lenore Zuck and Clark Barrett",
  title     = "Into the Loops: Practical Issues in Translation Validation for Optimizing Compilers",
  booktitle = "Proceedings of the $3^{rd}$ International Workshop on Compiler Optimization meets Compiler Verificaiton (COCV '04)",
  series    = "Electronic Notes in Theoretical Computer Science",
  volume    = "132(1)",
  publisher = "Elsevier",
  editor    = "J. Knoop and G.C. Necula and W. Zimmermann",
  pages     = "53--71",
  month     = may,
  year      = 2005,
  note      = "Barcelona, Spain",
  category  = "Refereed Workshop Publications"
}

%complete
@inproceedings{BBS+05,
  url       = "http://theory.stanford.edu/~barrett/pubs/BBS+05.pdf",
  author    = "Sergey Berezin and Clark Barrett and Igor Shikanian and Marsha Chechik and Arie Gurfinkel and David L. Dill",
  title     = "A Practical Approach to Partial Functions in {CVC L}ite",
  booktitle = "Selected Papers from the Workshops on Disproving
               and the Second International Workshop on Pragmatics
               of Decision Procedures (PDPAR '04)",
  series    = "Electronic Notes in Theoretical Computer Science",
  volume    = "125(3)",
  publisher = "Elsevier",
  editor    = "Wolfgang Ahrendt and Peter Baumgartner and Hans de Nivelle and Silvio Ranise and Cesare Tinelli",
  pages     = "13--23",
  month     = jul,
  year      = 2005,
  note      = "Cork, Ireland",
  category  = "Refereed Workshop Publications",
}

%complete
@inproceedings{BD05,
  url       = "http://theory.stanford.edu/~barrett/pubs/BD05.pdf",
  author    = "Clark Barrett and Jacob Donham",
  title     = "Combining {SAT} Methods with Non-Clausal Decision Heuristics",
  booktitle = "Selected Papers from the Workshops on Disproving
               and the Second International Workshop on Pragmatics
               of Decision Procedures (PDPAR '04)",
  series    = "Electronic Notes in Theoretical Computer Science",
  volume    = "125(3)",
  publisher = "Elsevier",
  editor    = "Wolfgang Ahrendt and Peter Baumgartner and Hans de Nivelle and Silvio Ranise and Cesare Tinelli",
  pages     = "3--12",
  month     = jul,
  year      = 2005,
  note      = "Cork, Ireland",
  category  = "Refereed Workshop Publications",
}

%complete (not published)
@InProceedings{BB03,
  url       = "http://theory.stanford.edu/~barrett/pubs/BB03.pdf",
  author    = "Clark Barrett and Sergey Berezin",
  title     = "A Proof-Producing Boolean Search Engine",
  booktitle = "Proceedings of the $1^{st}$ International Workshop on Pragmatics of Decision Procedures in Automated Reasoning (PDPAR '03)",
  month     = jul,
  year      = 2003,
  note      = "Miami, Florida",
  category  = "Refereed Workshop Publications",
}

%complete
@InProceedings{BGZ03,
  url       = "http://theory.stanford.edu/~barrett/pubs/BGZ03.pdf",
  author    = "Clark Barrett and Benjamin Goldberg and Lenore Zuck",
  title     = "Run-Time Validation of Speculative Optimizations using {CVC}",
  booktitle = "Proceedings of the $3^{rd}$ International Workshop on Run-time Verification (RV '03)",
  series    = "Electronic Notes in Theoretical Computer Science",
  volume    = "89(2)",
  publisher = "Elsevier",
  editor    = "Oleg Sokolsky and Mahesh Viswanathan",
  pages     = "89--107",
  month     = oct,
  year      = 2003,
  note      = "Boulder, Colorado",
  category  = "Refereed Workshop Publications"
}

%complete
@inproceedings{BDS02-FROCOS02,
  url       = "http://theory.stanford.edu/~barrett/pubs/BDS02-FROCOS02.pdf",
  author    = "Clark W. Barrett and David L. Dill and Aaron Stump",
  title     = "A Generalization of {S}hostak's Method for Combining Decision Procedures",
  booktitle = "Proceedings of the $4^{th}$ International Workshop on Frontiers of Combining Systems (FroCoS '02)",
  series    = "Lecture Notes in Artificial Intelligence",
  volume    = 2309,
  publisher = "Springer-Verlag",
  editor    = "Alessandro Armando",
  pages     = "132--146",
  month     = apr,
  year      = 2002,
  note      = "Santa Margherita Ligure, Italy",
  category  = "Refereed Workshop Publications",
}

%complete
@inproceedings{SBD02b,
  url       = "http://theory.stanford.edu/~barrett/pubs/SBD02b.pdf",
  author    = {Aaron Stump and
               Clark W. Barrett and
               David L. Dill},
  title     = {Producing Proofs from an Arithmetic Decision Procedure in
               Elliptical {LF}},
  booktitle = "Proceedings of the $3^{rd}$ International Workshop on Logical Frameworks and Meta-Languages (LFM '02)",
  series    = "Electronic Notes in Theoretical Computer Science",
  volume    = "70(2)",
  publisher = "Elsevier",
  editor    = "Frank Pfenning",
  pages     = "29--41",
  month     = jul,
  year      = 2002,
  note      = "Copenhagen, Denmark",
  category  = "Refereed Workshop Publications",
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Technical Reports
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

@TechReport{SZY+23,
  url         = "http://arxiv.org/abs/2303.06865",
  author      = "Ying Sheng and Lianmin Zheng and Binhang Yuan and Zhuohan Li and Max Ryabinin and Daniel Y. Fu and Zhiqiang Xie and Beidi Chen and Clark Barrett and Joseph E. Gonzalez and Percy Liang and Christopher R\'e and Ion Stoica and Ce Zhang",
  title       = "FlexGen: High-Throughput Generative Inference of Large Language Models with a Single GPU",
  year        = 2023,
  eprint      = "2303.06865",
  category    = "Technical Reports",
  abstract    = "The high computational and memory requirements of large
                  language model (LLM) inference make it feasible only with
                  multiple high-end accelerators. Motivated by the emerging
                  demand for latency-insensitive tasks with batched processing,
                  this paper initiates the study of high-throughput LLM
                  inference using limited resources, such as a single commodity
                  GPU. We present FlexGen, a high-throughput generation engine
                  for running LLMs with limited GPU memory. FlexGen can be
                  flexibly configured under various hardware resource
                  constraints by aggregating memory and computation from the
                  GPU, CPU, and disk. By solving a linear programming problem,
                  it searches for efficient patterns to store and access
                  tensors. FlexGen further compresses the weights and the
                  attention cache to 4 bits with negligible accuracy
                  loss. These techniques enable FlexGen to have a larger space
                  of batch size choices and thus significantly increase maximum
                  throughput. As a result, when running OPT-175B on a single
                  16GB GPU, FlexGen achieves significantly higher throughput
                  compared to state-of-the-art offloading systems, reaching a
                  generation throughput of 1 token/s for the first time with an
                  effective batch size of 144. On the HELM benchmark, FlexGen
                  can benchmark a 30B model with a 16GB GPU on 7 representative
                  sub-scenarios in 21 hours."
}

@TechReport{DDM+23,
  url         = "http://arxiv.org/abs/2308.13106",
  author      = "Caleb Donovick and Ross Daly and Jackson Melchert and Lenny Truong and Priyanka Raina and Pat Hanrahan and Clark Barrett",
  title       = "PEak: A Single Source of Truth for Hardware Design and Verification",
  year        = 2023,
  eprint      = "2308.13106",
  category    = "Technical Reports",
  abstract    = "Domain-specific languages for hardware can significantly
                  enhance designer productivity, but sometimes at the cost of
                  ease of verification. On the other hand, ISA specification
                  languages are too static to be used during early stage design
                  space exploration. We present PEak, an open-source hardware
                  design and specification language, which aims to improve both
                  design productivity and verification capability. PEak does
                  this by providing a single source of truth for functional
                  models, formal specifications, and RTL. PEak has been used in
                  several academic projects, and PEak-generated RTL has been
                  included in three fabricated hardware accelerators. In these
                  projects, the formal capabilities of PEak were crucial for
                  enabling both novel design space exploration techniques and
                  automated compiler synthesis."
}

@TechReport{GLN+20,
  url         = "http://arxiv.org/abs/2106.10392",
  author      = "Karthik Ganesan and Florian Lonsing and Srinivasa Shashank Nuthakki and Eshan Singh and Mohammad Rahmani Fadiheh and Wolfgang Kunz and Dominik Stoffel and Clark Barrett and Subhasish Mitra",
  title       = "Effective Pre-Silicon Verification of Processor Cores by Breaking the Bounds of Symbolic Quick Error Detection",
  year        = 2021,
  eprint      = "2106.10392",
  category    = "Technical Reports",
}

@TechReport{SWZ+20,
  url         = "http://arxiv.org/abs/2010.03258",
  author      = "Christopher A. Strong and Haoze Wu and Aleksandar Zelji{\'{c}} and Kyle D. Julian and Guy Katz and Clark Barrett and Mykel J. Kochenderfer",
  title       = "Global Optimization of Objective Functions Represented by {ReLU} Networks",
  year        = 2020,
  eprint      = "2010.03258",
  category    = "Technical Reports",
}

@TechReport{BDQ+20,
  url         = "https://arxiv.org/abs/2004.05106",
  title       = "Resources: A Safe Language Abstraction for Money",
  author      = "Sam Blackshear and David L. Dill and Shaz Qadeer and Clark W. Barrett and John C. Mitchell and Oded Padon and Yoni Zohar",
  year        = 2020,
  eprint      = "2004.05106",
  category    = "Technical Reports",
}

@TechReport{KKG+18,
   url        = "https://arxiv.org/abs/1801.05950",
   title      = "Toward Scalable Verification for Safety-Critical Deep Networks",
   author     = "Lindsey Kuper and Guy Katz and Justin Gottschlich and Kyle Julian and Clark Barrett and Mykel Kochenderfer",
   year       = 2018,
   eprint     = "1801.05950",
   category   = "Technical Reports",
}

@TechReport{CKB+18,
   url        = "https://arxiv.org/abs/1709.10207",
   title      = "Provably Minimally-Distorted Adversarial Examples",
   author     = "Nicholas Carlini and Guy Katz and Clark Barrett and David L. Dill",
   year       = 2018,
   eprint     = "1709.10207",
   category   = "Technical Reports",
}

%complete
@TechReport{BKM14,
  url         = "http://theory.stanford.edu/~barrett/pubs/BKM14.pdf",
  author      = "Clark Barrett and Daniel Kroening and Thomas Melham",
  title       = "Problem Solving for the 21st Century: Efficient Solvers for Satisfiability Modulo Theories",
  institution = "London Mathematical Society and Smith Institute for Industrial Mathematics and System Engineering",
  number      = 3,
  month       = Jun,
  year        = 2014,
  note        = "Knowledge Transfer Report",
  category    = "Technical Reports",
  abstract    = "What is the best way to allocate assets across an investment
                  portfolio to minimise risk? How should an airline, operating
                  on razor-thin profit margins, assign flight crew to flights
                  to minimise costs--at the same time meeting regulations and
                  ensuring the schedule is robust? What is the most effective
                  way to test a software system in a limited time?  Are there
                  any unforseen security holes in a new business-critical
                  computer system?  All these practical problems involve
                  finding solutions to complex systems of constraining
                  requirements that can be formulated mathematically. The task
                  resembles problem-solving in school maths: formulate some
                  equations that relate quantities in the problem to be solved,
                  and then find the right values for the variables that make
                  the equations true. In business and industry, however, the
                  problems are vastly larger and the mathematics much more
                  complex and varied.  These important problems cannot be
                  solved by hand, but must be tackled by computer software
                  algorithms. A prominent example is linear programming, a
                  mathematical optimisation technique with wide applications in
                  modern company management and microeconomics. First used in
                  earnest for planning in World War II, linear programming has
                  been a mainstay of business and industry since the 1950s.
                  Over the past decade, a new and revolutionary
                  problem-solving technology has emerged: Satisfiability Modulo
                  Theories, or 'SMT' for short. Like linear programming, it is
                  a computerised method for finding solutions to business and
                  industrial problems expressed mathematically by systems of
                  constraints. But SMT can handle a richer language of
                  constraints than linear programming, and the method
                  encompasses a more varied range of mathematical concepts--so
                  it has the flexibility to tackle many different kinds of
                  problems.  With established success in the engineering design
                  of computer chips, software that implements SMT does have
                  limits to the size of problem it can handle--but it has also
                  seen truly astonishing increases in speed and capacity over
                  the past decade.  The core SMT algorithms are generic and not
                  special to a particular problem. So, end-users who can frame
                  their practical business and industrial problems in a
                  mathematical way suitable for SMT automatically benefit from
                  intense investment by the highly skilled technical
                  specialists who develop SMT algorithms, a smart way to tap
                  into a sophisticated technology that is improving by leaps
                  and bounds every year.  To exploit SMT effectively, you have
                  to express the problem to be solved in the right mathematical
                  way.  Some types of problems have well-understood
                  translations into SMT, so the technology is ready for early
                  adoption by at least some enterprises seeking competitive
                  advantage. SMT solutions to other kinds of problems are the
                  subject of active academic and industrial research--and many
                  more lie awaiting creative discovery.  This report explains
                  the background to SMT technology and presents several success
                  stories.  Our aim is to give a sense of the potential of SMT
                  as an effective solution to some of today's problems--and a
                  unique emerging technology to watch in the future."
}

%complete
@TechReport{JB11-TR,
  url         = "http://theory.stanford.edu/~barrett/pubs/JB11-TR.pdf",
  author      = "Dejan Jovanovi\'{c} and Clark Barrett",
  title       = "Sharing is Caring: Combination of Theories",
  institution = "Depatrment of Computer Science, New York University",
  number      = "TR2011-940",
  month       = oct,
  year        = 2011,
  category    = "Technical Reports",
}

%complete
@TechReport{BDOS10-TR,
  url         = "http://theory.stanford.edu/~barrett/pubs/BDOS10-TR.pdf",
  author      = "Clark Barrett and Morgan Deters and Albert Oliveras and Aaron Stump",
  title       = "Design and Results of the $4^{th}$ Annual Satisfiability Modulo Theories Competition ({SMT-COMP} 2008)",
  institution = "Depatrment of Computer Science, New York University",
  number      = "TR2010-931",
  month       = jul,
  year        = 2010,
  category    = "Technical Reports",
}

%complete
@TechReport{JB10-TR,
  url         = "http://theory.stanford.edu/~barrett/pubs/JB10-TR.pdf",
  author      = "Dejan Jovanovi\'{c} and Clark Barrett",
  title       = "Polite Theories Revisited",
  institution = "Depatrment of Computer Science, New York University",
  number      = "TR2010-922",
  month       = jan,
  year        = 2010,
  category    = "Technical Reports",
}

%complete
@TechReport{CDN+08-TR,
  url         = "http://theory.stanford.edu/~barrett/pubs/CDN+08-TR.pdf",
  author      = "Christopher L. Conway and Dennis Dams and Kedar S. Namjoshi and Clark Barrett",
  title       = "Points-to Analysis, Conditional Soundness, and Proving the Absence of Errors",
  institution = "Depatrment of Computer Science, New York University",
  number      = "TR2008-910",
  month       = mar,
  year        = 2008,
  category    = "Technical Reports"
}

%complete
@TechReport{BNO+06-TR,
  url         = "http://theory.stanford.edu/~barrett/pubs/BNO+06-TR.pdf",
  author      =	"Clark Barrett and Robert Nieuwenhuis and Albert Oliveras and Cesare Tinelli",
  title       = "Splitting on Demand in {SAT Modulo Theories}",
  institution =	"Department of Computer Science, University of Iowa",
  number      = "06-05",
  month       = aug,
  year        = 2006,
  category    = "Technical Reports",
}

%complete
@TechReport{BST05,
  url         = "http://theory.stanford.edu/~barrett/pubs/BST05.pdf",
  author      = "Clark Barrett and Igor Shikanian and Cesare Tinelli",
  title       = "An Abstract Decision Procedure for Satisfiability in the Theory of Recursive Data Types",
  institution =	"Department of Computer Science, New York University",
  number      =	"TR2005-878",
  month       =	nov,
  year        =	2005,
  category    = "Technical Reports",
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PhD thesis
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%complete
@phdthesis{B03,
  url       = "http://theory.stanford.edu/~barrett/pubs/B03.pdf",
  author    = "Clark W. Barrett",
  title     = "Checking Validity of Quantifier-Free Formulas in Combinations of First-Order Theories",
  school    = "Stanford University",
  month     = jan,
  year      = 2003,
  note      = "Stanford, California",
  category  = "Thesis",
}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% PhD thesis
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%complete
@article {B13,
   url       = "http://theory.stanford.edu/~barrett/pubs/B13.pdf",
   author    = "Clark Barrett",
   title     = {{``Decision Procedures:An Algorithmic Point of View,'' by Daniel Kroening and Ofer Strichman, Springer-Verlag, 2008}},
   journal   = "Journal of Automated Reasoning",
   publisher = "Springer Netherlands",
   volume    = 51,
   number    = 4,
   doi       = {10.1007/s10817-013-9295-4},
   pages     = "453--456",
   month     = dec,
   year      = 2013,
   category  = "Book Reviews"
}

